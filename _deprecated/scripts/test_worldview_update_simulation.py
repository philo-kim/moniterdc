"""
ì„¸ê³„ê´€ ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜

í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:
1. ìƒˆë¡œìš´ ê¸€ ìˆ˜ì§‘
2. 3-layer ë¶„ì„
3. ì„¸ê³„ê´€ ì—…ë°ì´íŠ¸ ë°©ì‹ ë¹„êµ:
   - ë°©ì‹ A: ì „ì²´ ì¬êµ¬ì„± (ìƒˆë¡œ ìƒì„±)
   - ë°©ì‹ B: ê¸°ì¡´ ì„¸ê³„ê´€ì— ì¶”ê°€
   - ë°©ì‹ C: ì ì§„ì  ì—…ë°ì´íŠ¸ (merge)
   - ë°©ì‹ D: ì„ê³„ê°’ ê¸°ë°˜ ì—…ë°ì´íŠ¸
"""

import asyncio
import sys
import os
import json
from datetime import datetime
from openai import AsyncOpenAI
sys.path.insert(0, '/Users/taehyeonkim/dev/minjoo/moniterdc')
from engines.utils.supabase_client import get_supabase

client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))

async def collect_new_posts(limit=50):
    """ìµœì‹  ê°œë…ê¸€ ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜)"""
    print("\n" + "="*70)
    print("1. ìƒˆë¡œìš´ ê¸€ ìˆ˜ì§‘")
    print("="*70)

    supabase = get_supabase()

    # ê¸°ì¡´ ë°ì´í„° í™•ì¸
    existing = supabase.table('contents').select('id', count='exact').execute()
    print(f"\nê¸°ì¡´ contents: {existing.count}ê°œ")

    # ì‹¤ì œë¡œëŠ” DC Galleryì—ì„œ í¬ë¡¤ë§í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ ë°ì´í„°ë¡œ ì‹œë®¬ë ˆì´ì…˜
    # ê°€ì¥ ìµœê·¼ ê¸€ë“¤ì„ "ìƒˆ ê¸€"ë¡œ ê°€ì •
    new_posts = supabase.table('contents')\
        .select('*')\
        .order('created_at', desc=True)\
        .limit(limit)\
        .execute().data

    print(f"ìƒˆë¡œ ìˆ˜ì§‘í•  ê¸€: {len(new_posts)}ê°œ (ì‹œë®¬ë ˆì´ì…˜)")

    # ìƒ˜í”Œ ì¶œë ¥
    print(f"\nìƒ˜í”Œ 3ê°œ:")
    for i, post in enumerate(new_posts[:3], 1):
        print(f"  {i}. {post['title'][:60]}")

    return new_posts


async def analyze_new_posts(new_posts):
    """ìƒˆ ê¸€ 3-layer ë¶„ì„"""
    print("\n" + "="*70)
    print("2. ìƒˆ ê¸€ 3-Layer ë¶„ì„")
    print("="*70)

    from engines.analyzers.layered_perception_extractor import LayeredPerceptionExtractor

    extractor = LayeredPerceptionExtractor()
    supabase = get_supabase()

    # ì´ë¯¸ ë¶„ì„ëœ ê²ƒ ì œì™¸
    analyzed_ids = set(
        lp['content_id']
        for lp in supabase.table('layered_perceptions').select('content_id').execute().data
    )

    new_to_analyze = [p for p in new_posts if p['id'] not in analyzed_ids]

    print(f"\në¶„ì„ ëŒ€ìƒ: {len(new_to_analyze)}ê°œ")

    if len(new_to_analyze) == 0:
        print("âš ï¸  ëª¨ë‘ ì´ë¯¸ ë¶„ì„ë¨. ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•´ ê¸°ì¡´ ë¶„ì„ ì‚¬ìš©")

        # ê¸°ì¡´ ë¶„ì„ ì¤‘ ìµœì‹  ê²ƒ ì‚¬ìš©
        existing_lps = supabase.table('layered_perceptions')\
            .select('*')\
            .order('created_at', desc=True)\
            .limit(20)\
            .execute().data

        return existing_lps

    # ì‹¤ì œ ë¶„ì„ (ìƒ˜í”Œë§Œ)
    analyzed = []
    for i, post in enumerate(new_to_analyze[:5], 1):
        print(f"\r  ë¶„ì„ ì¤‘: {i}/5", end='', flush=True)

        try:
            lp_id = await extractor.extract(post)
            lp = supabase.table('layered_perceptions')\
                .select('*')\
                .eq('id', str(lp_id))\
                .execute().data[0]
            analyzed.append(lp)
        except Exception as e:
            print(f"\n  âš ï¸  ë¶„ì„ ì‹¤íŒ¨: {e}")

    print(f"\n\nâœ… {len(analyzed)}ê°œ ë¶„ì„ ì™„ë£Œ")

    return analyzed


async def scenario_a_full_rebuild(old_worldviews, new_perceptions):
    """
    ë°©ì‹ A: ì „ì²´ ì¬êµ¬ì„±

    - ê¸°ì¡´ + ìƒˆ ë°ì´í„° ì „ë¶€ í•©ì³ì„œ ë‹¤ì‹œ ì„¸ê³„ê´€ êµ¬ì„±
    - ì¥ì : ì™„ì „íˆ ìƒˆë¡œìš´ ì‹œê°
    - ë‹¨ì : ê¸°ì¡´ ì„¸ê³„ê´€ ì†Œì‹¤, ë¹„ìš© ë†’ìŒ
    """
    print("\n" + "="*70)
    print("ì‹œë‚˜ë¦¬ì˜¤ A: ì „ì²´ ì¬êµ¬ì„±")
    print("="*70)

    supabase = get_supabase()

    # ëª¨ë“  perception ê°€ì ¸ì˜¤ê¸°
    all_perceptions = supabase.table('layered_perceptions')\
        .select('*')\
        .execute().data

    print(f"\nì „ì²´ perception: {len(all_perceptions)}ê°œ")

    # ì „ì²´ ì¬êµ¬ì„± (OptimalWorldviewConstructor ì‚¬ìš©)
    from engines.analyzers.optimal_worldview_constructor import OptimalWorldviewConstructor

    constructor = OptimalWorldviewConstructor()

    # ìƒ˜í”Œë¡œë§Œ í…ŒìŠ¤íŠ¸ (ë¹„ìš© ì ˆê°)
    print("\nâš ï¸  ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ìƒ˜í”Œ 30ê°œë¡œ í…ŒìŠ¤íŠ¸")

    sample_perceptions = all_perceptions[:30]

    hierarchy = await constructor._extract_hierarchical_worldviews(sample_perceptions)

    print(f"\nìƒˆë¡œ ì¶”ì¶œëœ ì„¸ê³„ê´€:")
    for cat in hierarchy:
        print(f"  ğŸ“‚ {cat['category']}")
        for sub in cat.get('subcategories', []):
            print(f"    â””â”€ {sub['title']}")

    # í‰ê°€
    print("\nğŸ“Š í‰ê°€:")
    print("  ì¥ì : ì™„ì „íˆ ìƒˆë¡œìš´ ê´€ì  ë°˜ì˜")
    print("  ë‹¨ì :")
    print("    - ê¸°ì¡´ ì„¸ê³„ê´€ ID ë³€ê²½ (ë§í¬ ê¹¨ì§)")
    print("    - GPT ë¹„ìš© ë†’ìŒ")
    print("    - ì¼ê´€ì„± ìœ ì§€ ì–´ë ¤ì›€")

    return {
        'method': 'full_rebuild',
        'new_worldviews': len(hierarchy),
        'cost': 'high',
        'consistency': 'low'
    }


async def scenario_b_append_to_existing(old_worldviews, new_perceptions):
    """
    ë°©ì‹ B: ê¸°ì¡´ ì„¸ê³„ê´€ì— ì¶”ê°€

    - ìƒˆ perceptionì„ ê¸°ì¡´ ì„¸ê³„ê´€ì— ë§¤ì¹­ë§Œ
    - ì„¸ê³„ê´€ ìì²´ëŠ” ë³€ê²½ ì—†ìŒ
    - ì¥ì : ë¹ ë¦„, ì¼ê´€ì„± ìœ ì§€
    - ë‹¨ì : ìƒˆë¡œìš´ ì„¸ê³„ê´€ ë°œê²¬ ë¶ˆê°€
    """
    print("\n" + "="*70)
    print("ì‹œë‚˜ë¦¬ì˜¤ B: ê¸°ì¡´ ì„¸ê³„ê´€ì— ì¶”ê°€ë§Œ")
    print("="*70)

    supabase = get_supabase()

    # ê¸°ì¡´ ì„¸ê³„ê´€ ë¡œë“œ
    existing_wvs = [wv for wv in old_worldviews if '>' in wv['title']]

    print(f"\nê¸°ì¡´ ì„¸ê³„ê´€: {len(existing_wvs)}ê°œ")
    for wv in existing_wvs:
        print(f"  - {wv['title']}")

    # ìƒˆ perception ë§¤ì¹­
    print(f"\nìƒˆ perception {len(new_perceptions)}ê°œë¥¼ ê¸°ì¡´ ì„¸ê³„ê´€ì— ë§¤ì¹­...")

    matched = 0
    unmatched = 0

    for lp in new_perceptions[:10]:  # ìƒ˜í”Œë§Œ
        lp_text = ' '.join(lp.get('deep_beliefs', []))

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        best_match = None
        best_score = 0

        for wv in existing_wvs:
            frame = json.loads(wv['frame'])
            keywords = frame['metadata'].get('key_concepts', [])

            score = sum(1 for kw in keywords if kw in lp_text)

            if score > best_score:
                best_score = score
                best_match = wv['title']

        if best_score > 0:
            matched += 1
            print(f"  âœ… ë§¤ì¹­: '{best_match}' (score: {best_score})")
        else:
            unmatched += 1
            print(f"  âŒ ë¯¸ë§¤ì¹­: {lp_text[:50]}...")

    # í‰ê°€
    print(f"\nğŸ“Š ê²°ê³¼:")
    print(f"  ë§¤ì¹­: {matched}ê°œ")
    print(f"  ë¯¸ë§¤ì¹­: {unmatched}ê°œ")

    if unmatched > 0:
        print(f"\nâš ï¸  ë¬¸ì œ: {unmatched}ê°œ perceptionì´ ê¸°ì¡´ ì„¸ê³„ê´€ì— ì•ˆ ë§ìŒ")
        print(f"  â†’ ìƒˆë¡œìš´ ì„¸ê³„ê´€ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ")

    print("\nğŸ“Š í‰ê°€:")
    print("  ì¥ì : ë¹ ë¦„, ë¹„ìš© ë‚®ìŒ, ì¼ê´€ì„± ìœ ì§€")
    print("  ë‹¨ì : ìƒˆë¡œìš´ ì„¸ê³„ê´€ ë°œê²¬ ë¶ˆê°€")

    return {
        'method': 'append_only',
        'matched': matched,
        'unmatched': unmatched,
        'cost': 'low',
        'new_worldviews': 0
    }


async def scenario_c_incremental_merge(old_worldviews, new_perceptions):
    """
    ë°©ì‹ C: ì ì§„ì  ë³‘í•©

    - ìƒˆ perception ë¶„ì„
    - ê¸°ì¡´ ì„¸ê³„ê´€ê³¼ ìœ ì‚¬ë„ ê³„ì‚°
    - ë†’ìœ¼ë©´ ê¸°ì¡´ ì„¸ê³„ê´€ ì—…ë°ì´íŠ¸ (narrative ì˜ˆì‹œ ì¶”ê°€)
    - ë‚®ìœ¼ë©´ ìƒˆ ì„¸ê³„ê´€ ìƒì„±
    - ì¥ì : ë°œì „ + ì¼ê´€ì„±
    - ë‹¨ì : ë³µì¡ë„
    """
    print("\n" + "="*70)
    print("ì‹œë‚˜ë¦¬ì˜¤ C: ì ì§„ì  ë³‘í•© (Incremental Merge)")
    print("="*70)

    supabase = get_supabase()

    existing_wvs = [wv for wv in old_worldviews if '>' in wv['title']]

    print(f"\nê¸°ì¡´ ì„¸ê³„ê´€: {len(existing_wvs)}ê°œ")

    # ìƒˆ perceptionë“¤ì˜ ì£¼ìš” íŒ¨í„´ ì¶”ì¶œ
    print(f"\nìƒˆ perception {len(new_perceptions)}ê°œ ë¶„ì„...")

    new_themes = {}
    for lp in new_perceptions[:15]:
        hint = lp.get('worldview_hints', '')
        beliefs = lp.get('deep_beliefs', [])

        # ì£¼ì œ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
        if 'ë¯¼ì£¼ë‹¹' in hint or 'ì¢ŒíŒŒ' in hint:
            theme = 'ë¯¼ì£¼ë‹¹/ì¢ŒíŒŒ'
        elif 'ì¤‘êµ­' in hint:
            theme = 'ì¤‘êµ­'
        elif 'ë¶í•œ' in hint:
            theme = 'ë¶í•œ'
        else:
            theme = 'ê¸°íƒ€'

        if theme not in new_themes:
            new_themes[theme] = []
        new_themes[theme].append(lp)

    print(f"\nìƒˆ ë°ì´í„°ì˜ ì£¼ì œ ë¶„í¬:")
    for theme, lps in new_themes.items():
        print(f"  - {theme}: {len(lps)}ê°œ")

    # ë³‘í•© ì „ëµ
    print("\në³‘í•© ì „ëµ:")

    updated = []
    created = []

    for theme, lps in new_themes.items():
        # ê¸°ì¡´ ì„¸ê³„ê´€ ì¤‘ ë§¤ì¹­ë˜ëŠ” ê²ƒ ì°¾ê¸°
        matching_wv = None

        for wv in existing_wvs:
            if theme in wv['title']:
                matching_wv = wv
                break

        if matching_wv:
            print(f"\n  âœ… '{theme}' â†’ ê¸°ì¡´ ì„¸ê³„ê´€ ì—…ë°ì´íŠ¸: {matching_wv['title']}")
            print(f"     ìƒˆ ì˜ˆì‹œ {len(lps)}ê°œ ì¶”ê°€ ê°€ëŠ¥")
            updated.append(matching_wv['title'])
        else:
            print(f"\n  â­ '{theme}' â†’ ìƒˆ ì„¸ê³„ê´€ ìƒì„± í•„ìš”")
            print(f"     ë°ì´í„°: {len(lps)}ê°œ")
            created.append(theme)

    # ì‹¤ì œ ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜ (1ê°œë§Œ)
    if updated:
        print(f"\n\nì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜: {updated[0]}")

        wv_to_update = [wv for wv in existing_wvs if wv['title'] == updated[0]][0]
        frame = json.loads(wv_to_update['frame'])

        print(f"\ní˜„ì¬ ì˜ˆì‹œ ê°œìˆ˜: {len(frame['narrative'].get('examples', []))}ê°œ")

        # ìƒˆ ì˜ˆì‹œ ìƒì„± (GPT)
        sample_lp = new_themes[list(new_themes.keys())[0]][0]

        prompt = f"""
ë‹¤ìŒ ìƒˆ ë°ì´í„°ë¥¼ ê¸°ì¡´ ì„¸ê³„ê´€ ì˜ˆì‹œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

ìƒˆ ë°ì´í„°:
- ì‹¬ì¸µ ë¯¿ìŒ: {sample_lp.get('deep_beliefs', [])[:2]}
- ì•”ë¬µì  ì „ì œ: {sample_lp.get('implicit_assumptions', [])[:2]}

ê¸°ì¡´ ì˜ˆì‹œ í˜•ì‹:
{{
  "case": "êµ¬ì²´ì  ì‚¬ë¡€",
  "dc_interpretation": "DC Gallery í•´ì„",
  "normal_interpretation": "ì¼ë°˜ì  í•´ì„",
  "gap": "í•µì‹¬ ì°¨ì´"
}}

JSONìœ¼ë¡œ ì‘ë‹µ:
"""

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are an expert. Always respond in valid JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            response_format={"type": "json_object"}
        )

        new_example = json.loads(response.choices[0].message.content)

        print(f"\nìƒì„±ëœ ìƒˆ ì˜ˆì‹œ:")
        print(json.dumps(new_example, ensure_ascii=False, indent=2))

        print(f"\nâ†’ ì´ ì˜ˆì‹œë¥¼ narrative.examplesì— ì¶”ê°€")

    # í‰ê°€
    print("\n\nğŸ“Š í‰ê°€:")
    print(f"  ì—…ë°ì´íŠ¸ë  ì„¸ê³„ê´€: {len(updated)}ê°œ")
    print(f"  ìƒˆë¡œ ìƒì„±ë  ì„¸ê³„ê´€: {len(created)}ê°œ")
    print("\n  ì¥ì :")
    print("    - ê¸°ì¡´ ì„¸ê³„ê´€ ë°œì „ (ì˜ˆì‹œ ì¦ê°€)")
    print("    - ìƒˆë¡œìš´ ì„¸ê³„ê´€ ë°œê²¬")
    print("    - ì¼ê´€ì„± ìœ ì§€ (ID ë³€ê²½ ì—†ìŒ)")
    print("  ë‹¨ì :")
    print("    - êµ¬í˜„ ë³µì¡ë„ ë†’ìŒ")
    print("    - GPT ë¹„ìš© ì¤‘ê°„")

    return {
        'method': 'incremental_merge',
        'updated': len(updated),
        'created': len(created),
        'cost': 'medium',
        'consistency': 'high'
    }


async def scenario_d_threshold_based(old_worldviews, new_perceptions):
    """
    ë°©ì‹ D: ì„ê³„ê°’ ê¸°ë°˜ ì—…ë°ì´íŠ¸

    - ìƒˆ perception ëˆ„ì 
    - Nê°œ ì´ìƒ ìŒ“ì´ë©´ ì¬êµ¬ì„±
    - ë˜ëŠ” ê¸°ì¡´ ì„¸ê³„ê´€ê³¼ ë¶ˆì¼ì¹˜ìœ¨ > X% ì´ë©´ ì¬êµ¬ì„±
    - ì¥ì : ìë™í™”, ì•ˆì •ì„±
    - ë‹¨ì : ì§€ì—°
    """
    print("\n" + "="*70)
    print("ì‹œë‚˜ë¦¬ì˜¤ D: ì„ê³„ê°’ ê¸°ë°˜ ì—…ë°ì´íŠ¸")
    print("="*70)

    supabase = get_supabase()

    # í˜„ì¬ ìƒíƒœ
    total_perceptions = supabase.table('layered_perceptions').select('id', count='exact').execute().count

    existing_wvs = [wv for wv in old_worldviews if '>' in wv['title']]

    print(f"\ní˜„ì¬ ìƒíƒœ:")
    print(f"  ì „ì²´ perception: {total_perceptions}ê°œ")
    print(f"  ì„¸ê³„ê´€: {len(existing_wvs)}ê°œ")

    # ìƒˆ ë°ì´í„°
    new_count = len(new_perceptions)
    print(f"  ìƒˆ perception: {new_count}ê°œ")

    # ì„ê³„ê°’ ì„¤ì •
    REBUILD_THRESHOLD = 100  # 100ê°œ ìƒˆ ë°ì´í„°ë§ˆë‹¤ ì¬êµ¬ì„±
    MISMATCH_THRESHOLD = 0.3  # 30% ë¯¸ë§¤ì¹­ ì‹œ ì¬êµ¬ì„±

    print(f"\nì„ê³„ê°’:")
    print(f"  ì¬êµ¬ì„± ì„ê³„ê°’: {REBUILD_THRESHOLD}ê°œ")
    print(f"  ë¶ˆì¼ì¹˜ ì„ê³„ê°’: {MISMATCH_THRESHOLD*100}%")

    # ì¡°ê±´ 1: ê°œìˆ˜ ì„ê³„ê°’
    needs_rebuild_count = new_count >= REBUILD_THRESHOLD

    print(f"\nì¡°ê±´ 1: ëˆ„ì  ê°œìˆ˜")
    print(f"  {new_count} / {REBUILD_THRESHOLD} = {new_count/REBUILD_THRESHOLD*100:.1f}%")
    print(f"  â†’ {'ì¬êµ¬ì„± í•„ìš”' if needs_rebuild_count else 'ì•„ì§ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ'}")

    # ì¡°ê±´ 2: ë¶ˆì¼ì¹˜ìœ¨
    matched = 0
    for lp in new_perceptions[:20]:  # ìƒ˜í”Œ
        lp_text = ' '.join(lp.get('deep_beliefs', []))

        for wv in existing_wvs:
            frame = json.loads(wv['frame'])
            keywords = frame['metadata'].get('key_concepts', [])

            if any(kw in lp_text for kw in keywords):
                matched += 1
                break

    mismatch_rate = 1 - (matched / min(len(new_perceptions), 20))
    needs_rebuild_mismatch = mismatch_rate > MISMATCH_THRESHOLD

    print(f"\nì¡°ê±´ 2: ë¶ˆì¼ì¹˜ìœ¨")
    print(f"  ë¯¸ë§¤ì¹­: {mismatch_rate*100:.1f}%")
    print(f"  â†’ {'ì¬êµ¬ì„± í•„ìš”' if needs_rebuild_mismatch else 'ê¸°ì¡´ ì„¸ê³„ê´€ ì¶©ë¶„'}")

    # ìµœì¢… ê²°ì •
    should_rebuild = needs_rebuild_count or needs_rebuild_mismatch

    print(f"\n\nğŸ¯ ìµœì¢… ê²°ì •:")
    if should_rebuild:
        print("  â†’ ì¬êµ¬ì„± ì‹¤í–‰")
        print("  â†’ OptimalWorldviewConstructor í˜¸ì¶œ")
    else:
        print("  â†’ ê¸°ì¡´ ì„¸ê³„ê´€ ìœ ì§€")
        print("  â†’ ìƒˆ perceptionë§Œ ë§¤ì¹­")

    # í‰ê°€
    print("\nğŸ“Š í‰ê°€:")
    print("  ì¥ì :")
    print("    - ìë™í™” ê°€ëŠ¥")
    print("    - ì•ˆì •ì  (ë¶ˆí•„ìš”í•œ ì¬êµ¬ì„± ë°©ì§€)")
    print("  ë‹¨ì :")
    print("    - ì—…ë°ì´íŠ¸ ì§€ì—° ê°€ëŠ¥")
    print("    - ì„ê³„ê°’ íŠœë‹ í•„ìš”")

    return {
        'method': 'threshold_based',
        'should_rebuild': should_rebuild,
        'new_count': new_count,
        'mismatch_rate': mismatch_rate,
        'cost': 'low' if not should_rebuild else 'high'
    }


async def compare_all_scenarios(results):
    """ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ"""
    print("\n" + "="*70)
    print("ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ")
    print("="*70)

    print("\n| ë°©ì‹ | ë¹„ìš© | ì¼ê´€ì„± | ë°œì „ì„± | ìë™í™” | ì¶”ì²œë„ |")
    print("|------|------|--------|--------|--------|--------|")

    scenarios = {
        'A. ì „ì²´ ì¬êµ¬ì„±': {
            'cost': 'ë†’ìŒ',
            'consistency': 'ë‚®ìŒ',
            'evolution': 'ë†’ìŒ',
            'automation': 'ì¤‘ê°„',
            'score': 'âš ï¸'
        },
        'B. ì¶”ê°€ë§Œ': {
            'cost': 'ë‚®ìŒ',
            'consistency': 'ë†’ìŒ',
            'evolution': 'ë‚®ìŒ',
            'automation': 'ë†’ìŒ',
            'score': 'âš ï¸'
        },
        'C. ì ì§„ì  ë³‘í•©': {
            'cost': 'ì¤‘ê°„',
            'consistency': 'ë†’ìŒ',
            'evolution': 'ë†’ìŒ',
            'automation': 'ì¤‘ê°„',
            'score': 'âœ…âœ…'
        },
        'D. ì„ê³„ê°’ ê¸°ë°˜': {
            'cost': 'ë‚®ìŒ',
            'consistency': 'ë†’ìŒ',
            'evolution': 'ì¤‘ê°„',
            'automation': 'ë†’ìŒ',
            'score': 'âœ…'
        }
    }

    for name, scores in scenarios.items():
        print(f"| {name} | {scores['cost']} | {scores['consistency']} | {scores['evolution']} | {scores['automation']} | {scores['score']} |")

    print("\n\nğŸ† ìµœì  ì „ëµ:")
    print("="*70)
    print("""
ë°©ì‹ C (ì ì§„ì  ë³‘í•©) + ë°©ì‹ D (ì„ê³„ê°’)ì˜ í•˜ì´ë¸Œë¦¬ë“œ

ã€ìš´ì˜ ë°©ì‹ã€‘

1. ì¼ìƒ ìš´ì˜ (ë§¤ì¼):
   - ìƒˆ ê¸€ ìˆ˜ì§‘
   - 3-layer ë¶„ì„
   - ê¸°ì¡´ ì„¸ê³„ê´€ì— ë§¤ì¹­ (ë°©ì‹ B)

2. ì ì§„ì  ì—…ë°ì´íŠ¸ (ì£¼ 1íšŒ):
   - ìƒˆë¡œ ë§¤ì¹­ëœ perception ì¤‘ ëŒ€í‘œ ì‚¬ë¡€ ì„ ì •
   - ê¸°ì¡´ ì„¸ê³„ê´€ narrativeì— ì˜ˆì‹œ ì¶”ê°€ (ë°©ì‹ C)
   - GPTë¡œ ìƒˆ ì˜ˆì‹œ ìƒì„± í›„ ì¶”ê°€

3. ì„ê³„ê°’ ì¬êµ¬ì„± (ì›” 1íšŒ ë˜ëŠ” ì¡°ê±´ ì¶©ì¡± ì‹œ):
   - ì¡°ê±´ 1: ìƒˆ perception 100ê°œ+ ëˆ„ì 
   - ì¡°ê±´ 2: ë¯¸ë§¤ì¹­ë¥  30%+
   - ì¡°ê±´ ì¶©ì¡± ì‹œ: ì „ì²´ ì¬êµ¬ì„± (ë°©ì‹ A)

4. ìƒˆ ì„¸ê³„ê´€ ë°œê²¬ (ìˆ˜ì‹œ):
   - ë¯¸ë§¤ì¹­ perceptionì´ íŠ¹ì • ì£¼ì œë¡œ 10ê°œ+ ëˆ„ì 
   - GPTë¡œ ìƒˆ ì„¸ê³„ê´€ ìƒì„±
   - ê¸°ì¡´ ê³„ì¸µì— ì¶”ê°€

ã€ì¥ì ã€‘
- ì¼ìƒ: ë¹ ë¥´ê³  ì €ë¹„ìš© (ë§¤ì¹­ë§Œ)
- ì£¼ê°„: ê¸°ì¡´ ì„¸ê³„ê´€ ë°œì „ (ì˜ˆì‹œ ì¦ê°€)
- ì›”ê°„: ì „ì²´ êµ¬ì¡° ì¬ì •ë¹„
- ìˆ˜ì‹œ: ìƒˆë¡œìš´ ë‹´ë¡  í¬ì°©

ã€êµ¬í˜„ ë³µì¡ë„ã€‘
- ì¤‘ê°„ (í•˜ì§€ë§Œ ê°€ì¹˜ ìˆìŒ)
""")


async def main():
    print("="*70)
    print("ì„¸ê³„ê´€ ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜")
    print("="*70)

    # 1. ìƒˆ ê¸€ ìˆ˜ì§‘
    new_posts = await collect_new_posts(limit=50)

    # 2. 3-layer ë¶„ì„
    new_perceptions = await analyze_new_posts(new_posts)

    # 3. ê¸°ì¡´ ì„¸ê³„ê´€ ë¡œë“œ
    supabase = get_supabase()
    old_worldviews = supabase.table('worldviews').select('*').execute().data

    # 4. ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
    results = {}

    results['A'] = await scenario_a_full_rebuild(old_worldviews, new_perceptions)
    results['B'] = await scenario_b_append_to_existing(old_worldviews, new_perceptions)
    results['C'] = await scenario_c_incremental_merge(old_worldviews, new_perceptions)
    results['D'] = await scenario_d_threshold_based(old_worldviews, new_perceptions)

    # 5. ë¹„êµ
    await compare_all_scenarios(results)

if __name__ == '__main__':
    asyncio.run(main())
