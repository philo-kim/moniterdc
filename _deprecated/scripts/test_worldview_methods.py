"""
ì„¸ê³„ê´€ êµ¬ì„± ë°©ì‹ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸

ì‹¤ì œ ë°ì´í„°ë¡œ 3ê°€ì§€ ë°©ì‹ì„ í…ŒìŠ¤íŠ¸:
1. Vector embedding only
2. Structured template
3. Narrative + Metadata hybrid
"""

import asyncio
import sys
import os
import json
from openai import AsyncOpenAI
from engines.utils.supabase_client import get_supabase

client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))

async def fetch_sample_data(limit=20):
    """ì‹¤ì œ layered_perceptions ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°"""
    supabase = get_supabase()

    lps = supabase.table('layered_perceptions')\
        .select('id, content_id, deep_beliefs, implicit_assumptions, worldview_hints')\
        .limit(limit)\
        .execute().data

    # Get content titles for context
    for lp in lps:
        content = supabase.table('contents')\
            .select('title')\
            .eq('id', lp['content_id'])\
            .execute().data[0]
        lp['title'] = content['title']

    return lps


async def method1_vector_only(samples):
    """
    ë°©ë²• 1: Vector Embeddingë§Œ ì‚¬ìš©

    - deep_beliefsë¥¼ ëª¨ë‘ concatenate
    - embedding ê³„ì‚°
    - clusteringìœ¼ë¡œ ê·¸ë£¹í™”
    """
    print("\n" + "="*70)
    print("ë°©ë²• 1: Vector Embedding Only")
    print("="*70)

    # Step 1: ëª¨ë“  deep_beliefsë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    belief_texts = []
    for lp in samples:
        beliefs = lp.get('deep_beliefs', [])
        text = ' | '.join(beliefs)
        belief_texts.append({
            'id': lp['id'],
            'text': text,
            'title': lp['title']
        })

    # Step 2: Embedding ê³„ì‚°
    print(f"\n{len(belief_texts)}ê°œ perceptionì˜ embedding ê³„ì‚° ì¤‘...")

    embeddings = []
    for bt in belief_texts[:10]:  # First 10 for speed
        response = await client.embeddings.create(
            model="text-embedding-3-small",
            input=bt['text']
        )
        embeddings.append({
            'id': bt['id'],
            'title': bt['title'],
            'embedding': response.data[0].embedding
        })

    # Step 3: ê°„ë‹¨í•œ clustering (cosine similarity)
    import numpy as np

    def cosine_similarity(a, b):
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

    # ì²« ë²ˆì§¸ë¥¼ seedë¡œ ì‚¬ìš©
    clusters = []
    threshold = 0.75

    for emb in embeddings:
        matched = False
        for cluster in clusters:
            # í´ëŸ¬ìŠ¤í„°ì˜ ì²« ë²ˆì§¸ ìš”ì†Œì™€ ë¹„êµ
            sim = cosine_similarity(emb['embedding'], cluster[0]['embedding'])
            if sim > threshold:
                cluster.append(emb)
                matched = True
                break

        if not matched:
            clusters.append([emb])

    print(f"\nâœ… {len(clusters)}ê°œ í´ëŸ¬ìŠ¤í„° ë°œê²¬")

    for i, cluster in enumerate(clusters[:3], 1):
        print(f"\ní´ëŸ¬ìŠ¤í„° {i}: {len(cluster)}ê°œ")
        for item in cluster[:2]:
            print(f"  - {item['title'][:60]}")

    # í‰ê°€
    print("\nğŸ“Š í‰ê°€:")
    print("  ì¥ì : ìë™í™” ê°€ëŠ¥, ê°ê´€ì ")
    print("  ë‹¨ì : ì™œ ê°™ì€ ê·¸ë£¹ì¸ì§€ ì„¤ëª… ë¶ˆê°€, threshold ì¡°ì • ì–´ë ¤ì›€")

    return {
        'method': 'vector_only',
        'clusters': len(clusters),
        'avg_cluster_size': sum(len(c) for c in clusters) / len(clusters),
        'explainable': False
    }


async def method2_structured_template(samples):
    """
    ë°©ë²• 2: Structured Template

    - GPTë¡œ êµ¬ì¡°í™”ëœ í…œí”Œë¦¿ ì¶”ì¶œ
    - who/what/why/how/where ë¶„ì„
    - í…œí”Œë¦¿ ìœ ì‚¬ë„ë¡œ ê·¸ë£¹í™”
    """
    print("\n" + "="*70)
    print("ë°©ë²• 2: Structured Template")
    print("="*70)

    # Step 1: ìƒ˜í”Œ 3ê°œë¡œ í…œí”Œë¦¿ ìƒì„±
    sample_lps = samples[:3]

    templates = []

    for lp in sample_lps:
        prompt = f"""
ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

ì œëª©: {lp['title']}
ì‹¬ì¸µ ë¯¿ìŒ: {lp.get('deep_beliefs', [])}
ì•”ë¬µì  ì „ì œ: {lp.get('implicit_assumptions', [])}

í…œí”Œë¦¿:
{{
  "who": "ì£¼ì²´ (ëˆ„êµ¬ì— ëŒ€í•œ ì´ì•¼ê¸°ì¸ê°€)",
  "what_they_do": "í–‰ë™ (ë¬´ì—‡ì„ í•œë‹¤ê³  ë³´ëŠ”ê°€)",
  "why_they_do": "ë™ê¸° (ì™œ ê·¸ë ‡ê²Œ í•œë‹¤ê³  ë³´ëŠ”ê°€)",
  "how_it_works": "ë©”ì»¤ë‹ˆì¦˜ (ì–´ë–»ê²Œ ì‘ë™í•œë‹¤ê³  ë³´ëŠ”ê°€)",
  "where_it_leads": "ê²°ê³¼ (ì–´ë””ë¡œ í–¥í•œë‹¤ê³  ë³´ëŠ”ê°€)"
}}

JSONìœ¼ë¡œ ì‘ë‹µ:
"""

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are an expert in discourse analysis. Always respond in valid JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            response_format={"type": "json_object"}
        )

        template = json.loads(response.choices[0].message.content)
        templates.append({
            'id': lp['id'],
            'title': lp['title'],
            'template': template
        })

    print(f"\nâœ… {len(templates)}ê°œ í…œí”Œë¦¿ ìƒì„±")

    for i, t in enumerate(templates, 1):
        print(f"\ní…œí”Œë¦¿ {i}: {t['title'][:60]}")
        print(f"  Who: {t['template'].get('who', 'N/A')}")
        print(f"  What: {t['template'].get('what_they_do', 'N/A')[:80]}")

    # Step 2: í…œí”Œë¦¿ ìœ ì‚¬ë„ ê³„ì‚° (who ê¸°ì¤€)
    who_groups = {}
    for t in templates:
        who = t['template'].get('who', 'unknown')
        if who not in who_groups:
            who_groups[who] = []
        who_groups[who].append(t)

    print(f"\n{len(who_groups)}ê°œ ê·¸ë£¹ (who ê¸°ì¤€)")

    # í‰ê°€
    print("\nğŸ“Š í‰ê°€:")
    print("  ì¥ì : êµ¬ì¡°í™”ë˜ì–´ ì´í•´ ì‰¬ì›€, ì„¹ì…˜ë³„ ë¹„êµ ê°€ëŠ¥")
    print("  ë‹¨ì : GPT í˜¸ì¶œ ë§ìŒ, í…œí”Œë¦¿ ì •ì˜ í•„ìš”")

    return {
        'method': 'structured_template',
        'groups': len(who_groups),
        'explainable': True,
        'gpt_calls': len(samples)
    }


async def method3_narrative_metadata(samples):
    """
    ë°©ë²• 3: Narrative + Metadata Hybrid

    - GPTë¡œ ìì—°ì–´ ì„œìˆ  + ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    - narrativeëŠ” ì‚¬ëŒì´ ì½ê¸° ìœ„í•¨
    - metadataëŠ” ìë™ ë¶„ë¥˜ìš©
    """
    print("\n" + "="*70)
    print("ë°©ë²• 3: Narrative + Metadata Hybrid")
    print("="*70)

    # Step 1: ì „ì²´ ìƒ˜í”Œì„ ë³´ê³  ì„¸ê³„ê´€ ì¶”ì¶œ

    # ëŒ€í‘œ ìƒ˜í”Œ ìˆ˜ì§‘
    belief_summary = []
    for lp in samples[:10]:
        belief_summary.append({
            'title': lp['title'],
            'deep_beliefs': lp.get('deep_beliefs', [])[:2],
            'worldview_hints': lp.get('worldview_hints', '')
        })

    prompt = f"""
ë‹¤ìŒì€ DC Gallery ê¸€ {len(belief_summary)}ê°œì˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.

{json.dumps(belief_summary, ensure_ascii=False, indent=2)}

ì´ ì¤‘ì—ì„œ **ì£¼ìš” ì„¸ê³„ê´€ 3-5ê°œ**ë¥¼ ì¶”ì¶œí•˜ê³ , ê° ì„¸ê³„ê´€ì„:

1. **Narrative** (ìì—°ì–´ ì„œìˆ  - ì—¬ë‹¹ ì§€ì§€ìê°€ ì½ê³  ì´í•´í•  ìˆ˜ ìˆê²Œ)
2. **Metadata** (í‚¤ì›Œë“œ, íŒ¨í„´ - ì‹œìŠ¤í…œì´ ë¶„ë¥˜ì— ì‚¬ìš©)

ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”.

JSON í˜•ì‹:
{{
  "worldviews": [
    {{
      "title": "ì„¸ê³„ê´€ ì œëª©",
      "narrative": {{
        "summary": "í•œ ì¤„ ìš”ì•½",
        "full_description": "ìì„¸í•œ ì„¤ëª… (200ì ì´ìƒ)",
        "example_interpretation": "êµ¬ì²´ì  í•´ì„ ì˜ˆì‹œ"
      }},
      "metadata": {{
        "subjects": ["ì£¼ì²´1", "ì£¼ì²´2"],
        "key_concepts": ["ê°œë…1", "ê°œë…2"],
        "logic_pattern": "ë…¼ë¦¬ íŒ¨í„´",
        "emotions": ["ê°ì •1", "ê°ì •2"]
      }}
    }}
  ]
}}
"""

    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are an expert in political discourse analysis. Always respond in valid JSON."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)
    worldviews = result.get('worldviews', [])

    print(f"\nâœ… {len(worldviews)}ê°œ ì„¸ê³„ê´€ ì¶”ì¶œ")

    for i, wv in enumerate(worldviews, 1):
        print(f"\nì„¸ê³„ê´€ {i}: {wv['title']}")
        print(f"  ìš”ì•½: {wv['narrative']['summary']}")
        print(f"  ì£¼ì²´: {', '.join(wv['metadata']['subjects'])}")
        print(f"  ê°œë…: {', '.join(wv['metadata']['key_concepts'][:3])}")

    # Step 2: ê° perceptionì„ ì„¸ê³„ê´€ì— ë§¤ì¹­
    print(f"\n\në§¤ì¹­ ì‹œë®¬ë ˆì´ì…˜ (ìƒ˜í”Œ 5ê°œ):")

    for lp in samples[:5]:
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        lp_text = ' '.join(lp.get('deep_beliefs', []))

        best_match = None
        best_score = 0

        for wv in worldviews:
            score = 0
            for subject in wv['metadata']['subjects']:
                if subject in lp_text:
                    score += 1
            for concept in wv['metadata']['key_concepts']:
                if concept in lp_text:
                    score += 0.5

            if score > best_score:
                best_score = score
                best_match = wv['title']

        print(f"\n  '{lp['title'][:50]}...'")
        print(f"    â†’ {best_match} (score: {best_score:.1f})")

    # í‰ê°€
    print("\nğŸ“Š í‰ê°€:")
    print("  ì¥ì : ì´í•´ ì‰¬ì›€ + ìë™ ë¶„ë¥˜ ê°€ëŠ¥, ìœ ì—°í•¨")
    print("  ë‹¨ì : ë³µì¡í•¨, GPT í˜¸ì¶œ í•„ìš”")

    return {
        'method': 'narrative_metadata',
        'worldviews': len(worldviews),
        'explainable': True,
        'flexible': True,
        'gpt_calls': 1,  # í•œ ë²ˆë§Œ í˜¸ì¶œ
        'worldviews_data': worldviews
    }


async def main():
    print("="*70)
    print("ì„¸ê³„ê´€ êµ¬ì„± ë°©ì‹ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸")
    print("="*70)

    # ì‹¤ì œ ë°ì´í„° ë¡œë“œ
    print("\nì‹¤ì œ layered_perceptions ë°ì´í„° ë¡œë“œ ì¤‘...")
    samples = await fetch_sample_data(limit=20)
    print(f"âœ… {len(samples)}ê°œ ìƒ˜í”Œ ë¡œë“œ ì™„ë£Œ")

    # 3ê°€ì§€ ë°©ì‹ ì‹œë®¬ë ˆì´ì…˜
    results = []

    result1 = await method1_vector_only(samples)
    results.append(result1)

    result2 = await method2_structured_template(samples)
    results.append(result2)

    result3 = await method3_narrative_metadata(samples)
    results.append(result3)

    # ìµœì¢… ë¹„êµ
    print("\n" + "="*70)
    print("ìµœì¢… ë¹„êµ")
    print("="*70)

    print("\n| ë°©ì‹ | ì„¤ëª…ê°€ëŠ¥ì„± | GPT í˜¸ì¶œ | ì´í•´ ìš©ì´ì„± | ìë™í™” |")
    print("|------|-----------|----------|------------|--------|")
    print(f"| ë°©ë²• 1 | {'âŒ' if not result1['explainable'] else 'âœ…'} | 0 | âš ï¸  | âœ… |")
    print(f"| ë°©ë²• 2 | {'âœ…' if result2['explainable'] else 'âŒ'} | {result2['gpt_calls']} | âœ… | âš ï¸  |")
    print(f"| ë°©ë²• 3 | {'âœ…' if result3['explainable'] else 'âŒ'} | {result3['gpt_calls']} | âœ…âœ… | âœ… |")

    print("\nğŸ† ì¶”ì²œ: ë°©ë²• 3 (Narrative + Metadata)")
    print("\nì´ìœ :")
    print("  1. í•œ ë²ˆì˜ GPT í˜¸ì¶œë¡œ ì „ì²´ ì„¸ê³„ê´€ ì¶”ì¶œ")
    print("  2. Narrativeë¡œ ì‚¬ëŒì´ ì™„ì „íˆ ì´í•´ ê°€ëŠ¥")
    print("  3. Metadataë¡œ ìë™ ë¶„ë¥˜ ê°€ëŠ¥")
    print("  4. ìœ ì—°í•˜ê²Œ í™•ì¥ ê°€ëŠ¥")

    # ë°©ë²• 3ì˜ ì‹¤ì œ ê²°ê³¼ ìƒì„¸ ì¶œë ¥
    if result3.get('worldviews_data'):
        print("\n" + "="*70)
        print("ë°©ë²• 3 ì‹¤ì œ ì¶”ì¶œ ê²°ê³¼ (ìƒì„¸)")
        print("="*70)

        for i, wv in enumerate(result3['worldviews_data'], 1):
            print(f"\n{'â”€'*70}")
            print(f"ì„¸ê³„ê´€ {i}: {wv['title']}")
            print(f"{'â”€'*70}")
            print(f"\nğŸ“– Narrative:")
            print(f"  ìš”ì•½: {wv['narrative']['summary']}")
            print(f"\n  ìƒì„¸:\n  {wv['narrative']['full_description']}")
            print(f"\n  í•´ì„ ì˜ˆì‹œ:\n  {wv['narrative']['example_interpretation']}")

            print(f"\nğŸ·ï¸  Metadata:")
            print(f"  ì£¼ì²´: {', '.join(wv['metadata']['subjects'])}")
            print(f"  í•µì‹¬ ê°œë…: {', '.join(wv['metadata']['key_concepts'])}")
            print(f"  ë…¼ë¦¬ íŒ¨í„´: {wv['metadata']['logic_pattern']}")
            print(f"  ê°ì •: {', '.join(wv['metadata']['emotions'])}")

if __name__ == '__main__':
    asyncio.run(main())
