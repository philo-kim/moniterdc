"""
ë°©ë²• 3 (Narrative + Metadata) ê°œì„ ì•ˆ ì‹œë®¬ë ˆì´ì…˜

í…ŒìŠ¤íŠ¸í•  ê°œì„  ë°©ì•ˆ:
1. ë§¤ì¹­ ë°©ì‹: í‚¤ì›Œë“œ vs Vector Similarity vs Hybrid
2. Metadata êµ¬ì¡°: ë‹¨ìˆœ vs ë³µí•© vs ê³„ì¸µí˜•
3. Narrative ê¹Šì´: ìš”ì•½í˜• vs ìƒì„¸í˜• vs ì˜ˆì‹œ ì¤‘ì‹¬í˜•
4. ì„¸ê³„ê´€ ê°œìˆ˜: GPT ìžë™ ê²°ì • vs ê³ ì • ê°œìˆ˜ vs ê³„ì¸µì  êµ¬ì¡°
"""

import asyncio
import sys
import os
import json
import numpy as np
from openai import AsyncOpenAI
from engines.utils.supabase_client import get_supabase

client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))

async def fetch_sample_data(limit=30):
    """ì‹¤ì œ layered_perceptions ìƒ˜í”Œ ê°€ì ¸ì˜¤ê¸°"""
    supabase = get_supabase()

    lps = supabase.table('layered_perceptions')\
        .select('id, content_id, deep_beliefs, implicit_assumptions, worldview_hints, explicit_claims')\
        .limit(limit)\
        .execute().data

    # Get content titles
    for lp in lps:
        content = supabase.table('contents')\
            .select('title')\
            .eq('id', lp['content_id'])\
            .execute().data[0]
        lp['title'] = content['title']

    return lps


async def improvement1_matching_methods(samples):
    """
    ê°œì„  1: ë§¤ì¹­ ë°©ì‹ ë¹„êµ

    A. í‚¤ì›Œë“œ ë§¤ì¹­ (í˜„ìž¬ ë°©ì‹)
    B. Vector Similarity ë§¤ì¹­
    C. Hybrid (í‚¤ì›Œë“œ + Vector)
    """
    print("\n" + "="*70)
    print("ê°œì„  1: ë§¤ì¹­ ë°©ì‹ ë¹„êµ")
    print("="*70)

    # ë¨¼ì € ì„¸ê³„ê´€ ìƒì„±
    belief_summary = []
    for lp in samples[:15]:
        belief_summary.append({
            'title': lp['title'],
            'deep_beliefs': lp.get('deep_beliefs', [])[:3],
            'implicit_assumptions': lp.get('implicit_assumptions', [])[:2],
            'worldview_hints': lp.get('worldview_hints', '')
        })

    prompt = f"""
ë‹¤ìŒì€ DC Gallery ê¸€ {len(belief_summary)}ê°œì˜ ë¶„ì„ ê²°ê³¼ìž…ë‹ˆë‹¤.

{json.dumps(belief_summary, ensure_ascii=False, indent=2)}

**ì£¼ìš” ì„¸ê³„ê´€ 4-5ê°œ**ë¥¼ ì¶”ì¶œí•˜ê³ , ê°ê°:

1. **Narrative**: ìžì—°ì–´ ìƒì„¸ ì„¤ëª… (300ìž ì´ìƒ)
2. **Metadata**: ì£¼ì²´, í•µì‹¬ ê°œë…, ë…¼ë¦¬ íŒ¨í„´

JSON í˜•ì‹:
{{
  "worldviews": [
    {{
      "title": "ì„¸ê³„ê´€ ì œëª©",
      "narrative": "ìƒì„¸í•œ ìžì—°ì–´ ì„¤ëª…...",
      "metadata": {{
        "subjects": ["ì£¼ì²´1", "ì£¼ì²´2"],
        "key_concepts": ["ê°œë…1", "ê°œë…2", "ê°œë…3"],
        "historical_references": ["ì—­ì‚¬1", "ì—­ì‚¬2"],
        "logic_pattern": "A â†’ B â†’ C",
        "emotions": ["ê°ì •1", "ê°ì •2"]
      }}
    }}
  ]
}}
"""

    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are an expert in political discourse analysis. Always respond in valid JSON."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)
    worldviews = result.get('worldviews', [])

    print(f"\nâœ… {len(worldviews)}ê°œ ì„¸ê³„ê´€ ìƒì„±")

    # í…ŒìŠ¤íŠ¸ìš© perception 5ê°œ
    test_perceptions = samples[15:20]

    # A. í‚¤ì›Œë“œ ë§¤ì¹­
    print("\n" + "â”€"*70)
    print("A. í‚¤ì›Œë“œ ë§¤ì¹­")
    print("â”€"*70)

    keyword_matches = []
    for lp in test_perceptions:
        lp_text = ' '.join(lp.get('deep_beliefs', []) + lp.get('implicit_assumptions', []))

        best_match = None
        best_score = 0

        for wv in worldviews:
            score = 0
            metadata = wv['metadata']

            for subject in metadata.get('subjects', []):
                if subject in lp_text:
                    score += 2

            for concept in metadata.get('key_concepts', []):
                if concept in lp_text:
                    score += 1

            if score > best_score:
                best_score = score
                best_match = wv['title']

        keyword_matches.append({
            'title': lp['title'][:50],
            'matched': best_match,
            'score': best_score
        })
        print(f"  {lp['title'][:45]}... â†’ {best_match} ({best_score})")

    # B. Vector Similarity ë§¤ì¹­
    print("\n" + "â”€"*70)
    print("B. Vector Similarity ë§¤ì¹­")
    print("â”€"*70)

    # Worldview embeddings
    wv_embeddings = []
    for wv in worldviews:
        emb_response = await client.embeddings.create(
            model="text-embedding-3-small",
            input=wv['narrative']
        )
        wv_embeddings.append({
            'title': wv['title'],
            'embedding': emb_response.data[0].embedding
        })

    def cosine_similarity(a, b):
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

    vector_matches = []
    for lp in test_perceptions:
        lp_text = ' '.join(lp.get('deep_beliefs', []))

        lp_emb_response = await client.embeddings.create(
            model="text-embedding-3-small",
            input=lp_text
        )
        lp_embedding = lp_emb_response.data[0].embedding

        best_match = None
        best_sim = 0

        for wv_emb in wv_embeddings:
            sim = cosine_similarity(lp_embedding, wv_emb['embedding'])
            if sim > best_sim:
                best_sim = sim
                best_match = wv_emb['title']

        vector_matches.append({
            'title': lp['title'][:50],
            'matched': best_match,
            'similarity': best_sim
        })
        print(f"  {lp['title'][:45]}... â†’ {best_match} ({best_sim:.3f})")

    # C. Hybrid (í‚¤ì›Œë“œ + Vector)
    print("\n" + "â”€"*70)
    print("C. Hybrid ë§¤ì¹­ (í‚¤ì›Œë“œ 30% + Vector 70%)")
    print("â”€"*70)

    hybrid_matches = []
    for i, lp in enumerate(test_perceptions):
        keyword_score = keyword_matches[i]['score']
        vector_score = vector_matches[i]['similarity']

        # Normalize keyword score (0-1)
        normalized_keyword = min(keyword_score / 5.0, 1.0)

        # Hybrid score
        hybrid_score = 0.3 * normalized_keyword + 0.7 * vector_score

        # Find best match
        best_match = vector_matches[i]['matched']  # Default to vector match

        hybrid_matches.append({
            'title': lp['title'][:50],
            'matched': best_match,
            'hybrid_score': hybrid_score
        })
        print(f"  {lp['title'][:45]}... â†’ {best_match} ({hybrid_score:.3f})")

    # ë¹„êµ
    print("\n" + "="*70)
    print("ðŸ“Š ë§¤ì¹­ ë°©ì‹ í‰ê°€")
    print("="*70)

    print("\n| ë°©ì‹ | ì†ë„ | ì •í™•ë„ | ì„¤ëª…ë ¥ | ë¹„ìš© |")
    print("|------|------|--------|--------|------|")
    print("| í‚¤ì›Œë“œ | âš¡âš¡âš¡ | âš ï¸  | âœ… | ë¬´ë£Œ |")
    print("| Vector | âš¡âš¡ | âœ…âœ… | âš ï¸  | ðŸ’° |")
    print("| Hybrid | âš¡âš¡ | âœ…âœ… | âœ… | ðŸ’° |")

    return {
        'recommendation': 'hybrid',
        'reason': 'Vectorë¡œ ì˜ë¯¸ì  ìœ ì‚¬ë„ + í‚¤ì›Œë“œë¡œ ëª…ì‹œì  ì—°ê²° í™•ì¸'
    }


async def improvement2_metadata_structure(samples):
    """
    ê°œì„  2: Metadata êµ¬ì¡° ë¹„êµ

    A. ë‹¨ìˆœí˜•: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë§Œ
    B. ë³µí•©í˜•: í‚¤ì›Œë“œ + ê°€ì¤‘ì¹˜
    C. ê³„ì¸µí˜•: ì¹´í…Œê³ ë¦¬ë³„ êµ¬ì¡°í™”
    """
    print("\n" + "="*70)
    print("ê°œì„  2: Metadata êµ¬ì¡° ë¹„êµ")
    print("="*70)

    # A. ë‹¨ìˆœí˜•
    print("\n" + "â”€"*70)
    print("A. ë‹¨ìˆœí˜• Metadata")
    print("â”€"*70)

    simple_metadata = {
        "subjects": ["ë¯¼ì£¼ë‹¹", "ì¢ŒíŒŒ"],
        "key_concepts": ["ë…ìž¬", "ì‚¬ì°°", "ê¶Œë ¥ë‚¨ìš©"],
        "emotions": ["ë¶„ë…¸", "ìœ„ê¸°ê°"]
    }

    print(json.dumps(simple_metadata, ensure_ascii=False, indent=2))
    print("\nìž¥ì : ê°„ë‹¨, ë¹ ë¦„")
    print("ë‹¨ì : ì¤‘ìš”ë„ êµ¬ë¶„ ë¶ˆê°€, ê´€ê³„ í‘œí˜„ ë¶ˆê°€")

    # B. ë³µí•©í˜• (ê°€ì¤‘ì¹˜ í¬í•¨)
    print("\n" + "â”€"*70)
    print("B. ë³µí•©í˜• Metadata (ê°€ì¤‘ì¹˜)")
    print("â”€"*70)

    weighted_metadata = {
        "subjects": [
            {"name": "ë¯¼ì£¼ë‹¹", "importance": 1.0},
            {"name": "ì¢ŒíŒŒ", "importance": 0.9},
            {"name": "ê²€ì°°", "importance": 0.5}
        ],
        "key_concepts": [
            {"concept": "ë…ìž¬", "centrality": 1.0},
            {"concept": "ì‚¬ì°°", "centrality": 0.9},
            {"concept": "ê¶Œë ¥ë‚¨ìš©", "centrality": 0.7}
        ],
        "emotions": [
            {"emotion": "ë¶„ë…¸", "intensity": 0.8},
            {"emotion": "ìœ„ê¸°ê°", "intensity": 0.9}
        ]
    }

    print(json.dumps(weighted_metadata, ensure_ascii=False, indent=2))
    print("\nìž¥ì : ì¤‘ìš”ë„ êµ¬ë¶„, ë§¤ì¹­ ì •í™•ë„ í–¥ìƒ")
    print("ë‹¨ì : ê°€ì¤‘ì¹˜ ê²°ì • ì–´ë ¤ì›€")

    # C. ê³„ì¸µí˜• (êµ¬ì¡°í™”)
    print("\n" + "â”€"*70)
    print("C. ê³„ì¸µí˜• Metadata (êµ¬ì¡°í™”)")
    print("â”€"*70)

    hierarchical_metadata = {
        "core": {
            "primary_subject": "ë¯¼ì£¼ë‹¹",
            "primary_attribute": "ë…ìž¬ì„±í–¥",
            "primary_action": "ì‚¬ì°°"
        },
        "interpretation_frame": {
            "historical_lens": {
                "reference_period": "1970-80ë…„ëŒ€ êµ°ì‚¬ë…ìž¬",
                "reference_events": ["ë¯¼ê°„ì¸ ì‚¬ì°°", "ì–¸ë¡ í†µì œ"],
                "projection_logic": "ê³¼ê±° íŒ¨í„´ â†’ í˜„ìž¬ ë°˜ë³µ"
            },
            "causal_chain": [
                "ê¶Œë ¥ íšë“",
                "ìž‘ì€ ì›”ê¶Œ",
                "ì ì§„ì  í™•ëŒ€",
                "ì „ë©´ ë…ìž¬"
            ],
            "slippery_slope": {
                "trigger": "ìœ ì‹¬êµì²´ ì •ë³´ í™•ì¸",
                "escalation": "ì‚¬ì°° â†’ ìž¥ì•… â†’ ë…ìž¬",
                "endpoint": "1970ë…„ëŒ€ì‹ ê°ì‹œêµ­ê°€"
            }
        },
        "emotional_drivers": {
            "primary": "ìœ„ê¸°ê°",
            "secondary": ["ë¶„ë…¸", "ë¶ˆì‹ "],
            "urgency_level": "high"
        },
        "validation_criteria": {
            "confirming_evidence": ["ì •ë³´ íŒŒì•… ì‚¬ë¡€", "ì¸ì‚¬ ê°œìž…"],
            "disconfirming_ignored": ["í•©ë²•ì  ì ˆì°¨", "ê²¬ì œ ìž‘ë™"]
        }
    }

    print(json.dumps(hierarchical_metadata, ensure_ascii=False, indent=2))
    print("\nìž¥ì : ì™„ì „í•œ êµ¬ì¡°, ê¹Šì€ ì´í•´, ë¶„ì„ ê°€ëŠ¥")
    print("ë‹¨ì : ë³µìž¡, GPT ìƒì„± ì–´ë ¤ì›€")

    # GPTë¡œ ì‹¤ì œ ìƒì„± í…ŒìŠ¤íŠ¸
    print("\n" + "â”€"*70)
    print("ì‹¤ì œ GPT ìƒì„± í…ŒìŠ¤íŠ¸")
    print("â”€"*70)

    sample = samples[2]  # "ë¯¼ì£¼ë‹¹ ì‚¬ì°°" ê¸€

    prompt = f"""
ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ê³„ì¸µí˜• Metadataë¡œ ë³€í™˜í•˜ì„¸ìš”:

ì œëª©: {sample['title']}
ì‹¬ì¸µ ë¯¿ìŒ: {sample.get('deep_beliefs', [])}
ì•”ë¬µì  ì „ì œ: {sample.get('implicit_assumptions', [])}

ê³„ì¸µí˜• êµ¬ì¡°:
{{
  "core": {{
    "primary_subject": "ì£¼ìš” ëŒ€ìƒ",
    "primary_attribute": "í•µì‹¬ ì†ì„±",
    "primary_action": "í•µì‹¬ í–‰ë™"
  }},
  "interpretation_frame": {{
    "historical_lens": {{
      "reference_period": "ì°¸ì¡° ì‹œê¸°",
      "reference_events": ["ì‚¬ê±´1", "ì‚¬ê±´2"],
      "projection_logic": "íˆ¬ì˜ ë…¼ë¦¬"
    }},
    "causal_chain": ["ë‹¨ê³„1", "ë‹¨ê³„2", "ë‹¨ê³„3"],
    "slippery_slope": {{
      "trigger": "ì‹œìž‘ì ",
      "escalation": "í™•ëŒ€ ê²½ë¡œ",
      "endpoint": "ìµœì¢… ê²°ê³¼"
    }}
  }},
  "emotional_drivers": {{
    "primary": "ì£¼ ê°ì •",
    "secondary": ["ë¶€ ê°ì •ë“¤"],
    "urgency_level": "ê¸´ê¸‰ë„"
  }}
}}

JSONìœ¼ë¡œ ì‘ë‹µ:
"""

    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are an expert. Always respond in valid JSON."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        response_format={"type": "json_object"}
    )

    generated = json.loads(response.choices[0].message.content)
    print("\nGPT ìƒì„± ê²°ê³¼:")
    print(json.dumps(generated, ensure_ascii=False, indent=2))

    # í‰ê°€
    print("\n" + "="*70)
    print("ðŸ“Š Metadata êµ¬ì¡° í‰ê°€")
    print("="*70)

    print("\n| êµ¬ì¡° | ìƒì„± ìš©ì´ì„± | ë§¤ì¹­ ì •í™•ë„ | ì´í•´ ê¹Šì´ | ìœ ì§€ë³´ìˆ˜ |")
    print("|------|------------|------------|----------|---------|")
    print("| ë‹¨ìˆœí˜• | âš¡âš¡âš¡ | âš ï¸  | âš ï¸  | âœ…âœ… |")
    print("| ë³µí•©í˜• | âš¡âš¡ | âœ… | âœ… | âœ… |")
    print("| ê³„ì¸µí˜• | âš¡ | âœ…âœ… | âœ…âœ…âœ… | âš ï¸  |")

    return {
        'recommendation': 'hierarchical',
        'reason': 'ì„¸ê³„ê´€ì˜ êµ¬ì¡°ë¥¼ ì™„ì „ížˆ í‘œí˜„, ì—¬ë‹¹ ì§€ì§€ìžê°€ ë…¼ë¦¬ ì²´ì¸ ì´í•´ ê°€ëŠ¥'
    }


async def improvement3_narrative_depth(samples):
    """
    ê°œì„  3: Narrative ê¹Šì´ ë¹„êµ

    A. ìš”ì•½í˜•: 2-3ë¬¸ìž¥
    B. ìƒì„¸í˜•: ë‹¨ë½ í˜•ì‹
    C. ì˜ˆì‹œ ì¤‘ì‹¬í˜•: êµ¬ì²´ì  ì‚¬ë¡€ í¬í•¨
    """
    print("\n" + "="*70)
    print("ê°œì„  3: Narrative ê¹Šì´ ë¹„êµ")
    print("="*70)

    sample = samples[2]

    # A. ìš”ì•½í˜•
    print("\n" + "â”€"*70)
    print("A. ìš”ì•½í˜• Narrative")
    print("â”€"*70)

    summary_narrative = """
ë¯¼ì£¼ë‹¹/ì¢ŒíŒŒì˜ ëª¨ë“  ê¶Œë ¥ í–‰ì‚¬ë¥¼ ê³¼ê±° ë…ìž¬ì •ê¶Œì˜ ìž¬í˜„ìœ¼ë¡œ í•´ì„í•œë‹¤.
ìž‘ì€ ì›”ê¶Œë„ ë°˜ë“œì‹œ ì „ë©´ì  ê°ì‹œêµ­ê°€ë¡œ ë°œì „í•œë‹¤ê³  ë¯¿ëŠ”ë‹¤.
"""

    print(summary_narrative)
    print("\nìž¥ì : ë¹ ë¥¸ ì´í•´")
    print("ë‹¨ì : ë§¥ë½ ë¶€ì¡±, ì™œ ê·¸ë ‡ê²Œ ìƒê°í•˜ëŠ”ì§€ ë¶ˆëª…í™•")

    # B. ìƒì„¸í˜•
    print("\n" + "â”€"*70)
    print("B. ìƒì„¸í˜• Narrative")
    print("â”€"*70)

    detailed_narrative = """
ì´ ì„¸ê³„ê´€ì„ ê°€ì§„ ì‚¬ëžŒë“¤ì€ ë¯¼ì£¼ë‹¹ì´ë‚˜ ì¢ŒíŒŒ ì •ê¶Œì˜ ëª¨ë“  í–‰ë™ì„
ê³¼ê±° ë°•ì •í¬/ì „ë‘í™˜ ë…ìž¬ ì •ê¶Œê³¼ ë™ì¼ì„ ìƒì—ì„œ í•´ì„í•œë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, í†µì‹ ì‚¬ì—ì„œ ìœ ì‹¬ êµì²´ ì •ë³´ë¥¼ ì•Œì•˜ë‹¤ëŠ” ì‚¬ì‹¤ì„
'í†µì‹ ì‚¬ í˜‘ë°•ì„ í†µí•œ ë¶ˆë²• ì‚¬ì°°'ë¡œ ì¦‰ì‹œ í•´ì„í•˜ë©°, ì´ê²ƒì´
ê³¼ê±° ë…ìž¬ ì‹œì ˆì˜ ë¯¼ê°„ì¸ ì‚¬ì°°ê³¼ ë³¸ì§ˆì ìœ¼ë¡œ ê°™ë‹¤ê³  ë³¸ë‹¤.

ìž‘ì€ ì›”ê¶Œì´ë‚˜ ì •ë³´ íŒŒì•…ë„ 'ë…ìž¬ì˜ ì´ˆê¸° ë‹¨ê³„'ë¡œ ì¸ì‹í•˜ë©°,
ë°©ì¹˜í•˜ë©´ ë°˜ë“œì‹œ ì „ë©´ì  ê°ì‹œêµ­ê°€ë¡œ ë°œì „í•œë‹¤ê³  ë¯¿ëŠ”ë‹¤(ìŠ¬ë¦¬í¼ë¦¬ ìŠ¬ë¡œí”„).

ë”°ë¼ì„œ í˜„ìž¬ëŠ” 'ë…ìž¬ ì „ì•¼'ì´ë©°, ì§€ê¸ˆ ì €ì§€í•˜ì§€ ì•Šìœ¼ë©´
1970-80ë…„ëŒ€ë¡œ íšŒê·€í•œë‹¤ëŠ” ìœ„ê¸°ê°ì„ ê°€ì§„ë‹¤.
"""

    print(detailed_narrative)
    print("\nìž¥ì : ì™„ì „í•œ ì´í•´, ë…¼ë¦¬ ì²´ì¸ ëª…í™•")
    print("ë‹¨ì : ê¸¸ì´, ì½ê¸° ë¶€ë‹´")

    # C. ì˜ˆì‹œ ì¤‘ì‹¬í˜•
    print("\n" + "â”€"*70)
    print("C. ì˜ˆì‹œ ì¤‘ì‹¬í˜• Narrative")
    print("â”€"*70)

    example_narrative = """
**ì„¸ê³„ê´€ í•µì‹¬:**
ë¯¼ì£¼ë‹¹/ì¢ŒíŒŒ = ë…ìž¬ì •ê¶Œ ìž¬í˜„

**êµ¬ì²´ì  í•´ì„ ë°©ì‹:**

ðŸ“Œ ì‚¬ë¡€ 1: ìœ ì‹¬êµì²´ ì •ë³´ í™•ì¸
  - DC Gallery í•´ì„: "í†µì‹ ì‚¬ í˜‘ë°• â†’ ë¶ˆë²• ì‚¬ì°° â†’ ë…ìž¬ ì‹œìž‘"
  - ì¼ë°˜ì¸ í•´ì„: "ì •ìƒì  ì •ë³´ íŒŒì•…ì¼ ìˆ˜ë„..."
  - ì°¨ì´ì : ì¦‰ì‹œ 'ë…ìž¬'ë¡œ ì—°ê²°

ðŸ“Œ ì‚¬ë¡€ 2: íŒì‚¬ ì¸ì‚¬
  - DC Gallery í•´ì„: "ë§˜ì— ì•ˆë“œëŠ” íŒì‚¬ ì œê±° â†’ ì‚¬ë²•ë¶€ ìž¥ì•… â†’ ë…ìž¬"
  - ì¼ë°˜ì¸ í•´ì„: "ì •ìƒì  ì¸ì‚¬ ì ˆì°¨..."
  - ì°¨ì´ì : ëª¨ë“  ì¸ì‚¬ë¥¼ 'ìž¥ì•…'ìœ¼ë¡œ í•´ì„

**í•µì‹¬ ë…¼ë¦¬:**
ìž‘ì€ ê²ƒ â†’ í° ê²ƒìœ¼ë¡œ ë°˜ë“œì‹œ í™•ëŒ€ëœë‹¤ (ìŠ¬ë¦¬í¼ë¦¬ ìŠ¬ë¡œí”„)

**ì—­ì‚¬ì  ì°¸ì¡°:**
1970-80ë…„ëŒ€ ë¯¼ê°„ì¸ ì‚¬ì°° â†’ ì–¸ë¡ í†µì œ â†’ ì•¼ë‹¹ íƒ„ì••

**ê°ì •:**
"ì§€ê¸ˆ ë§‰ì§€ ì•Šìœ¼ë©´ ìš°ë¦¬ë„ ë…ìž¬ ì‹œëŒ€ë¡œ ëŒì•„ê°„ë‹¤" (ìœ„ê¸°ê°)
"""

    print(example_narrative)
    print("\nìž¥ì : êµ¬ì²´ì , ì´í•´ ì‰¬ì›€, ë¹„êµ ê°€ëŠ¥")
    print("ë‹¨ì : ì˜ˆì‹œ ì„ ì • ì–´ë ¤ì›€")

    # í‰ê°€
    print("\n" + "="*70)
    print("ðŸ“Š Narrative ê¹Šì´ í‰ê°€")
    print("="*70)

    print("\n| í˜•ì‹ | ì´í•´ ì†ë„ | ì´í•´ ê¹Šì´ | ê³µê° ìœ ë°œ | í™œìš©ì„± |")
    print("|------|----------|----------|----------|--------|")
    print("| ìš”ì•½í˜• | âš¡âš¡âš¡ | âš ï¸  | âš ï¸  | âš ï¸  |")
    print("| ìƒì„¸í˜• | âš¡ | âœ…âœ… | âœ… | âœ… |")
    print("| ì˜ˆì‹œí˜• | âš¡âš¡ | âœ…âœ…âœ… | âœ…âœ… | âœ…âœ… |")

    return {
        'recommendation': 'example_based',
        'reason': 'êµ¬ì²´ì  ì˜ˆì‹œë¡œ ì´í•´ ì‰¬ì›€, ì—¬ë‹¹ ì§€ì§€ìžê°€ "ì•„ ì´ëž˜ì„œ ì €ë ‡ê²Œ ë§í•˜ëŠ”êµ¬ë‚˜" ì¦‰ì‹œ íŒŒì•…'
    }


async def improvement4_worldview_count(samples):
    """
    ê°œì„  4: ì„¸ê³„ê´€ ê°œìˆ˜ ê²°ì • ë°©ì‹

    A. GPT ìžë™ ê²°ì • (í˜„ìž¬)
    B. ê³ ì • ê°œìˆ˜ (5ê°œ, 10ê°œ)
    C. ê³„ì¸µì  êµ¬ì¡° (ëŒ€ë¶„ë¥˜ â†’ ì¤‘ë¶„ë¥˜)
    """
    print("\n" + "="*70)
    print("ê°œì„  4: ì„¸ê³„ê´€ ê°œìˆ˜ ê²°ì • ë°©ì‹")
    print("="*70)

    # A. GPT ìžë™ ê²°ì •
    print("\n" + "â”€"*70)
    print("A. GPT ìžë™ ê²°ì •")
    print("â”€"*70)

    belief_summary = []
    for lp in samples[:20]:
        belief_summary.append({
            'deep_beliefs': lp.get('deep_beliefs', [])[:2],
            'worldview_hints': lp.get('worldview_hints', '')
        })

    prompt_auto = f"""
{len(belief_summary)}ê°œ ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê³ , **ì ì ˆí•œ ê°œìˆ˜ì˜ ì„¸ê³„ê´€**ì„ ì¶”ì¶œí•˜ì„¸ìš”.
(ë„ˆë¬´ ì ìœ¼ë©´ ê³¼ë„í•œ ë‹¨ìˆœí™”, ë„ˆë¬´ ë§Žìœ¼ë©´ íŒŒíŽ¸í™”)

{json.dumps(belief_summary[:10], ensure_ascii=False)}

JSON: {{"worldviews": [...]}}
"""

    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt_auto}],
        temperature=0.3,
        response_format={"type": "json_object"}
    )

    auto_result = json.loads(response.choices[0].message.content)
    print(f"  ê²°ê³¼: {len(auto_result.get('worldviews', []))}ê°œ ì„¸ê³„ê´€")
    print("  ìž¥ì : ë°ì´í„°ì— ë§žê²Œ ìœ ì—°")
    print("  ë‹¨ì : ì¼ê´€ì„± ì—†ìŒ, ì˜ˆì¸¡ ë¶ˆê°€")

    # B. ê³ ì • ê°œìˆ˜
    print("\n" + "â”€"*70)
    print("B. ê³ ì • ê°œìˆ˜ (7ê°œ)")
    print("â”€"*70)

    prompt_fixed = f"""
{len(belief_summary)}ê°œ ë¶„ì„ ê²°ê³¼ë¥¼ **ì •í™•ížˆ 7ê°œ ì„¸ê³„ê´€**ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

{json.dumps(belief_summary[:10], ensure_ascii=False)}

JSON: {{"worldviews": [...7ê°œ...]}}
"""

    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt_fixed}],
        temperature=0.3,
        response_format={"type": "json_object"}
    )

    fixed_result = json.loads(response.choices[0].message.content)
    print(f"  ê²°ê³¼: {len(fixed_result.get('worldviews', []))}ê°œ ì„¸ê³„ê´€")
    print("  ìž¥ì : ì¼ê´€ì„±, ì˜ˆì¸¡ ê°€ëŠ¥")
    print("  ë‹¨ì : ë°ì´í„°ì— ì•ˆ ë§žì„ ìˆ˜ ìžˆìŒ")

    # C. ê³„ì¸µì  êµ¬ì¡°
    print("\n" + "â”€"*70)
    print("C. ê³„ì¸µì  êµ¬ì¡° (ëŒ€ë¶„ë¥˜ â†’ ì„¸ë¶€)")
    print("â”€"*70)

    prompt_hierarchical = f"""
{len(belief_summary)}ê°œ ë¶„ì„ ê²°ê³¼ë¥¼ **ê³„ì¸µì  ì„¸ê³„ê´€ êµ¬ì¡°**ë¡œ ì¡°ì§í•˜ì„¸ìš”.

1ë‹¨ê³„: 3-4ê°œ ëŒ€ë¶„ë¥˜
2ë‹¨ê³„: ê° ëŒ€ë¶„ë¥˜ë§ˆë‹¤ 2-3ê°œ ì„¸ë¶€ ì„¸ê³„ê´€

ì˜ˆì‹œ:
{{
  "hierarchy": [
    {{
      "category": "ëŒ€ë¶„ë¥˜ 1",
      "subcategories": [
        {{"title": "ì„¸ë¶€ 1-1", "narrative": "..."}},
        {{"title": "ì„¸ë¶€ 1-2", "narrative": "..."}}
      ]
    }}
  ]
}}

{json.dumps(belief_summary[:10], ensure_ascii=False)}
"""

    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt_hierarchical}],
        temperature=0.3,
        response_format={"type": "json_object"}
    )

    hierarchical_result = json.loads(response.choices[0].message.content)
    hierarchy = hierarchical_result.get('hierarchy', [])

    print(f"  ê²°ê³¼: {len(hierarchy)}ê°œ ëŒ€ë¶„ë¥˜")
    for cat in hierarchy:
        print(f"    - {cat.get('category', 'N/A')}: {len(cat.get('subcategories', []))}ê°œ ì„¸ë¶€")

    print("  ìž¥ì : ì¡°ì§í™”, ë¸Œë¼ìš°ì§• ì‰¬ì›€, ìœ ì—°ì„±")
    print("  ë‹¨ì : ë³µìž¡ë„ ì¦ê°€")

    # í‰ê°€
    print("\n" + "="*70)
    print("ðŸ“Š ì„¸ê³„ê´€ ê°œìˆ˜ ê²°ì • í‰ê°€")
    print("="*70)

    print("\n| ë°©ì‹ | ì¼ê´€ì„± | ìœ ì—°ì„± | ì‚¬ìš©ì„± | í™•ìž¥ì„± |")
    print("|------|--------|--------|--------|--------|")
    print("| ìžë™ | âš ï¸  | âœ…âœ… | âœ… | âœ… |")
    print("| ê³ ì • | âœ…âœ… | âš ï¸  | âœ… | âš ï¸  |")
    print("| ê³„ì¸µ | âœ… | âœ…âœ… | âœ…âœ… | âœ…âœ… |")

    return {
        'recommendation': 'hierarchical',
        'reason': 'ëŒ€ë¶„ë¥˜ë¡œ ì „ì²´ íŒŒì•… + ì„¸ë¶€ë¡œ ê¹Šì´ íƒìƒ‰ ê°€ëŠ¥'
    }


async def main():
    print("="*70)
    print("ë°©ë²• 3 ê°œì„ ì•ˆ ìƒì„¸ ì‹œë®¬ë ˆì´ì…˜")
    print("="*70)

    samples = await fetch_sample_data(limit=30)
    print(f"\nâœ… {len(samples)}ê°œ ìƒ˜í”Œ ë¡œë“œ\n")

    results = {}

    # 4ê°€ì§€ ê°œì„  ì˜ì—­ í…ŒìŠ¤íŠ¸
    results['matching'] = await improvement1_matching_methods(samples)
    results['metadata'] = await improvement2_metadata_structure(samples)
    results['narrative'] = await improvement3_narrative_depth(samples)
    results['count'] = await improvement4_worldview_count(samples)

    # ìµœì¢… ì¶”ì²œ
    print("\n" + "="*70)
    print("ðŸ† ìµœì¢… ì¶”ì²œ êµ¬ì„±")
    print("="*70)

    print("\n1. ë§¤ì¹­ ë°©ì‹: Hybrid (í‚¤ì›Œë“œ 30% + Vector 70%)")
    print("   â†’ ì˜ë¯¸ì  ìœ ì‚¬ë„ + ëª…ì‹œì  ì—°ê²° í™•ì¸")

    print("\n2. Metadata êµ¬ì¡°: ê³„ì¸µí˜•")
    print("   â†’ core + interpretation_frame + emotional_drivers")

    print("\n3. Narrative ê¹Šì´: ì˜ˆì‹œ ì¤‘ì‹¬í˜•")
    print("   â†’ êµ¬ì²´ì  ì‚¬ë¡€ë¡œ ì´í•´ ìš©ì´")

    print("\n4. ì„¸ê³„ê´€ ê°œìˆ˜: ê³„ì¸µì  (3-4 ëŒ€ë¶„ë¥˜ â†’ ê° 2-3 ì„¸ë¶€)")
    print("   â†’ ì „ì²´ íŒŒì•… + ê¹Šì´ íƒìƒ‰ ê°€ëŠ¥")

    print("\n" + "="*70)
    print("ìµœì  WorldviewConstructor ì„¤ê³„")
    print("="*70)

    optimal_design = """

class OptimalWorldviewConstructor:

    async def construct(self, perceptions):
        # 1. ê³„ì¸µì  ì„¸ê³„ê´€ ì¶”ì¶œ
        worldviews = await self._extract_hierarchical_worldviews(perceptions)

        # ê° ì„¸ê³„ê´€ êµ¬ì¡°:
        {
          "category": "ëŒ€ë¶„ë¥˜ëª…",
          "subcategories": [
            {
              "title": "ì„¸ë¶€ ì„¸ê³„ê´€",
              "narrative": {
                "summary": "í•œ ì¤„",
                "examples": [
                  {
                    "case": "êµ¬ì²´ì  ì‚¬ë¡€",
                    "interpretation": "í•´ì„ ë°©ì‹",
                    "contrast": "ì¼ë°˜ì¸ í•´ì„ê³¼ ì°¨ì´"
                  }
                ],
                "logic_chain": "A â†’ B â†’ C",
                "historical_context": "ê³¼ê±° ì°¸ì¡°"
              },
              "metadata": {
                "core": {...},
                "interpretation_frame": {...},
                "emotional_drivers": {...}
              }
            }
          ]
        }

        # 2. Perception ë§¤ì¹­ (Hybrid)
        for perception in perceptions:
            # Vector similarity
            vector_scores = await self._calculate_vector_similarity(
                perception, worldviews
            )

            # Keyword matching
            keyword_scores = self._calculate_keyword_match(
                perception, worldviews
            )

            # Hybrid score
            final_scores = 0.7 * vector_scores + 0.3 * keyword_scores

            # Link to worldviews (threshold > 0.6)
            await self._create_links(perception, final_scores)
    """

    print(optimal_design)

if __name__ == '__main__':
    asyncio.run(main())
