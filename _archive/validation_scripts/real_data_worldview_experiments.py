"""
ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë§ì¶˜ ì„¸ê³„ê´€ í‘œí˜„ ë°©ì‹ ì‹¤í—˜

ë°ì´í„° êµ¬ì¡°:
- perception: {subject, attribute, valence, claims[], keywords[], emotions[]}
- worldview: {title, frame, perception_ids[]}

ëª©í‘œ: ì–´ë–¤ ë°©ì‹ì´ "ì„¸ê³„ê´€ = ë Œì¦ˆ"ë¥¼ ê°€ì¥ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ”ê°€?
"""

import os
import json
import asyncio
from supabase import create_client
from openai import AsyncOpenAI
from collections import Counter
from typing import List, Dict, Any
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Setup
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_ANON_KEY")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

if not all([SUPABASE_URL, SUPABASE_KEY, OPENAI_API_KEY]):
    raise ValueError("Missing required environment variables. Please check your .env file.")

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)


def load_worldview_with_perceptions():
    """worldviewì™€ í•´ë‹¹í•˜ëŠ” ëª¨ë“  perception ë¡œë“œ"""
    print("ë°ì´í„° ë¡œë”© ì¤‘...")

    # worldview ì¤‘ "ë…ì¬ì™€ ì‚¬ì°°ì˜ ë¶€í™œ" ê°€ì ¸ì˜¤ê¸°
    wv_result = supabase.table('worldviews').select('*').eq('title', 'ë…ì¬ì™€ ì‚¬ì°°ì˜ ë¶€í™œ').execute()

    if not wv_result.data:
        print("worldviewë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        # ì²« ë²ˆì§¸ worldview ì‚¬ìš©
        wv_result = supabase.table('worldviews').select('*').limit(1).execute()

    worldview = wv_result.data[0] if wv_result.data else {}
    print(f"\nWorldview: {worldview.get('title', 'No title')}")
    print(f"ID: {worldview.get('id', 'No ID')}")

    # ì‹¤ì œ DBì— ìˆëŠ” ëª¨ë“  perception ê°€ì ¸ì˜¤ê¸° (perception_idsê°€ outdatedë¨)
    print("\nì „ì²´ perception ë¡œë“œ ì¤‘...")
    p_result = supabase.table('perceptions').select('*').execute()
    perceptions = p_result.data

    print(f"âœ“ Loaded {len(perceptions)} perceptions (ì „ì²´)")

    return worldview, perceptions


def analyze_perception_structure(perceptions):
    """ì‹¤ì œ perception ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
    print("\n" + "="*80)
    print("=== ë°ì´í„° êµ¬ì¡° ë¶„ì„ ===")
    print("="*80)

    all_subjects = []
    all_attributes = []
    all_valences = []
    all_keywords = []
    all_emotions = []
    all_claims = []

    for p in perceptions:
        all_subjects.append(p.get('perceived_subject', ''))
        all_attributes.append(p.get('perceived_attribute', ''))
        all_valences.append(p.get('perceived_valence', ''))
        all_keywords.extend(p.get('keywords', []))
        all_emotions.extend(p.get('emotions', []))
        all_claims.extend(p.get('claims', []))

    print(f"\nì´ perception: {len(perceptions)}ê°œ")
    print(f"ì´ claims: {len(all_claims)}ê°œ")
    print(f"ì´ keywords: {len(all_keywords)}ê°œ (ê³ ìœ : {len(set(all_keywords))})")
    print(f"ì´ emotions: {len(all_emotions)}ê°œ (ê³ ìœ : {len(set(all_emotions))})")

    print(f"\nì£¼ìš” ì£¼ì²´ Top 10:")
    for subject, count in Counter(all_subjects).most_common(10):
        if subject:
            print(f"  - {subject}: {count}íšŒ")

    print(f"\nì£¼ìš” ì†ì„± Top 10:")
    for attr, count in Counter(all_attributes).most_common(10):
        if attr:
            print(f"  - {attr}: {count}íšŒ")

    print(f"\nValence ë¶„í¬:")
    for val, count in Counter(all_valences).most_common():
        print(f"  - {val}: {count}ê°œ")

    print(f"\nì£¼ìš” í‚¤ì›Œë“œ Top 15:")
    for kw, count in Counter(all_keywords).most_common(15):
        print(f"  - {kw}: {count}íšŒ")

    print(f"\nì£¼ìš” ê°ì • Top 10:")
    for em, count in Counter(all_emotions).most_common(10):
        print(f"  - {em}: {count}íšŒ")

    print(f"\nìƒ˜í”Œ perception 3ê°œ:")
    for i, p in enumerate(perceptions[:3], 1):
        print(f"\n  [{i}] {p.get('perceived_subject')} - {p.get('perceived_attribute')}")
        print(f"      Valence: {p.get('perceived_valence')}")
        print(f"      Claims: {p.get('claims', [])[:2]}")
        print(f"      Keywords: {p.get('keywords', [])[:5]}")
        print(f"      Emotions: {p.get('emotions', [])}")

    return {
        'total': len(perceptions),
        'subjects': Counter(all_subjects),
        'attributes': Counter(all_attributes),
        'valences': Counter(all_valences),
        'keywords': Counter(all_keywords),
        'emotions': Counter(all_emotions),
        'all_claims': all_claims
    }


# ====================================
# ì‹¤í—˜ 1: í†µê³„ì  ìš”ì•½
# ====================================

async def experiment1_statistical_summary(perceptions, stats):
    """í†µê³„ ê¸°ë°˜ ì„¸ê³„ê´€ ìš”ì•½"""
    print("\n" + "="*80)
    print("=== ì‹¤í—˜ 1: í†µê³„ì  ìš”ì•½ ë°©ì‹ ===")
    print("="*80)

    summary = {
        "ì´_perceptionìˆ˜": len(perceptions),
        "ì£¼ìš”_ì£¼ì²´_top5": [s for s, c in stats['subjects'].most_common(5)],
        "ì£¼ìš”_ì†ì„±_top5": [a for a, c in stats['attributes'].most_common(5)],
        "ì£¼ìš”_í‚¤ì›Œë“œ_top10": [k for k, c in stats['keywords'].most_common(10)],
        "ì£¼ìš”_ê°ì •_top5": [e for e, c in stats['emotions'].most_common(5)],
        "ê°ì •_ë¶„í¬": dict(stats['valences'])
    }

    print("\nê²°ê³¼:")
    print(json.dumps(summary, ensure_ascii=False, indent=2))

    print("\n=== í‰ê°€ ===")
    print("ğŸ‘ ì¥ì : ê°ê´€ì , ë°ì´í„°ì— ì¶©ì‹¤, ê²€ì¦ ê°€ëŠ¥")
    print("ğŸ‘ ë‹¨ì : 'ì„¸ê³„ê´€ = ë Œì¦ˆ'ë¥¼ ì „í˜€ ì „ë‹¬í•˜ì§€ ëª»í•¨, ë‹¨ìˆœ í†µê³„ì¼ ë¿")
    print("ğŸ“Š ì‚¬ìš©ì ì´í•´ë„: â˜…â˜†â˜†â˜†â˜† (1/5)")

    return {
        "method": "statistical_summary",
        "result": summary,
        "understanding_score": 1,
        "fidelity_score": 5
    }


# ====================================
# ì‹¤í—˜ 2: GPT ë‹¨ìˆœ ìš”ì•½
# ====================================

async def experiment2_gpt_simple_summary(perceptions):
    """GPTì—ê²Œ perception ì£¼ê³  ìš”ì•½ ìš”ì²­"""
    print("\n" + "="*80)
    print("=== ì‹¤í—˜ 2: GPT ë‹¨ìˆœ ìš”ì•½ ë°©ì‹ ===")
    print("="*80)

    # ìƒ˜í”Œ 15ê°œë§Œ ì‚¬ìš©
    sample = perceptions[:15]

    perception_texts = []
    for i, p in enumerate(sample, 1):
        text = f"""
[{i}] {p.get('perceived_subject')} - {p.get('perceived_attribute')} ({p.get('perceived_valence')})
   Claims: {p.get('claims', [])}
   Keywords: {p.get('keywords', [])}
   Emotions: {p.get('emotions', [])}
"""
        perception_texts.append(text)

    prompt = f"""
ë‹¤ìŒì€ íŠ¹ì • ì„¸ê³„ê´€ì— ì†í•œ 15ê°œì˜ perceptionì…ë‹ˆë‹¤:

{chr(10).join(perception_texts)}

ì´ perceptionë“¤ì„ ê´€í†µí•˜ëŠ” ì„¸ê³„ê´€ì„ 3-5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
"""

    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )

    result = response.choices[0].message.content

    print("\nê²°ê³¼:")
    print(result)

    print("\n=== í‰ê°€ ===")
    print("ğŸ‘ ì¥ì : ì½ê¸° ì‰¬ì›€, ê°„ê²°í•¨")
    print("ğŸ‘ ë‹¨ì : ì¶”ìƒì , 'ë Œì¦ˆ'ë¥¼ ê²½í—˜í•  ìˆ˜ ì—†ìŒ, ì •ë³´ ì••ì¶•ì¼ ë¿")
    print("ğŸ“Š ì‚¬ìš©ì ì´í•´ë„: â˜…â˜…â˜†â˜†â˜† (2/5)")

    return {
        "method": "gpt_simple_summary",
        "result": result,
        "understanding_score": 2,
        "fidelity_score": 3
    }


# ====================================
# ì‹¤í—˜ 3: íŒ¨í„´ ê¸°ë°˜ í•´ì„ ì°¨ì´
# ====================================

async def experiment3_pattern_based_interpretation(perceptions, stats):
    """ì‹¤ì œ ë°ì´í„° íŒ¨í„´ì—ì„œ í•´ì„ ì°¨ì´ ì¶”ì¶œ"""
    print("\n" + "="*80)
    print("=== ì‹¤í—˜ 3: íŒ¨í„´ ê¸°ë°˜ í•´ì„ ì°¨ì´ ë°©ì‹ ===")
    print("="*80)

    # ëŒ€í‘œ perception ì„ ì • (ë¹ˆë²ˆí•œ ì£¼ì²´ + ëª…í™•í•œ valence)
    representative = []

    # Top ì£¼ì²´ë“¤ì˜ ëŒ€í‘œ perception
    for subject, _ in stats['subjects'].most_common(5):
        if not subject:
            continue
        for p in perceptions:
            if p.get('perceived_subject') == subject and p.get('claims'):
                representative.append(p)
                break

    # GPTì—ê²Œ "ì´ perceptionë“¤ì´ ë³´ì—¬ì£¼ëŠ” ë Œì¦ˆ"ë¥¼ ë¬¼ì–´ë³´ê¸°
    perception_texts = []
    for p in representative[:6]:
        text = f"""
ì£¼ì²´: {p.get('perceived_subject')}
ì†ì„±: {p.get('perceived_attribute')}
í‰ê°€: {p.get('perceived_valence')}
ì£¼ì¥: {p.get('claims', [])[:3]}
"""
        perception_texts.append(text)

    prompt = f"""
ë‹¤ìŒì€ íŠ¹ì • ì„¸ê³„ê´€ì— ì†í•œ ëŒ€í‘œì ì¸ perception 6ê°œì…ë‹ˆë‹¤:

{chr(10).join(perception_texts)}

ì´ perceptionë“¤ì´ ê³µí†µì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” "ë Œì¦ˆì˜ íŠ¹ì„±"ì„ íŒŒì•…í•˜ê³ ,
"í•´ì„ ì°¨ì´ ì˜ˆì‹œ" 3ê°œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

í˜•ì‹:
{{
  "core_lens": "ì´ ë Œì¦ˆì˜ í•µì‹¬ íŠ¹ì„± (1ë¬¸ì¥)",
  "interpretation_examples": [
    {{
      "subject": "ëŒ€ìƒ/ì£¼ì²´",
      "normal_view": "ì¼ë°˜ì ìœ¼ë¡œëŠ” ì´ë ‡ê²Œ ë´„",
      "through_this_lens": "ì´ ë Œì¦ˆë¡œëŠ” ì´ë ‡ê²Œ ë´„",
      "key_difference": "í•µì‹¬ ì°¨ì´ì ",
      "evidence_from_data": "ì‹¤ì œ perceptionì—ì„œì˜ ê·¼ê±°"
    }}
  ]
}}

ì‹¤ì œ ë°ì´í„°ì— ê¸°ë°˜í•´ì„œ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""

    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"},
        temperature=0.5
    )

    result = json.loads(response.choices[0].message.content)

    print("\nê²°ê³¼:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

    print("\n=== í‰ê°€ ===")
    print("ğŸ‘ ì¥ì : ì§ê´€ì , ë Œì¦ˆì˜ ì°¨ì´ë¥¼ ë³´ì—¬ì¤Œ, ì´í•´í•˜ê¸° ì‰¬ì›€")
    print("ğŸ‘ ë‹¨ì : GPTê°€ í•´ì„ì„ ì¶”ê°€í•¨, ì‹¤ì œ ë°ì´í„°ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ê°€?")
    print("ğŸ“Š ì‚¬ìš©ì ì´í•´ë„: â˜…â˜…â˜…â˜…â˜† (4/5)")

    return {
        "method": "pattern_based_interpretation",
        "result": result,
        "understanding_score": 4,
        "fidelity_score": 3
    }


# ====================================
# ì‹¤í—˜ 4: ì‹¤ì œ perception ì§ì ‘ ì œì‹œ
# ====================================

async def experiment4_direct_perception_presentation(perceptions, stats):
    """ê°€ê³µ ì—†ì´ ëŒ€í‘œ perceptionì„ ì§ì ‘ ë³´ì—¬ì£¼ê¸°"""
    print("\n" + "="*80)
    print("=== ì‹¤í—˜ 4: ì‹¤ì œ Perception ì§ì ‘ ì œì‹œ ë°©ì‹ ===")
    print("="*80)

    # ì£¼ìš” ì£¼ì²´ë³„ë¡œ ê°€ì¥ ëŒ€í‘œì ì¸ perception ì„ ì •
    representatives = []

    for subject, count in stats['subjects'].most_common(5):
        if not subject:
            continue

        # í•´ë‹¹ ì£¼ì²´ì˜ perception ì¤‘ claimsê°€ ë§ì€ ê²ƒ
        subject_perceptions = [p for p in perceptions if p.get('perceived_subject') == subject]
        if subject_perceptions:
            best = max(subject_perceptions, key=lambda x: len(x.get('claims', [])))
            representatives.append({
                "subject": best.get('perceived_subject'),
                "attribute": best.get('perceived_attribute'),
                "valence": best.get('perceived_valence'),
                "claims": best.get('claims', [])[:3],
                "keywords": best.get('keywords', [])[:5],
                "emotions": best.get('emotions', [])[:3]
            })

    result = {
        "approach": "ëŒ€í‘œ perceptionì„ ì§ì ‘ ì œì‹œ",
        "representative_perceptions": representatives[:5]
    }

    print("\nê²°ê³¼:")
    for i, rp in enumerate(result['representative_perceptions'], 1):
        print(f"\n[{i}] {rp['subject']} - {rp['attribute']}")
        print(f"    í‰ê°€: {rp['valence']}")
        print(f"    ì£¼ì¥: {rp['claims']}")
        print(f"    í‚¤ì›Œë“œ: {rp['keywords']}")
        print(f"    ê°ì •: {rp['emotions']}")

    print("\n=== í‰ê°€ ===")
    print("ğŸ‘ ì¥ì : ì›ë³¸ ë°ì´í„°ì— 100% ì¶©ì‹¤, ê°€ì§œ ì—†ìŒ")
    print("ğŸ‘ ë‹¨ì : 'ë Œì¦ˆ'ë¥¼ ê²½í—˜í•˜ê¸° ì–´ë ¤ì›€, ì—¬ì „íˆ ì •ë³´ ë‚˜ì—´")
    print("ğŸ“Š ì‚¬ìš©ì ì´í•´ë„: â˜…â˜…â˜†â˜†â˜† (2/5)")

    return {
        "method": "direct_perception",
        "result": result,
        "understanding_score": 2,
        "fidelity_score": 5
    }


# ====================================
# ì‹¤í—˜ 5: ëŒ€ì¡°ì  í”„ë ˆì„ (A vs B vs C)
# ====================================

async def experiment5_contrastive_frames(perceptions, stats):
    """ê°™ì€ ëŒ€ìƒì„ ë‹¤ë¥´ê²Œ ë³´ëŠ” ë°©ì‹ì„ ëŒ€ì¡°ë¡œ ë³´ì—¬ì£¼ê¸°"""
    print("\n" + "="*80)
    print("=== ì‹¤í—˜ 5: ëŒ€ì¡°ì  í”„ë ˆì„ ë°©ì‹ ===")
    print("="*80)

    # ê°€ì¥ ë¹ˆë²ˆí•œ ì£¼ì²´ ì„ íƒ
    top_subject = stats['subjects'].most_common(1)[0][0] if stats['subjects'] else None

    if not top_subject:
        print("ì£¼ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return None

    # í•´ë‹¹ ì£¼ì²´ì— ëŒ€í•œ perceptionë“¤
    subject_perceptions = [p for p in perceptions if p.get('perceived_subject') == top_subject][:5]

    perception_texts = []
    for p in subject_perceptions:
        text = f"""
ì†ì„±: {p.get('perceived_attribute')}
í‰ê°€: {p.get('perceived_valence')}
ì£¼ì¥: {p.get('claims', [])}
"""
        perception_texts.append(text)

    prompt = f"""
ë‹¤ìŒì€ "{top_subject}"ì— ëŒ€í•œ ì—¬ëŸ¬ perceptionì…ë‹ˆë‹¤:

{chr(10).join(perception_texts)}

"{top_subject}"ë¥¼ 3ê°€ì§€ ë‹¤ë¥¸ ë Œì¦ˆë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ ë°ì´í„°ëŠ” ê·¸ ì¤‘ ì–´ëŠ ë Œì¦ˆë¥¼ ì„ íƒí•˜ê³  ìˆëŠ”ì§€ ë³´ì—¬ì£¼ì„¸ìš”:

{{
  "subject": "{top_subject}",
  "possible_frames": [
    {{
      "frame_name": "í”„ë ˆì„ A ì´ë¦„",
      "view": "ì´ë ‡ê²Œ ë³¸ë‹¤",
      "this_is_chosen": false
    }},
    {{
      "frame_name": "í”„ë ˆì„ B ì´ë¦„",
      "view": "ì´ë ‡ê²Œ ë³¸ë‹¤",
      "this_is_chosen": false
    }},
    {{
      "frame_name": "í”„ë ˆì„ C ì´ë¦„",
      "view": "ì´ë ‡ê²Œ ë³¸ë‹¤",
      "this_is_chosen": true,
      "evidence": "ì‹¤ì œ perceptionì—ì„œì˜ ê·¼ê±°"
    }}
  ]
}}

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""

    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"},
        temperature=0.6
    )

    result = json.loads(response.choices[0].message.content)

    print("\nê²°ê³¼:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

    print("\n=== í‰ê°€ ===")
    print("ğŸ‘ ì¥ì : ì„ íƒì˜ ì´ìœ ê°€ ëª…í™•í•¨, ë Œì¦ˆì˜ í¸í–¥ì„ ì˜ ë“œëŸ¬ëƒ„")
    print("ğŸ‘ ë‹¨ì : ë‹¤ë¥¸ í”„ë ˆì„ë“¤ì€ GPTê°€ ë§Œë“  ê²ƒ, ì‹¤ì œ ì¡´ì¬í•˜ëŠ”ê°€?")
    print("ğŸ“Š ì‚¬ìš©ì ì´í•´ë„: â˜…â˜…â˜…â˜…â˜† (4/5)")

    return {
        "method": "contrastive_frames",
        "result": result,
        "understanding_score": 4,
        "fidelity_score": 2
    }


# ====================================
# ì‹¤í—˜ 6: í•˜ì´ë¸Œë¦¬ë“œ (ì›ë³¸ + í•´ì„ ë ˆì´ì–´)
# ====================================

async def experiment6_hybrid_original_plus_interpretation(perceptions, stats):
    """ì›ë³¸ perception + GPT í•´ì„ ë ˆì´ì–´"""
    print("\n" + "="*80)
    print("=== ì‹¤í—˜ 6: í•˜ì´ë¸Œë¦¬ë“œ (ì›ë³¸ + í•´ì„ ë ˆì´ì–´) ===")
    print("="*80)

    # Layer 1: ì›ë³¸ í†µê³„
    layer1_stats = {
        "ì£¼ìš”_ì£¼ì²´": [s for s, c in stats['subjects'].most_common(5)],
        "ì£¼ìš”_í‚¤ì›Œë“œ": [k for k, c in stats['keywords'].most_common(10)],
        "ì£¼ìš”_ê°ì •": [e for e, c in stats['emotions'].most_common(5)]
    }

    # Layer 2: ëŒ€í‘œ perception
    representatives = []
    for subject, _ in stats['subjects'].most_common(3):
        if not subject:
            continue
        for p in perceptions:
            if p.get('perceived_subject') == subject and p.get('claims'):
                representatives.append({
                    "subject": p.get('perceived_subject'),
                    "attribute": p.get('perceived_attribute'),
                    "claims": p.get('claims', [])[:2]
                })
                break

    layer2_perceptions = representatives

    # Layer 3: GPT í•´ì„
    perception_texts = []
    for rp in layer2_perceptions:
        text = f"{rp['subject']} - {rp['attribute']}: {rp['claims']}"
        perception_texts.append(text)

    prompt = f"""
ë‹¤ìŒì€ ì„¸ê³„ê´€ì˜ í†µê³„ì™€ ëŒ€í‘œ perceptionì…ë‹ˆë‹¤:

í†µê³„:
{json.dumps(layer1_stats, ensure_ascii=False)}

ëŒ€í‘œ Perception:
{chr(10).join(perception_texts)}

ì´ ë°ì´í„°ê°€ ë³´ì—¬ì£¼ëŠ” "ë Œì¦ˆì˜ íŠ¹ì„±"ì„ í•´ì„í•´ì£¼ì„¸ìš”:

{{
  "core_lens": "ì´ ë Œì¦ˆì˜ í•µì‹¬ íŠ¹ì„± (1ë¬¸ì¥)",
  "what_they_focus_on": "ì´ ë Œì¦ˆê°€ ì£¼ëª©í•˜ëŠ” ê²ƒ",
  "what_they_ignore": "ì´ ë Œì¦ˆê°€ ë†“ì¹˜ëŠ” ê²ƒ",
  "emotional_tone": "ì „ë°˜ì ì¸ ê°ì • í†¤"
}}

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""

    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"},
        temperature=0.5
    )

    layer3_interpretation = json.loads(response.choices[0].message.content)

    result = {
        "layer1_statistics": layer1_stats,
        "layer2_representative_perceptions": layer2_perceptions,
        "layer3_gpt_interpretation": layer3_interpretation
    }

    print("\nê²°ê³¼:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

    print("\n=== í‰ê°€ ===")
    print("ğŸ‘ ì¥ì : ì›ë³¸ ì¶©ì‹¤ì„± + í•´ì„ ë ˆì´ì–´, ê²€ì¦ ê°€ëŠ¥, ê· í˜•ì ")
    print("ğŸ‘ ë‹¨ì : ë³µì¡ë„ ì¦ê°€, ì—¬ì „íˆ 'ë Œì¦ˆ ê²½í—˜'ì€ ì•½í•¨")
    print("ğŸ“Š ì‚¬ìš©ì ì´í•´ë„: â˜…â˜…â˜…â˜†â˜† (3/5)")

    return {
        "method": "hybrid_original_plus_interpretation",
        "result": result,
        "understanding_score": 3,
        "fidelity_score": 4
    }


# ====================================
# ì‹¤í—˜ 7: ìŠ¤í† ë¦¬í…”ë§ (ë‚´ëŸ¬í‹°ë¸Œ)
# ====================================

async def experiment7_narrative_storytelling(perceptions, stats):
    """ì´ì•¼ê¸° í˜•ì‹ìœ¼ë¡œ ë Œì¦ˆ ì „ë‹¬"""
    print("\n" + "="*80)
    print("=== ì‹¤í—˜ 7: ìŠ¤í† ë¦¬í…”ë§ (ë‚´ëŸ¬í‹°ë¸Œ) ë°©ì‹ ===")
    print("="*80)

    # ìƒ˜í”Œ perception
    sample = perceptions[:10]

    perception_texts = []
    for p in sample:
        text = f"{p.get('perceived_subject')} - {p.get('perceived_attribute')} ({p.get('perceived_valence')}): {p.get('claims', [])[:2]}"
        perception_texts.append(text)

    prompt = f"""
ë‹¤ìŒ perceptionë“¤ì„ ë°”íƒ•ìœ¼ë¡œ:

{chr(10).join(perception_texts)}

ì´ ì„¸ê³„ê´€ì„ ê°€ì§„ ì‚¬ëŒì˜ ì‹œê°ìœ¼ë¡œ ì„¸ìƒì„ ë³´ëŠ” ì§§ì€ ë‚´ëŸ¬í‹°ë¸Œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

"ì´ ì‚¬ëŒë“¤ì—ê²Œ ì„¸ìƒì€..."ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” 3-4ê°œ ë¬¸ë‹¨.
ê°ì •ê³¼ ë…¼ë¦¬ë¥¼ ëª¨ë‘ ë‹´ì•„ì£¼ì„¸ìš”.

ë‹¨, ì‹¤ì œ perceptionì— ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
"""

    response = await openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )

    result = response.choices[0].message.content

    print("\nê²°ê³¼:")
    print(result)

    print("\n=== í‰ê°€ ===")
    print("ğŸ‘ ì¥ì : ê°ì •ì ìœ¼ë¡œ ê³µê° ê°€ëŠ¥, ë Œì¦ˆë¥¼ 'ëŠë‚„' ìˆ˜ ìˆìŒ")
    print("ğŸ‘ ë‹¨ì : ì§€ë‚˜ì¹˜ê²Œ ì£¼ê´€ì , ê²€ì¦ ì–´ë ¤ì›€, CLAUDE.md ìœ„ë°˜ ê°€ëŠ¥ì„±")
    print("âš ï¸  ê²½ê³ : ì‚¬ìš©ìê°€ ë§Œë“  ìŠ¤í¬ë¦½íŠ¸/ì„œì‚¬ë¥¼ ê°•ìš”í•˜ëŠ” ê²ƒì¼ ìˆ˜ ìˆìŒ")
    print("ğŸ“Š ì‚¬ìš©ì ì´í•´ë„: â˜…â˜…â˜…â˜†â˜† (3/5)")

    return {
        "method": "narrative_storytelling",
        "result": result,
        "understanding_score": 3,
        "fidelity_score": 1,
        "warning": "CLAUDE.md ì˜¨ë³´ë”© ì›ì¹™ ìœ„ë°˜ ê°€ëŠ¥ì„±"
    }


# ====================================
# ì¢…í•© í‰ê°€
# ====================================

async def run_all_experiments():
    """ëª¨ë“  ì‹¤í—˜ ì‹¤í–‰ ë° ë¹„êµ"""

    print("="*80)
    print("ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì„¸ê³„ê´€ í‘œí˜„ ë°©ì‹ ì¢…í•© ì‹¤í—˜")
    print("="*80)

    # ë°ì´í„° ë¡œë“œ
    worldview, perceptions = load_worldview_with_perceptions()

    if not perceptions:
        print("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return

    # ë°ì´í„° êµ¬ì¡° ë¶„ì„
    stats = analyze_perception_structure(perceptions)

    # ëª¨ë“  ì‹¤í—˜ ì‹¤í–‰
    results = []

    results.append(await experiment1_statistical_summary(perceptions, stats))
    results.append(await experiment2_gpt_simple_summary(perceptions))
    results.append(await experiment3_pattern_based_interpretation(perceptions, stats))
    results.append(await experiment4_direct_perception_presentation(perceptions, stats))
    results.append(await experiment5_contrastive_frames(perceptions, stats))
    results.append(await experiment6_hybrid_original_plus_interpretation(perceptions, stats))
    results.append(await experiment7_narrative_storytelling(perceptions, stats))

    # ìµœì¢… ë¹„êµ
    print("\n\n" + "="*80)
    print("=== ì „ì²´ ì‹¤í—˜ ê²°ê³¼ ë¹„êµ ===")
    print("="*80)

    print("\n{:40s} {:20s} {:20s}".format("ë°©ë²•", "ì‚¬ìš©ì ì´í•´ë„", "ë°ì´í„° ì¶©ì‹¤ì„±"))
    print("-"*80)

    for r in results:
        method = r['method']
        understanding = "â˜…" * r['understanding_score'] + "â˜†" * (5 - r['understanding_score'])
        fidelity = "â˜…" * r['fidelity_score'] + "â˜†" * (5 - r['fidelity_score'])
        print(f"{method:40s} {understanding:20s} {fidelity:20s}")

    # ë¶„ì„
    print("\n\n" + "="*80)
    print("=== í•µì‹¬ ë°œê²¬ ===")
    print("="*80)

    analysis = """
íŠ¸ë ˆì´ë“œì˜¤í”„ê°€ ëª…í™•í•©ë‹ˆë‹¤:

1. ë°ì´í„° ì¶©ì‹¤ì„± â†‘ â†’ ì‚¬ìš©ì ì´í•´ë„ â†“
   - ì‹¤í—˜ 1, 4: ì›ë³¸ì— ì¶©ì‹¤í•˜ì§€ë§Œ 'ë Œì¦ˆ'ë¥¼ ì „ë‹¬ ëª»í•¨

2. ì‚¬ìš©ì ì´í•´ë„ â†‘ â†’ ë°ì´í„° ì¶©ì‹¤ì„± â†“
   - ì‹¤í—˜ 3, 5: ë Œì¦ˆë¥¼ ì˜ ë³´ì—¬ì£¼ì§€ë§Œ GPTê°€ í•´ì„ ì¶”ê°€

3. ë‚´ëŸ¬í‹°ë¸Œ (ì‹¤í—˜ 7): ê³µê°ì€ ê°€ëŠ¥í•˜ì§€ë§Œ ìœ„í—˜ì„± ë†’ìŒ
   - CLAUDE.md ìœ„ë°˜ ê°€ëŠ¥ì„±
   - ì‚¬ìš©ì ì£¼ë„ê¶Œ ì¹¨í•´ ê°€ëŠ¥ì„±

=== ì§ˆë¬¸ ===

ì–´ë–¤ ê²ƒì„ ì„ íƒí•  ê²ƒì¸ê°€?

A. ì¶©ì‹¤ì„± ìš°ì„  (ì‹¤í—˜ 1, 4)
   â†’ ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ í•´ì„í•˜ê²Œ í•¨
   â†’ í•˜ì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ ì‚¬ìš©ìëŠ” í•´ì„ ëª»í•¨

B. ì´í•´ë„ ìš°ì„  (ì‹¤í—˜ 3, 5)
   â†’ GPT í•´ì„ ë ˆì´ì–´ ì œê³µ
   â†’ í•˜ì§€ë§Œ "ê°€ì§œ" ì„¸ê³„ê´€ ë§Œë“¤ ìœ„í—˜

C. ê· í˜• (ì‹¤í—˜ 6)
   â†’ ì›ë³¸ + í•´ì„ ë ˆì´ì–´ ë³‘í–‰
   â†’ í•˜ì§€ë§Œ ë³µì¡ë„ ì¦ê°€

=== ë” ê¹Šì€ ì§ˆë¬¸ ===

ì• ì´ˆì— "ì„¸ê³„ê´€ì„ í‘œí˜„í•œë‹¤"ëŠ” ê²ƒì´ ê°€ëŠ¥í•œê°€?

- ì„¸ê³„ê´€ = 137ê°œ perceptionì˜ ì§‘í•©
- í†µì¼ëœ "ë Œì¦ˆ"ê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆìŒ
- ìš°ë¦¬ê°€ "ë Œì¦ˆ"ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì¼ ìˆ˜ë„ ìˆìŒ

ëŒ€ì•ˆ:
- ì„¸ê³„ê´€ì„ "í‘œí˜„"í•˜ë ¤ í•˜ì§€ ë§ê³ 
- perceptionë“¤ì„ "íƒìƒ‰"í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²ƒì€ ì–´ë–¤ê°€?
"""

    print(analysis)

    # ê²°ê³¼ ì €ì¥
    final_report = {
        "worldview": {
            "id": worldview['id'],
            "title": worldview.get('title'),
            "total_perceptions": len(perceptions)
        },
        "data_analysis": {
            "total": stats['total'],
            "ì£¼ìš”_ì£¼ì²´": [s for s, c in stats['subjects'].most_common(5)],
            "ì£¼ìš”_í‚¤ì›Œë“œ": [k for k, c in stats['keywords'].most_common(10)]
        },
        "experiments": results,
        "conclusion": analysis
    }

    with open('/tmp/real_worldview_experiments_result.json', 'w', encoding='utf-8') as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)

    print("\n\nì „ì²´ ê²°ê³¼ ì €ì¥: /tmp/real_worldview_experiments_result.json")

    return final_report


if __name__ == "__main__":
    asyncio.run(run_all_experiments())
