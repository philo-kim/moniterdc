"""
ì„¸ê³„ê´€ êµ¬ì¡° ì—°êµ¬: ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ìµœì  êµ¬ì¡° ì°¾ê¸°

ì‹¤í—˜ ëª©í‘œ:
- 137ê°œ perceptionì„ "ì„¸ê³„ê´€"ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆê²Œ ë§Œë“œëŠ” ìµœì ì˜ êµ¬ì¡° ë°œê²¬
- ì´ë¡ ë³´ë‹¤ëŠ” ì‹¤ì œ ë°ì´í„°ê°€ ë³´ì—¬ì£¼ëŠ” íŒ¨í„´ ì¤‘ì‹¬
- ì‚¬ìš©ìê°€ "ì´ ê´€ì "ì„ ì´í•´í•˜ëŠ”ë° ë„ì›€ë˜ëŠ” êµ¬ì¡°
"""

import asyncio
import os
from supabase import create_client
from openai import AsyncOpenAI
import json
from collections import Counter, defaultdict
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
from sklearn.cluster import KMeans
import numpy as np
import re
from dotenv import load_dotenv

load_dotenv()

supabase = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_KEY')
)
openai_client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))


# ==============================================================================
# ë°ì´í„° ë¡œë“œ
# ==============================================================================

def load_worldview_data():
    """ë…ì¬ì™€ ì‚¬ì°°ì˜ ë¶€í™œ ë°ì´í„° ë¡œë“œ"""
    wv = supabase.table('worldviews').select('*').limit(1).execute().data[0]
    perception_ids = wv['perception_ids']

    # ëª¨ë“  perception ë¡œë“œ
    perceptions = supabase.table('layered_perceptions').select('*').in_('id', perception_ids).execute().data

    print(f"Loaded: {wv['title']}")
    print(f"Perceptions: {len(perceptions)}")

    return wv, perceptions


# ==============================================================================
# ì‹¤í—˜ 1: í†µê³„ì  íŒ¨í„´ ë¶„ì„ (What do they actually talk about?)
# ==============================================================================

def experiment1_statistical_patterns(perceptions):
    """ì‹¤ì œë¡œ ë¬´ì—‡ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ëŠ”ê°€?"""
    print("\n" + "="*80)
    print("ì‹¤í—˜ 1: í†µê³„ì  íŒ¨í„´ ë¶„ì„")
    print("="*80)

    # ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    all_explicit = []
    all_implicit = []
    all_deep = []

    subjects = []
    predicates = []

    for lp in perceptions:
        if lp.get('explicit_claims'):
            for claim in lp['explicit_claims']:
                subjects.append(claim.get('subject', ''))
                predicates.append(claim.get('predicate', ''))
                all_explicit.append(f"{claim.get('subject', '')} {claim.get('predicate', '')}")

        if lp.get('implicit_assumptions'):
            all_implicit.extend(lp['implicit_assumptions'])

        if lp.get('deep_beliefs'):
            all_deep.extend(lp['deep_beliefs'])

    # ì£¼ì²´ ë¶„ì„
    subject_counter = Counter(subjects)
    print(f"\nğŸ“Š ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì£¼ì²´ (Top 15):")
    for subj, count in subject_counter.most_common(15):
        print(f"  {subj}: {count}íšŒ")

    # Deep beliefs í‚¤ì›Œë“œ ë¶„ì„
    all_deep_text = ' '.join(all_deep)

    # ëª…ì‚¬êµ¬ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´)
    noun_phrases = re.findall(r'[ê°€-í£]{2,}(?:ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜)', all_deep_text)
    noun_phrase_counter = Counter([p[:-1] for p in noun_phrases])

    print(f"\nğŸ”‘ Deep beliefsì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” ê°œë…:")
    for phrase, count in noun_phrase_counter.most_common(20):
        if len(phrase) > 1:
            print(f"  {phrase}: {count}íšŒ")

    # ì„œìˆ ì–´ íŒ¨í„´ (ë™ì‚¬/í˜•ìš©ì‚¬)
    verb_patterns = re.findall(r'[ê°€-í£]{2,}(?:í•œë‹¤|í•˜ëŠ”|í–ˆë‹¤|ë |ë˜ëŠ”|ì´ë‹¤|ìˆë‹¤)', all_deep_text)
    verb_counter = Counter(verb_patterns)

    print(f"\nâš¡ ìì£¼ ë‚˜ì˜¤ëŠ” ì„œìˆ  íŒ¨í„´:")
    for verb, count in verb_counter.most_common(15):
        print(f"  {verb}: {count}íšŒ")

    # ê´€ê³„ íŒ¨í„´ (XëŠ” Yí•˜ë‹¤)
    print(f"\nğŸ”— ì£¼ìš” ê´€ê³„ íŒ¨í„´ (ìƒ˜í”Œ):")
    for belief in all_deep[:10]:
        # ê°„ë‹¨í•œ êµ¬ë¬¸ íŒŒì‹±
        match = re.match(r'([^ì€ëŠ”ì´ê°€]+)[ì€ëŠ”ì´ê°€]\s*(.+)', belief)
        if match:
            subject, predicate = match.groups()
            print(f"  [{subject}] â†’ {predicate[:60]}...")

    return {
        'subjects': dict(subject_counter.most_common(20)),
        'key_concepts': dict(noun_phrase_counter.most_common(20)),
        'verb_patterns': dict(verb_counter.most_common(15)),
        'all_deep': all_deep,
        'all_implicit': all_implicit
    }


# ==============================================================================
# ì‹¤í—˜ 2: í† í”½ ëª¨ë¸ë§ (What are the underlying themes?)
# ==============================================================================

def experiment2_topic_modeling(perceptions):
    """ì ì¬ëœ ì£¼ì œë“¤ì€ ë¬´ì—‡ì¸ê°€?"""
    print("\n" + "="*80)
    print("ì‹¤í—˜ 2: í† í”½ ëª¨ë¸ë§ (LDA)")
    print("="*80)

    # Deep beliefsë§Œ ëª¨ìœ¼ê¸°
    docs = []
    for lp in perceptions:
        if lp.get('deep_beliefs'):
            docs.append(' '.join(lp['deep_beliefs']))

    # LDA
    vectorizer = CountVectorizer(max_features=100, min_df=2)
    doc_term_matrix = vectorizer.fit_transform(docs)

    lda = LatentDirichletAllocation(n_components=5, random_state=42)
    lda.fit(doc_term_matrix)

    feature_names = vectorizer.get_feature_names_out()

    print(f"\në°œê²¬ëœ 5ê°œ ì£¼ì œ:")
    topics = []
    for topic_idx, topic in enumerate(lda.components_):
        top_words_idx = topic.argsort()[-10:][::-1]
        top_words = [feature_names[i] for i in top_words_idx]
        print(f"\nì£¼ì œ {topic_idx + 1}: {', '.join(top_words)}")
        topics.append(top_words)

    return {
        'topics': topics,
        'model': lda,
        'vectorizer': vectorizer
    }


# ==============================================================================
# ì‹¤í—˜ 3: ì¸ê³¼ ê´€ê³„ ì¶”ì¶œ (What causal chains do they believe?)
# ==============================================================================

def experiment3_causal_chains(perceptions):
    """ì–´ë–¤ ì¸ê³¼ ì—°ì‡„ë¥¼ ë¯¿ëŠ”ê°€?"""
    print("\n" + "="*80)
    print("ì‹¤í—˜ 3: ì¸ê³¼ ê´€ê³„ íŒ¨í„´ ì¶”ì¶œ")
    print("="*80)

    # ì¸ê³¼ í‘œí˜„ íŒ¨í„´
    causal_patterns = [
        r'(.+?)(?:ë•Œë¬¸ì—|ìœ¼ë¡œ ì¸í•´|í•˜ì—¬|í•´ì„œ)\s*(.+)',
        r'(.+?)\s*â†’\s*(.+)',
        r'(.+?)(?:í•˜ë©´|í•œë‹¤ë©´)\s*(.+)',
    ]

    all_deep = []
    for lp in perceptions:
        if lp.get('deep_beliefs'):
            all_deep.extend(lp['deep_beliefs'])

    causal_chains = []
    for belief in all_deep:
        for pattern in causal_patterns:
            matches = re.findall(pattern, belief)
            if matches:
                causal_chains.extend(matches)

    print(f"\në°œê²¬ëœ ì¸ê³¼ ê´€ê³„ íŒ¨í„´ (ìƒ˜í”Œ 10ê°œ):")
    for cause, effect in causal_chains[:10]:
        print(f"  {cause.strip()[:40]} â†’ {effect.strip()[:40]}")

    return causal_chains


# ==============================================================================
# ì‹¤í—˜ 4: GPTë¡œ êµ¬ì¡° ì¶”ì¶œ (ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸)
# ==============================================================================

async def experiment4_gpt_structuring(perceptions, stats_result):
    """GPTë¡œ ì—¬ëŸ¬ ë°©ì‹ì˜ êµ¬ì¡° ì¶”ì¶œ"""
    print("\n" + "="*80)
    print("ì‹¤í—˜ 4: GPT êµ¬ì¡°í™” (5ê°€ì§€ í”„ë¡¬í”„íŠ¸)")
    print("="*80)

    # ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„
    deep_beliefs_sample = []
    for lp in perceptions[:30]:  # ì²˜ìŒ 30ê°œë§Œ
        if lp.get('deep_beliefs'):
            deep_beliefs_sample.extend(lp['deep_beliefs'])

    # í†µê³„ ë°ì´í„°
    top_subjects = list(stats_result['subjects'].keys())[:10]
    top_concepts = list(stats_result['key_concepts'].keys())[:10]

    results = {}

    # -------------------------------------------------------------------------
    # í”„ë¡¬í”„íŠ¸ 1: "ì´ ì‚¬ëŒë“¤ì€ ì„¸ìƒì„ ì–´ë–»ê²Œ ë³´ëŠ”ê°€?"
    # -------------------------------------------------------------------------
    print("\nğŸ”¬ í”„ë¡¬í”„íŠ¸ 1: ì„¸ê³„ê´€ì˜ ë³¸ì§ˆ")

    prompt1 = f"""ë‹¤ìŒì€ ê°™ì€ ì •ì¹˜ì  ê´€ì ì„ ê°€ì§„ ì‚¬ëŒë“¤ì˜ ì‹¬ì¸µ ë¯¿ìŒ(deep beliefs) ìƒ˜í”Œì…ë‹ˆë‹¤:

{chr(10).join([f"- {b}" for b in deep_beliefs_sample[:20]])}

ì´ ì‚¬ëŒë“¤ì€ **ì„¸ìƒì„ ì–´ë–»ê²Œ ë³´ëŠ”ê°€**ë¥¼ JSONìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”:

{{
  "core_lens": "ì´ ê´€ì ì˜ í•µì‹¬ ë Œì¦ˆ (1ë¬¸ì¥)",
  "what_they_see": "ë¬´ì—‡ì— ì£¼ëª©í•˜ëŠ”ê°€",
  "how_they_interpret": "ì–´ë–»ê²Œ í•´ì„í•˜ëŠ”ê°€",
  "what_they_fear": "ë¬´ì—‡ì„ ë‘ë ¤ì›Œí•˜ëŠ”ê°€",
  "what_they_want": "ë¬´ì—‡ì„ ì›í•˜ëŠ”ê°€"
}}"""

    response1 = await openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt1}],
        response_format={"type": "json_object"},
        temperature=0.3
    )
    results['prompt1'] = json.loads(response1.choices[0].message.content)
    print(json.dumps(results['prompt1'], indent=2, ensure_ascii=False))

    # -------------------------------------------------------------------------
    # í”„ë¡¬í”„íŠ¸ 2: "í•µì‹¬ ì£¼ì¥ê³¼ ê·¸ ê·¼ê±°"
    # -------------------------------------------------------------------------
    print("\nğŸ”¬ í”„ë¡¬í”„íŠ¸ 2: ì£¼ì¥ì˜ êµ¬ì¡°")

    prompt2 = f"""ê°™ì€ ê´€ì ì˜ ì‹¬ì¸µ ë¯¿ìŒë“¤:
{chr(10).join([f"- {b}" for b in deep_beliefs_sample[:20]])}

ì£¼ìš” ì–¸ê¸‰ ëŒ€ìƒ: {', '.join(top_subjects)}

ì´ ê´€ì ì˜ **í•µì‹¬ ì£¼ì¥ê³¼ ê·¼ê±° êµ¬ì¡°**ë¥¼ JSONìœ¼ë¡œ:

{{
  "main_claim": "í•µì‹¬ ì£¼ì¥",
  "why_they_believe": ["ë¯¿ëŠ” ì´ìœ  3-5ê°œ"],
  "evidence_they_use": ["ì–´ë–¤ ì‚¬ì‹¤ì„ ì¦ê±°ë¡œ ë³´ëŠ”ê°€"],
  "logic_chain": "ì‚¬ê³  íë¦„ (A â†’ B â†’ C)"
}}"""

    response2 = await openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt2}],
        response_format={"type": "json_object"},
        temperature=0.3
    )
    results['prompt2'] = json.loads(response2.choices[0].message.content)
    print(json.dumps(results['prompt2'], indent=2, ensure_ascii=False))

    # -------------------------------------------------------------------------
    # í”„ë¡¬í”„íŠ¸ 3: "ì´ì•¼ê¸° êµ¬ì¡°"
    # -------------------------------------------------------------------------
    print("\nğŸ”¬ í”„ë¡¬í”„íŠ¸ 3: ì„œì‚¬ êµ¬ì¡°")

    prompt3 = f"""ì‹¬ì¸µ ë¯¿ìŒ ìƒ˜í”Œ:
{chr(10).join([f"- {b}" for b in deep_beliefs_sample[:20]])}

ì´ ê´€ì ì´ **ì´ì•¼ê¸°í•˜ëŠ” ìŠ¤í† ë¦¬**ë¥¼ JSONìœ¼ë¡œ:

{{
  "protagonist": "ì£¼ì¸ê³µ (ëˆ„ê°€ í”¼í•´ìì¸ê°€)",
  "antagonist": "ì•…ë‹¹ (ëˆ„ê°€ ê°€í•´ìì¸ê°€)",
  "conflict": "ê°ˆë“± (ë¬´ì—‡ì´ ë¬¸ì œì¸ê°€)",
  "plot": "ì¤„ê±°ë¦¬ (ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ê°€)",
  "ending": "ê²°ë§ (ì–´ë””ë¡œ í–¥í•˜ëŠ”ê°€)"
}}"""

    response3 = await openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt3}],
        response_format={"type": "json_object"},
        temperature=0.3
    )
    results['prompt3'] = json.loads(response3.choices[0].message.content)
    print(json.dumps(results['prompt3'], indent=2, ensure_ascii=False))

    # -------------------------------------------------------------------------
    # í”„ë¡¬í”„íŠ¸ 4: "íŒ¨í„´ ì¸ì‹"
    # -------------------------------------------------------------------------
    print("\nğŸ”¬ í”„ë¡¬í”„íŠ¸ 4: ë°˜ë³µ íŒ¨í„´")

    prompt4 = f"""ì‹¬ì¸µ ë¯¿ìŒë“¤:
{chr(10).join([f"- {b}" for b in deep_beliefs_sample[:25]])}

**ë°˜ë³µë˜ëŠ” íŒ¨í„´**ì„ JSONìœ¼ë¡œ:

{{
  "recurring_themes": ["ë°˜ë³µë˜ëŠ” ì£¼ì œ 3-5ê°œ"],
  "typical_interpretation": "ì „í˜•ì ì¸ í•´ì„ ë°©ì‹",
  "common_metaphors": ["ìì£¼ ì“°ëŠ” ë¹„ìœ "],
  "signature_moves": ["íŠ¹ì§•ì ì¸ ì‚¬ê³  íŒ¨í„´"]
}}"""

    response4 = await openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt4}],
        response_format={"type": "json_object"},
        temperature=0.3
    )
    results['prompt4'] = json.loads(response4.choices[0].message.content)
    print(json.dumps(results['prompt4'], indent=2, ensure_ascii=False))

    # -------------------------------------------------------------------------
    # í”„ë¡¬í”„íŠ¸ 5: "ì°¨ì´ì  - ê°™ì€ ì‚¬ê±´ì„ ì–´ë–»ê²Œ ë‹¤ë¥´ê²Œ ë³´ëŠ”ê°€"
    # -------------------------------------------------------------------------
    print("\nğŸ”¬ í”„ë¡¬í”„íŠ¸ 5: í•´ì„ ì°¨ì´")

    prompt5 = f"""ì´ ê´€ì ì˜ ì‹¬ì¸µ ë¯¿ìŒ:
{chr(10).join([f"- {b}" for b in deep_beliefs_sample[:20]])}

**ê°™ì€ ì‚¬ê±´ì„ ì–´ë–»ê²Œ ë‹¤ë¥´ê²Œ í•´ì„í•˜ëŠ”ê°€** JSONìœ¼ë¡œ:

{{
  "interpretation_examples": [
    {{
      "event": "ì‚¬ê±´/ìƒí™©",
      "normal_view": "ì¼ë°˜ì ìœ¼ë¡œ ë³´ëŠ” ë°©ì‹",
      "this_view": "ì´ ê´€ì ì—ì„œ ë³´ëŠ” ë°©ì‹",
      "key_difference": "í•µì‹¬ ì°¨ì´"
    }}
  ]
}}

ìµœì†Œ 3ê°œ ì˜ˆì‹œë¥¼ ë§Œë“œì„¸ìš”."""

    response5 = await openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt5}],
        response_format={"type": "json_object"},
        temperature=0.3
    )
    results['prompt5'] = json.loads(response5.choices[0].message.content)
    print(json.dumps(results['prompt5'], indent=2, ensure_ascii=False))

    return results


# ==============================================================================
# ì‹¤í—˜ 5: êµ¬ì¡° ì¡°í•© ì‹¤í—˜
# ==============================================================================

async def experiment5_combined_structure(perceptions, all_results):
    """ì—¬ëŸ¬ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì¢…í•©í•œ ìµœì  êµ¬ì¡°"""
    print("\n" + "="*80)
    print("ì‹¤í—˜ 5: ì¢…í•© êµ¬ì¡° ìƒì„±")
    print("="*80)

    # ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ë¥¼ GPTì—ê²Œ ì£¼ê³  ìµœì  êµ¬ì¡° ìƒì„±
    summary = f"""ë‹¤ìŒì€ "ë…ì¬ì™€ ì‚¬ì°°ì˜ ë¶€í™œ" ì„¸ê³„ê´€ì— ëŒ€í•œ ì—¬ëŸ¬ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

**í†µê³„ ë¶„ì„:**
- ì£¼ìš” ì£¼ì²´: {list(all_results['stats']['subjects'].keys())[:10]}
- í•µì‹¬ ê°œë…: {list(all_results['stats']['key_concepts'].keys())[:10]}

**GPT ë¶„ì„ ê²°ê³¼:**

ì„¸ê³„ê´€ì˜ ë³¸ì§ˆ: {json.dumps(all_results['gpt']['prompt1'], ensure_ascii=False)}

ì£¼ì¥ì˜ êµ¬ì¡°: {json.dumps(all_results['gpt']['prompt2'], ensure_ascii=False)}

ì„œì‚¬ êµ¬ì¡°: {json.dumps(all_results['gpt']['prompt3'], ensure_ascii=False)}

ë°˜ë³µ íŒ¨í„´: {json.dumps(all_results['gpt']['prompt4'], ensure_ascii=False)}

í•´ì„ ì°¨ì´: {json.dumps(all_results['gpt']['prompt5'], ensure_ascii=False)}

ì´ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•´ì„œ, ì‚¬ìš©ìê°€ "ì´ ì„¸ê³„ê´€(ê´€ì )"ì„ ì´í•´í•˜ëŠ”ë° ê°€ì¥ ë„ì›€ì´ ë˜ëŠ” êµ¬ì¡°ë¥¼ ë§Œë“œì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œ, ë‹¤ìŒ ê¸°ì¤€ì„ ê³ ë ¤í•˜ì„¸ìš”:
1. **ì§ê´€ì **: 5ë¶„ ì•ˆì— ì´í•´ ê°€ëŠ¥
2. **êµ¬ì²´ì **: ì¶”ìƒì  ê°œë…ë³´ë‹¤ ì‹¤ì œ ì˜ˆì‹œ
3. **ì°¨ë³„ì **: ë‹¤ë¥¸ ê´€ì ê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ëª…í™•
4. **í–‰ë™ ì§€í–¥ì **: ì™œ ì´ë ‡ê²Œ ìƒê°í•˜ê³ , ë­˜ í•˜ë ¤ëŠ”ì§€

ììœ ë¡­ê²Œ êµ¬ì¡°ë¥¼ ì„¤ê³„í•˜ì„¸ìš”. ì´ë¡ ì— ì–½ë§¤ì´ì§€ ë§ê³  "ì´í•´"ì— ìµœì í™”í•˜ì„¸ìš”."""

    response = await openai_client.chat.completions.create(
        model="gpt-4o",  # ë” ê°•ë ¥í•œ ëª¨ë¸ ì‚¬ìš©
        messages=[
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ë³µì¡í•œ ì„¸ê³„ê´€ì„ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ êµ¬ì¡°ë¡œ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
            },
            {"role": "user", "content": summary}
        ],
        response_format={"type": "json_object"},
        temperature=0.4
    )

    final_structure = json.loads(response.choices[0].message.content)

    print("\n" + "="*80)
    print("ğŸ¯ ìµœì¢… ì œì•ˆ êµ¬ì¡°:")
    print("="*80)
    print(json.dumps(final_structure, indent=2, ensure_ascii=False))

    return final_structure


# ==============================================================================
# ë©”ì¸ ì‹¤í–‰
# ==============================================================================

async def main():
    print("="*80)
    print("ì„¸ê³„ê´€ êµ¬ì¡° ì—°êµ¬: ì‹¤ì œ ë°ì´í„° ê¸°ë°˜")
    print("="*80)

    # ë°ì´í„° ë¡œë“œ
    worldview, perceptions = load_worldview_data()

    results = {}

    # ì‹¤í—˜ 1: í†µê³„
    results['stats'] = experiment1_statistical_patterns(perceptions)

    # ì‹¤í—˜ 2: í† í”½ ëª¨ë¸ë§
    results['topics'] = experiment2_topic_modeling(perceptions)

    # ì‹¤í—˜ 3: ì¸ê³¼ ê´€ê³„
    results['causal'] = experiment3_causal_chains(perceptions)

    # ì‹¤í—˜ 4: GPT êµ¬ì¡°í™”
    results['gpt'] = await experiment4_gpt_structuring(perceptions, results['stats'])

    # ì‹¤í—˜ 5: ì¢…í•©
    results['final'] = await experiment5_combined_structure(perceptions, results)

    # ê²°ê³¼ ì €ì¥
    with open('worldview_structure_research_results.json', 'w', encoding='utf-8') as f:
        # causal_chainsëŠ” tupleì´ë¼ JSON ì§ë ¬í™” ë¶ˆê°€, ì œì™¸
        save_results = {
            'stats': results['stats'],
            'gpt': results['gpt'],
            'final': results['final']
        }
        json.dump(save_results, f, ensure_ascii=False, indent=2)

    print("\n" + "="*80)
    print("âœ… ì—°êµ¬ ì™„ë£Œ! ê²°ê³¼: worldview_structure_research_results.json")
    print("="*80)

    return results


if __name__ == "__main__":
    asyncio.run(main())
