"""
GPT-5-mini vs GPT-5 ì„±ëŠ¥ ë¹„êµ ì‹œë®¬ë ˆì´ì…˜

ëª©ì : 3-Layer ë¶„ì„ì—ì„œ ì–´ë–¤ ëª¨ë¸ì´ ë” ì í•©í•œì§€ ê²€ì¦
"""

import asyncio
from openai import AsyncOpenAI
import os
from engines.utils.supabase_client import get_supabase
import json

client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))

async def analyze_with_model(content_title: str, content_body: str, model: str) -> dict:
    """íŠ¹ì • ëª¨ë¸ë¡œ 3-Layer ë¶„ì„"""

    prompt = f"""ë‹¤ìŒ DC Inside ê²Œì‹œê¸€ì„ 3-Layerë¡œ ë¶„ì„í•˜ì„¸ìš”.

ì œëª©: {content_title}
ë³¸ë¬¸: {content_body}

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{{
    "explicit_claims": [
        {{"subject": "ì£¼ì²´", "predicate": "ì„œìˆ ", "quote": "ì¸ìš©"}}
    ],
    "implicit_assumptions": ["ì•”ë¬µì  ì „ì œ1", "ì•”ë¬µì  ì „ì œ2"],
    "deep_beliefs": ["ì‹¬ì¸µ ë¯¿ìŒ1", "ì‹¬ì¸µ ë¯¿ìŒ2"],
    "worldview_hints": "ì„¸ê³„ê´€ íŒíŠ¸"
}}"""

    # GPT-5ëŠ” temperature íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ
    params = {
        "model": model,
        "messages": [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì •ì¹˜ ë‹´ë¡  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        "response_format": {"type": "json_object"}
    }

    response = await client.chat.completions.create(**params)

    result = json.loads(response.choices[0].message.content)

    return {
        "model": model,
        "result": result,
        "tokens_used": response.usage.total_tokens,
        "cost_estimate": calculate_cost(response.usage.total_tokens, model)
    }

def calculate_cost(tokens: int, model: str) -> float:
    """í† í° ê¸°ë°˜ ë¹„ìš© ê³„ì‚° (ì¶”ì •ì¹˜)"""
    # GPT-5 pricing (ì¶”ì •)
    if "mini" in model:
        cost_per_1k = 0.0001  # $0.0001/1k tokens
    else:
        cost_per_1k = 0.003   # $0.003/1k tokens

    return (tokens / 1000) * cost_per_1k

async def compare_models():
    """ë‘ ëª¨ë¸ ë¹„êµ"""

    supabase = get_supabase()

    # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ 1ê°œ ì„ íƒ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
    samples = supabase.table('contents').select('id, title, body').neq('body', '').limit(1).execute().data

    print("\n" + "="*80)
    print("GPT-5-mini vs GPT-5 ì„±ëŠ¥ ë¹„êµ ì‹œë®¬ë ˆì´ì…˜")
    print("="*80)
    print(f"\ní…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(samples)}ê°œ")
    print("\nëª©ì : 3-Layer ë¶„ì„ì—ì„œ ì–´ë–¤ ëª¨ë¸ì´ ë” ì í•©í•œì§€ ê²€ì¦")
    print("ê¸°ì¤€: 1) ë¶„ì„ ê¹Šì´, 2) ë¹„ìš© íš¨ìœ¨ì„±, 3) ì¼ê´€ì„±")
    print("="*80)

    comparison_results = []

    for i, sample in enumerate(samples, 1):
        print(f"\n{'='*80}")
        print(f"ìƒ˜í”Œ {i}: \"{sample['title'][:50]}...\"")
        print(f"{'='*80}")

        # GPT-5-minië¡œ ë¶„ì„
        print("\nğŸ”µ GPT-5-mini ë¶„ì„ ì¤‘...")
        mini_result = await analyze_with_model(sample['title'], sample['body'][:1000], "gpt-5-mini")

        # GPT-5ë¡œ ë¶„ì„
        print("ğŸŸ¢ GPT-5 ë¶„ì„ ì¤‘...")
        full_result = await analyze_with_model(sample['title'], sample['body'][:1000], "gpt-5")

        # ê²°ê³¼ ë¹„êµ
        print("\n" + "-"*80)
        print("ğŸ“Š ë¶„ì„ ê²°ê³¼ ë¹„êµ:")
        print("-"*80)

        print(f"\n[GPT-5-mini]")
        print(f"  Deep Beliefs ê°œìˆ˜: {len(mini_result['result'].get('deep_beliefs', []))}ê°œ")
        print(f"  í† í° ì‚¬ìš©: {mini_result['tokens_used']}ê°œ")
        print(f"  ì˜ˆìƒ ë¹„ìš©: ${mini_result['cost_estimate']:.4f}")
        print(f"  Deep Beliefs ì˜ˆì‹œ:")
        for j, belief in enumerate(mini_result['result'].get('deep_beliefs', [])[:2], 1):
            print(f"    {j}. {belief[:80]}...")

        print(f"\n[GPT-5]")
        print(f"  Deep Beliefs ê°œìˆ˜: {len(full_result['result'].get('deep_beliefs', []))}ê°œ")
        print(f"  í† í° ì‚¬ìš©: {full_result['tokens_used']}ê°œ")
        print(f"  ì˜ˆìƒ ë¹„ìš©: ${full_result['cost_estimate']:.4f}")
        print(f"  Deep Beliefs ì˜ˆì‹œ:")
        for j, belief in enumerate(full_result['result'].get('deep_beliefs', [])[:2], 1):
            print(f"    {j}. {belief[:80]}...")

        comparison_results.append({
            "sample_id": sample['id'],
            "title": sample['title'],
            "mini": mini_result,
            "full": full_result
        })

        await asyncio.sleep(1)  # Rate limiting

    # ì „ì²´ í†µê³„
    print("\n" + "="*80)
    print("ğŸ“ˆ ì „ì²´ í†µê³„")
    print("="*80)

    total_mini_cost = sum(r['mini']['cost_estimate'] for r in comparison_results)
    total_full_cost = sum(r['full']['cost_estimate'] for r in comparison_results)

    avg_mini_beliefs = sum(len(r['mini']['result'].get('deep_beliefs', [])) for r in comparison_results) / len(comparison_results)
    avg_full_beliefs = sum(len(r['full']['result'].get('deep_beliefs', [])) for r in comparison_results) / len(comparison_results)

    print(f"\ní‰ê·  Deep Beliefs ê°œìˆ˜:")
    print(f"  GPT-5-mini: {avg_mini_beliefs:.1f}ê°œ")
    print(f"  GPT-5: {avg_full_beliefs:.1f}ê°œ")

    print(f"\nì´ ë¹„ìš© (3ê°œ ìƒ˜í”Œ):")
    print(f"  GPT-5-mini: ${total_mini_cost:.4f}")
    print(f"  GPT-5: ${total_full_cost:.4f}")
    print(f"  ë¹„ìš© ì°¨ì´: {total_full_cost / total_mini_cost:.1f}x")

    print(f"\nì˜ˆìƒ ì›”ê°„ ë¹„ìš© (ì¼ 100ê°œ ë¶„ì„ ê¸°ì¤€):")
    print(f"  GPT-5-mini: ${(total_mini_cost / len(comparison_results) * 100 * 30):.2f}")
    print(f"  GPT-5: ${(total_full_cost / len(comparison_results) * 100 * 30):.2f}")

    # ê²°ë¡ 
    print("\n" + "="*80)
    print("ğŸ’¡ ê²°ë¡ ")
    print("="*80)

    quality_diff = avg_full_beliefs / avg_mini_beliefs if avg_mini_beliefs > 0 else 1
    cost_ratio = total_full_cost / total_mini_cost if total_mini_cost > 0 else 1

    print(f"\ní’ˆì§ˆ ì°¨ì´: GPT-5ê°€ {quality_diff:.1f}x ë” ë§ì€ Deep Beliefs ì¶”ì¶œ")
    print(f"ë¹„ìš© ì°¨ì´: GPT-5ê°€ {cost_ratio:.1f}x ë” ë¹„ìŒˆ")

    if quality_diff > 1.5 and cost_ratio < 10:
        print("\nâœ… ê¶Œì¥: GPT-5")
        print("   ì´ìœ : í’ˆì§ˆ í–¥ìƒì´ ë¹„ìš© ì¦ê°€ë¥¼ ì •ë‹¹í™”í•¨")
    elif cost_ratio > 20:
        print("\nâœ… ê¶Œì¥: GPT-5-mini")
        print("   ì´ìœ : ë¹„ìš© ëŒ€ë¹„ í’ˆì§ˆì´ ì¶©ë¶„í•¨")
    else:
        print("\nâš–ï¸  ê¶Œì¥: ìƒí™©ì— ë”°ë¼ ì„ íƒ")
        print(f"   - ëŒ€ëŸ‰ ë¶„ì„: GPT-5-mini (ë¹„ìš© íš¨ìœ¨)")
        print(f"   - ì •ë°€ ë¶„ì„: GPT-5 (í’ˆì§ˆ ìš°ì„ )")

    print("\n" + "="*80)

    return comparison_results

if __name__ == '__main__':
    asyncio.run(compare_models())
