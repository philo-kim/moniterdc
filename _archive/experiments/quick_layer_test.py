"""
ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: ê¸°ì¡´ 3-Layer êµ¬ì¡°ê°€ 'íŠ¹ì •í•œ ì„¸ê³„ê´€'ì„ í¬ì°©í•˜ëŠ”ê°€?
"""

import asyncio
import os
import json
from openai import AsyncOpenAI
from supabase import create_client
from dotenv import load_dotenv

load_dotenv()

supabase = create_client(
    os.getenv('SUPABASE_URL'),
    os.getenv('SUPABASE_SERVICE_KEY')
)

client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))


async def main():
    print("=" * 80)
    print("ë¹ ë¥¸ í…ŒìŠ¤íŠ¸: ê¸°ì¡´ layered_perception_extractor.py ê²€ì¦")
    print("=" * 80)

    # Test case: ìœ ì‹¬êµì²´ ì‚¬ê±´
    test_content = {
        "title": '"ë¯¼ì£¼, ì§€ê·€ì—° í•¸ë“œí° êµì²´ ì–´ë–»ê²Œ ì•Œì•˜ë‚˜â€¦ë…ì¬ì‹œëŒ€ ì˜ˆê³ í¸"',
        "body": """ë‚˜ê²½ì› "ë¯¼ì£¼, ì§€ê·€ì—° í•¸ë“œí° êµì²´ ì–´ë–»ê²Œ ì•Œì•˜ë‚˜â€¦ë…ì¬ì‹œëŒ€ ì˜ˆê³ í¸"
ê°œì¸ ì‚¬ì°°ì„ í–ˆë‹¤ê³  ë¯¼ì£¼ë‹¹ì´ ìë°±í•œ ìˆ˜ì¤€
ìœ ì‹¬êµì²´ë¥¼ ì–´ë–»ê²Œ ì•Œì•„ã…‹ã…‹ã…‹ã…‹ë¯¸ì¹œ
ì§€ë“¤ ë§˜ì— ì•ˆë“œëŠ” íŒì‚¬ ì‚¬ì°°í•˜ë ¤ê³  í†µì‹ ì‚¬ í˜‘ë°•í•´ì„œ ì–»ì–´ë‚¸ ì •ë³´
í†µì‹ ì‚¬ë“¤ë„ ìš”ìƒˆ í•´í‚¹ ë¬¸ì œ ë§ê³ 
ì´ê²Œ ì§„ì§œ ë§ëŠ”ê±°ëƒ"""
    }

    print(f"\ní…ŒìŠ¤íŠ¸ ê¸€: {test_content['title'][:50]}...")

    # ê¸°ì¡´ Prompt (layered_perception_extractor.py ê·¸ëŒ€ë¡œ)
    prompt = f"""
ë‹¤ìŒì€ DC Gallery ì •ì¹˜ ê°¤ëŸ¬ë¦¬ì˜ ê¸€ì…ë‹ˆë‹¤:

ì œëª©: {test_content['title']}
ë‚´ìš©: {test_content['body']}

ì´ ê¸€ì„ **3ê°œ ì¸µìœ„**ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ì¼ë°˜ë¡ ì´ ì•„ë‹Œ, **ì´ ê¸€ì“´ì´ê°€ ì‹¤ì œë¡œ ë¯¿ëŠ” êµ¬ì²´ì ì¸ ë‚´ìš©**ì„ ì¶”ì¶œí•˜ì„¸ìš”.

## 1. í‘œë©´ì¸µ (Explicit Layer) - ëª…ì‹œì  ì£¼ì¥
**ê¸€ì—ì„œ ì§ì ‘ ë§í•˜ê³  ìˆëŠ” ê²ƒ**

## 2. ì•”ë¬µì¸µ (Implicit Layer) - ì „ì œí•˜ëŠ” ì‚¬ê³ 
**ë§í•˜ì§€ ì•Šì•˜ì§€ë§Œ ë‹¹ì—°í•˜ê²Œ ì—¬ê¸°ëŠ” ê²ƒ**

âŒ ë‚˜ìœ ì˜ˆ: "ë¹„ê³µê°œ ì •ë³´ë¥¼ ì•ˆë‹¤ = ë¶ˆë²•"
âœ… ì¢‹ì€ ì˜ˆ: "ë¯¼ì£¼ë‹¹ì€ í†µì‹ ì‚¬ë¥¼ í˜‘ë°•í•´ì„œ ê°œì¸ì •ë³´ë¥¼ ì–»ëŠ”ë‹¤"

## 3. ì‹¬ì¸µ (Deep Layer) - ë¬´ì˜ì‹ì  ë¯¿ìŒ
**ì´ ê¸€ì“´ì´ ì§„ì˜ë§Œì˜ ì„¸ê³„ê´€**

âŒ ë‚˜ìœ ì˜ˆ: "ê¶Œë ¥ì€ ë¶€íŒ¨í•œë‹¤" (ëˆ„êµ¬ë‚˜ í•˜ëŠ” ë§)
âœ… ì¢‹ì€ ì˜ˆ: "ë¯¼ì£¼ë‹¹/ì¢ŒíŒŒëŠ” ê³¼ê±° ë…ì¬ì •ê¶Œì²˜ëŸ¼ ì‚¬ì°°ê³¼ íƒ„ì••ìœ¼ë¡œ ê¶Œë ¥ì„ ìœ ì§€í•˜ë ¤ í•œë‹¤"

JSON í˜•ì‹:
{{
  "explicit_claims": [...],
  "implicit_assumptions": [...],
  "reasoning_gaps": [...],
  "deep_beliefs": [...],
  "worldview_hints": "..."
}}
"""

    print("\nGPT-5 í˜¸ì¶œ ì¤‘...")
    response = await client.chat.completions.create(
        model="gpt-5",
        messages=[
            {"role": "system", "content": "You are an expert in discourse analysis. Always respond in valid JSON format."},
            {"role": "user", "content": prompt}
        ],
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)

    print("\n" + "=" * 80)
    print("ì¶”ì¶œ ê²°ê³¼:")
    print("=" * 80)
    print(json.dumps(result, ensure_ascii=False, indent=2))

    # í‰ê°€
    print("\n" + "=" * 80)
    print("í‰ê°€: ì´ê²Œ 'íŠ¹ì •í•œ ì„¸ê³„ê´€'ì„ í¬ì°©í–ˆëŠ”ê°€?")
    print("=" * 80)

    eval_prompt = f"""
ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ í‰ê°€í•˜ì„¸ìš”:

{json.dumps(result, ensure_ascii=False, indent=2)}

ìœ ì €ì˜ ìš”êµ¬ì‚¬í•­:
- "ì €ë“¤ì˜ íŠ¹ì •í•œ ì„¸ê³„ê´€ì„ ì´í•´í•˜ê³  ì‹¶ë‹¤"
- "'ìœ ì‹¬êµì²´ë¥¼ ì–´ë–»ê²Œ ì•Œì•„'ë¼ëŠ” ì§ˆë¬¸ ìì²´ê°€ ê·¸ë“¤ë§Œì˜ ì‹œê°ì´ë‹¤"
- "ì¼ë°˜ë¡ ì´ ì•„ë‹Œ, ì´ ì§„ì˜ íŠ¹ìœ ì˜ ì‹œê°ì´ì–´ì•¼ í•œë‹¤"

í‰ê°€:
1. ì›ë¬¸ì˜ ë…íŠ¹í•œ í‘œí˜„ì´ ì‚´ì•„ìˆëŠ”ê°€? (ì˜ˆ: "ìœ ì‹¬êµì²´ë¥¼ ì–´ë–»ê²Œ ì•Œì•„ã…‹ã…‹ã…‹ã…‹ë¯¸ì¹œ")
2. ì¼ë°˜ë¡ ì´ ì•„ë‹Œ êµ¬ì²´ì ì¸ ë¯¿ìŒì¸ê°€? (ì˜ˆ: "ë¯¼ì£¼ë‹¹ì€ í†µì‹ ì‚¬ í˜‘ë°•")
3. ê·¸ë“¤ë§Œì˜ ë…¼ë¦¬ êµ¬ì¡°ê°€ ë“œëŸ¬ë‚˜ëŠ”ê°€? (ì˜ˆ: ìœ ì‹¬ì •ë³´ ì•Œì•˜ë‹¤ â†’ í†µì‹ ì‚¬ í˜‘ë°• â†’ ì‚¬ë²•ë¶€ ì¥ì•…)
4. ì„¸ê³„ê´€ ì‹¬ë„ê°€ ìˆëŠ”ê°€? (ì˜ˆ: "ì¢ŒíŒŒ = ë…ì¬ ë³¸ì„±, ì—­ì‚¬ ë°˜ë³µ")

ê° í•­ëª© 10ì  ë§Œì , ì´ 40ì .

JSON:
{{
  "original_expression_preserved": 0-10,
  "specific_not_generic": 0-10,
  "unique_logic_structure": 0-10,
  "worldview_depth": 0-10,
  "total": 0-40,
  "key_issue": "ê°€ì¥ í° ë¬¸ì œì ",
  "improvement": "ê°œì„  ë°©ì•ˆ"
}}
"""

    eval_response = await client.chat.completions.create(
        model="gpt-5",
        messages=[
            {"role": "system", "content": "Evaluator. JSON only."},
            {"role": "user", "content": eval_prompt}
        ],
        response_format={"type": "json_object"}
    )

    evaluation = json.loads(eval_response.choices[0].message.content)

    print(f"\nğŸ“Š ì ìˆ˜:")
    print(f"  ì›ë¬¸ í‘œí˜„ ë³´ì¡´: {evaluation['original_expression_preserved']}/10")
    print(f"  íŠ¹ì •ì„± (ì¼ë°˜ë¡  ì•„ë‹˜): {evaluation['specific_not_generic']}/10")
    print(f"  ë…íŠ¹í•œ ë…¼ë¦¬ êµ¬ì¡°: {evaluation['unique_logic_structure']}/10")
    print(f"  ì„¸ê³„ê´€ ì‹¬ë„: {evaluation['worldview_depth']}/10")
    print(f"  ì´ì : {evaluation['total']}/40")

    print(f"\nâŒ í•µì‹¬ ë¬¸ì œ: {evaluation['key_issue']}")
    print(f"ğŸ’¡ ê°œì„  ë°©ì•ˆ: {evaluation['improvement']}")

    # Save
    output = {
        "extraction_result": result,
        "evaluation": evaluation
    }

    with open('/tmp/quick_layer_test_result.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print("\nâœ… ê²°ê³¼ ì €ì¥: /tmp/quick_layer_test_result.json")

    # ê²°ë¡ 
    print("\n" + "=" * 80)
    print("ê²°ë¡ ")
    print("=" * 80)

    if evaluation['total'] >= 30:
        print("âœ… í˜„ì¬ 3-layer êµ¬ì¡°ê°€ ì˜ ì‘ë™í•˜ê³  ìˆìŒ")
        print("   â†’ ë‹¤ìŒ ë‹¨ê³„(clustering, worldview ìƒì„±)ë¡œ ì§„í–‰")
    elif evaluation['total'] >= 20:
        print("âš ï¸  ë¶€ë¶„ì ìœ¼ë¡œ ì‘ë™í•˜ì§€ë§Œ ê°œì„  í•„ìš”")
        print(f"   â†’ {evaluation['improvement']}")
    else:
        print("âŒ ê·¼ë³¸ì ì¸ ë¬¸ì œ ìˆìŒ")
        print(f"   â†’ {evaluation['key_issue']}")
        print(f"   â†’ {evaluation['improvement']}")


if __name__ == '__main__':
    asyncio.run(main())
