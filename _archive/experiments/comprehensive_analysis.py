"""
ì¢…í•© ë¶„ì„: 3-Layer êµ¬ì¡° ê²€ì¦ ë° ìµœì í™” ë°©ì•ˆ

ëª©ì :
1. ê¸°ì¡´ layered_perception_extractor.pyì˜ 3-layer êµ¬ì¡° ê²€ì¦
2. ì‹¤ì œ ë°ì´í„°ë¡œ "íŠ¹ì •í•œ ì„¸ê³„ê´€" ì¶”ì¶œ í…ŒìŠ¤íŠ¸
3. ë¬¸ì œì  ë°œê²¬ ë° ê°œì„  ë°©ì•ˆ ì œì•ˆ
"""

import asyncio
import os
import json
from openai import AsyncOpenAI
from supabase import create_client
from dotenv import load_dotenv

load_dotenv()

SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_SERVICE_KEY')

if not SUPABASE_URL or not SUPABASE_KEY:
    raise Exception(f"Missing env vars: URL={SUPABASE_URL is not None}, KEY={SUPABASE_KEY is not None}")

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))


async def main():
    print("=" * 80)
    print("ì¢…í•© ë¶„ì„: 3-Layer êµ¬ì¡°ì™€ ì„¸ê³„ê´€ íŠ¹ì •ì„± ê²€ì¦")
    print("=" * 80)

    # Step 1: í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
    print("\n\n[Step 1] ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© ë¶„ì„")
    print("-" * 80)

    # Check tables
    contents = supabase.table('contents').select('id', count='exact').execute()
    perceptions = supabase.table('perceptions').select('id', count='exact').execute()
    worldviews = supabase.table('worldviews').select('id', count='exact').execute()

    print(f"Contents: {contents.count}ê°œ")
    print(f"Perceptions: {perceptions.count}ê°œ")
    print(f"Worldviews: {worldviews.count}ê°œ")

    # Check if layered_perceptions table exists
    try:
        layered = supabase.table('layered_perceptions').select('id', count='exact').execute()
        print(f"Layered Perceptions: {layered.count}ê°œ")
        has_layered_table = True
    except:
        print(f"Layered Perceptions: âŒ í…Œì´ë¸” ì—†ìŒ")
        has_layered_table = False

    # Step 2: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¤€ë¹„ (ìœ ì‹¬êµì²´ ì‚¬ë¡€)
    print("\n\n[Step 2] í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¤€ë¹„: 'ìœ ì‹¬êµì²´ ì‚¬ê±´' ê¸€")
    print("-" * 80)

    test_content = {
        "title": '"ë¯¼ì£¼, ì§€ê·€ì—° í•¸ë“œí° êµì²´ ì–´ë–»ê²Œ ì•Œì•˜ë‚˜â€¦ë…ì¬ì‹œëŒ€ ì˜ˆê³ í¸"',
        "body": """ë‚˜ê²½ì› "ë¯¼ì£¼, ì§€ê·€ì—° í•¸ë“œí° êµì²´ ì–´ë–»ê²Œ ì•Œì•˜ë‚˜â€¦ë…ì¬ì‹œëŒ€ ì˜ˆê³ í¸"
ë°•íƒœí›ˆ ì„ ì„ê¸°ì = ë‚˜ê²½ì› êµ­ë¯¼ì˜í˜ ì˜ì›ì€ ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹ì´ ê°œì¸ì •ë³´ê¹Œì§€ ë§˜ëŒ€ë¡œ ë“¤ì¶°ë³´ê³  ìˆë‹¤ë©° "í­ì£¼ë¥¼ ë©ˆì¶œ ê²ƒ"ì„ ìš”êµ¬í–ˆë‹¤. ë‚˜ ì˜ì›ì€ 1ì¼ SNSë¥¼ í†µí•´ "ì¶”ë¯¸ì•  ë²•ì‚¬ìœ„ê°€ ì–´ì œ ì¼ë°©ì ìœ¼ë¡œ ì¶”ì§„í•œ ì¡°í¬ëŒ€ ëŒ€ë²•ì›ì¥ ì²­
naver.me
ê°œì¸ ì‚¬ì°°ì„ í–ˆë‹¤ê³  ë¯¼ì£¼ë‹¹ì´ ìë°±í•œ ìˆ˜ì¤€
ìœ ì‹¬êµì²´ë¥¼ ì–´ë–»ê²Œ ì•Œì•„ã…‹ã…‹ã…‹ã…‹ë¯¸ì¹œ
ì§€ë“¤ ë§˜ì— ì•ˆë“œëŠ” íŒì‚¬ ì‚¬ì°°í•˜ë ¤ê³  í†µì‹ ì‚¬ í˜‘ë°•í•´ì„œ ì–»ì–´ë‚¸ ì •ë³´
í†µì‹ ì‚¬ë“¤ë„ ìš”ìƒˆ í•´í‚¹ ë¬¸ì œ ë§ê³ 
ì´ê²Œ ì§„ì§œ ë§ëŠ”ê±°ëƒ"""
    }

    print(f"ì œëª©: {test_content['title']}")
    print(f"ë³¸ë¬¸: {test_content['body'][:150]}...")

    # Step 3: ê¸°ì¡´ Prompt í…ŒìŠ¤íŠ¸ (layered_perception_extractor.py)
    print("\n\n[Step 3] ê¸°ì¡´ 3-Layer Prompt í…ŒìŠ¤íŠ¸")
    print("-" * 80)

    original_prompt = f"""
ë‹¤ìŒì€ DC Gallery ì •ì¹˜ ê°¤ëŸ¬ë¦¬ì˜ ê¸€ì…ë‹ˆë‹¤:

ì œëª©: {test_content['title']}
ë‚´ìš©: {test_content['body']}

ì´ ê¸€ì„ **3ê°œ ì¸µìœ„**ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ì¼ë°˜ë¡ ì´ ì•„ë‹Œ, **ì´ ê¸€ì“´ì´ê°€ ì‹¤ì œë¡œ ë¯¿ëŠ” êµ¬ì²´ì ì¸ ë‚´ìš©**ì„ ì¶”ì¶œí•˜ì„¸ìš”.

## 1. í‘œë©´ì¸µ (Explicit Layer) - ëª…ì‹œì  ì£¼ì¥
**ê¸€ì—ì„œ ì§ì ‘ ë§í•˜ê³  ìˆëŠ” ê²ƒ**
- ëˆ„ê°€/ë¬´ì—‡ì„ ë¹„ë‚œí•˜ëŠ”ê°€?
- ì–´ë–¤ í–‰ë™/ì‚¬ê±´ì„ ë¬¸ì œ ì‚¼ëŠ”ê°€?
- êµ¬ì²´ì ì¸ ì¸ë¬¼/ì¡°ì§/ì‚¬ê±´ ì´ë¦„ í¬í•¨

## 2. ì•”ë¬µì¸µ (Implicit Layer) - ì „ì œí•˜ëŠ” ì‚¬ê³ 
**ë§í•˜ì§€ ì•Šì•˜ì§€ë§Œ ë‹¹ì—°í•˜ê²Œ ì—¬ê¸°ëŠ” ê²ƒ**

âŒ ë‚˜ìœ ì˜ˆ: "ë¹„ê³µê°œ ì •ë³´ë¥¼ ì•ˆë‹¤ = ë¶ˆë²•"
âœ… ì¢‹ì€ ì˜ˆ: "ë¯¼ì£¼ë‹¹ì€ í†µì‹ ì‚¬ë¥¼ í˜‘ë°•í•´ì„œ ê°œì¸ì •ë³´ë¥¼ ì–»ëŠ”ë‹¤"

âŒ ë‚˜ìœ ì˜ˆ: "ì‚¬ì°°ì€ ë‚˜ì˜ë‹¤"
âœ… ì¢‹ì€ ì˜ˆ: "ì´ë“¤ì€ ë§˜ì— ì•ˆë“œëŠ” íŒì‚¬ê¹Œì§€ ì‚¬ì°°í•œë‹¤ (ì‚¬ë²•ë¶€ ì¥ì•… ì‹œë„)"

**êµ¬ì²´ì ìœ¼ë¡œ:**
- ëˆ„ê°€ ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ ë¬´ì—‡ì„ í•œë‹¤ê³  ë¯¿ëŠ”ê°€?
- ê·¸ë“¤ì˜ ì˜ë„/ëª©ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ëŠ”ê°€?
- ì–´ë–¤ íŒ¨í„´/ì „ëµì´ ìˆë‹¤ê³  ë³´ëŠ”ê°€?

## 3. ì‹¬ì¸µ (Deep Layer) - ë¬´ì˜ì‹ì  ë¯¿ìŒ
**ì´ ê¸€ì“´ì´ ì§„ì˜ë§Œì˜ ì„¸ê³„ê´€**

âŒ ë‚˜ìœ ì˜ˆ: "ê¶Œë ¥ì€ ë¶€íŒ¨í•œë‹¤" (ëˆ„êµ¬ë‚˜ í•˜ëŠ” ë§)
âœ… ì¢‹ì€ ì˜ˆ: "ë¯¼ì£¼ë‹¹/ì¢ŒíŒŒëŠ” ê³¼ê±° ë…ì¬ì •ê¶Œì²˜ëŸ¼ ì‚¬ì°°ê³¼ íƒ„ì••ìœ¼ë¡œ ê¶Œë ¥ì„ ìœ ì§€í•˜ë ¤ í•œë‹¤"

âŒ ë‚˜ìœ ì˜ˆ: "ì‘ì€ ë¬¸ì œê°€ ì»¤ì§„ë‹¤"
âœ… ì¢‹ì€ ì˜ˆ: "ì§€ê¸ˆì˜ ì‘ì€ ì‚¬ì°°ì´ ê³¼ê±° ë…ì¬ì‹œëŒ€ì²˜ëŸ¼ ì „ë©´ì  ê°ì‹œêµ­ê°€ë¡œ ë°œì „í•œë‹¤"

**êµ¬ì²´ì ìœ¼ë¡œ:**
- ì´ ì§„ì˜ì´ **ì—­ì‚¬ë¥¼ ì–´ë–»ê²Œ ë³´ëŠ”ê°€**? (ê³¼ê±° ì‚¬ë¡€ â†’ í˜„ì¬ ì—°ê²°)
- **ìƒëŒ€í¸ì˜ ë³¸ì§ˆ**ì„ ì–´ë–»ê²Œ ê·œì •í•˜ëŠ”ê°€? (ë¯¼ì£¼ë‹¹/ì¢ŒíŒŒ/ì¤‘êµ­ = ?)
- **ì„¸ìƒì˜ ì‘ë™ ì›ë¦¬**ë¥¼ ì–´ë–»ê²Œ ì´í•´í•˜ëŠ”ê°€? (Aê°€ ì¼ì–´ë‚˜ë©´ ë°˜ë“œì‹œ Bê°€ ì¼ì–´ë‚œë‹¤)

JSON í˜•ì‹:
{{
  "explicit_claims": [
    {{
      "subject": "ë¯¼ì£¼ë‹¹",
      "predicate": "ìœ ì‹¬êµì²´ ì •ë³´ë¥¼ ë¶ˆë²•ìœ¼ë¡œ ì–»ì—ˆë‹¤",
      "evidence_cited": "ë‚˜ê²½ì› ì˜ì› SNS - ì–´ë–»ê²Œ ì•Œì•˜ë‚˜",
      "quote": "ìœ ì‹¬êµì²´ë¥¼ ì–´ë–»ê²Œ ì•Œì•„"
    }}
  ],
  "implicit_assumptions": [
    "ë¯¼ì£¼ë‹¹ì€ í†µì‹ ì‚¬ë¥¼ í˜‘ë°•í•´ì„œ ê°œì¸ ì‚¬ì°°ìš© ì •ë³´ë¥¼ ì–»ëŠ”ë‹¤",
    "ë§˜ì— ì•ˆë“œëŠ” íŒì‚¬ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ ì‚¬ì°°í•œë‹¤ (ì‚¬ë²•ë¶€ ì¥ì•… ì‹œë„)"
  ],
  "reasoning_gaps": [
    {{
      "from": "ìœ ì‹¬êµì²´ ì •ë³´ë¥¼ ì•Œì•˜ë‹¤",
      "to": "í†µì‹ ì‚¬ í˜‘ë°•ìœ¼ë¡œ ì–»ì—ˆë‹¤",
      "gap": "ì •ìƒì  ë°©ë²• ê°€ëŠ¥ì„±ì€ ë°°ì œí•˜ê³  ì¦‰ì‹œ ë¶ˆë²•ìœ¼ë¡œ ë‹¨ì •"
    }}
  ],
  "deep_beliefs": [
    "ë¯¼ì£¼ë‹¹/ì¢ŒíŒŒëŠ” ê³¼ê±° ë…ì¬ì •ê¶Œì²˜ëŸ¼ ì‚¬ì°°ë¡œ ë°˜ëŒ€íŒŒë¥¼ ì œê±°í•œë‹¤",
    "ì§€ê¸ˆì˜ ì‘ì€ ì‚¬ì°°ì´ ê³§ ì „ë©´ì  ê°ì‹œë…ì¬ ì‚¬íšŒë¡œ ë°œì „í•œë‹¤ (ì—­ì‚¬ ë°˜ë³µ)",
    "ì´ë“¤ì€ ì‚¬ë²•ë¶€ê¹Œì§€ ì¥ì•…í•´ì„œ ì™„ì „í•œ ê¶Œë ¥ì„ ì°¨ì§€í•˜ë ¤ í•œë‹¤"
  ],
  "worldview_hints": "ê³¼ê±° ë…ì¬ â†’ í˜„ì¬ ì¬í˜„, ì¢ŒíŒŒ = ë…ì¬ ë³¸ì„±, ì‚¬ë²•ë¶€ ì¥ì•… ì‹œë„"
}}
"""

    print("GPT-5 í˜¸ì¶œ ì¤‘...")
    response = await client.chat.completions.create(
        model="gpt-5",
        messages=[
            {"role": "system", "content": "You are an expert in discourse analysis. Always respond in valid JSON format."},
            {"role": "user", "content": original_prompt}
        ],
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)

    print("\nâœ… ì¶”ì¶œ ê²°ê³¼:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

    # Step 4: ê²°ê³¼ í‰ê°€
    print("\n\n[Step 4] ê²°ê³¼ í‰ê°€: 'íŠ¹ì •í•œ ì„¸ê³„ê´€' í¬ì°© ì—¬ë¶€")
    print("-" * 80)

    evaluation_prompt = f"""
ë‹¤ìŒì€ "ìœ ì‹¬êµì²´ ì‚¬ê±´" ê¸€ì— ëŒ€í•œ 3-layer ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

{json.dumps(result, ensure_ascii=False, indent=2)}

ì´ ë¶„ì„ì´ **"ì €ë“¤ì˜ íŠ¹ì •í•œ ì„¸ê³„ê´€"ì„ í¬ì°©í–ˆëŠ”ì§€** í‰ê°€í•´ì£¼ì„¸ìš”.

í‰ê°€ ê¸°ì¤€:
1. **íŠ¹ì •ì„± (Specificity)**: ì¼ë°˜ë¡ ì´ ì•„ë‹Œ ì´ ì§„ì˜ íŠ¹ìœ ì˜ ì‹œê°ì¸ê°€?
   - âŒ "ê¶Œë ¥ì€ ë¶€íŒ¨í•œë‹¤" (ëˆ„êµ¬ë‚˜ í•˜ëŠ” ë§)
   - âœ… "ë¯¼ì£¼ë‹¹ì€ í†µì‹ ì‚¬ í˜‘ë°•ìœ¼ë¡œ ê°œì¸ì •ë³´ë¥¼ ì–»ëŠ”ë‹¤" (êµ¬ì²´ì )

2. **ì›ë¬¸ ë³´ì¡´**: ì›ë¬¸ì˜ ë…íŠ¹í•œ í‘œí˜„ì´ ì‚´ì•„ìˆëŠ”ê°€?
   - âŒ "ê°œì¸ì •ë³´ ë¶ˆë²• ì·¨ë“ ì˜í˜¹" (ì¶”ìƒí™”)
   - âœ… "ìœ ì‹¬êµì²´ë¥¼ ì–´ë–»ê²Œ ì•Œì•„ã…‹ã…‹ã…‹ã…‹ë¯¸ì¹œ" (ì›ë¬¸ ê·¸ëŒ€ë¡œ)

3. **ë…¼ë¦¬ êµ¬ì¡°**: ê·¸ë“¤ë§Œì˜ ì¶”ë¡  ë°©ì‹ì´ ë“œëŸ¬ë‚˜ëŠ”ê°€?
   - "ìœ ì‹¬êµì²´ ì •ë³´ ì•Œì•˜ë‹¤" â†’ "í†µì‹ ì‚¬ í˜‘ë°•" â†’ "ì‚¬ë²•ë¶€ ì¥ì•…" â†’ "ë…ì¬ ì¬í˜„"

4. **ì„¸ê³„ê´€ ì‹¬ë„**: ë‹¨ìˆœ ì‚¬ì‹¤ ë‚˜ì—´ì´ ì•„ë‹Œ ì„¸ìƒ ì‘ë™ ì›ë¦¬ì— ëŒ€í•œ ë¯¿ìŒì¸ê°€?

ê° í•­ëª©ì„ 10ì  ë§Œì ìœ¼ë¡œ í‰ê°€í•˜ê³ , ê°œì„  ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.

JSON í˜•ì‹:
{{
  "specificity_score": 0-10,
  "original_text_preservation": 0-10,
  "logic_structure_clarity": 0-10,
  "worldview_depth": 0-10,
  "total_score": 0-40,
  "strengths": ["ê°•ì 1", "ê°•ì 2"],
  "weaknesses": ["ì•½ì 1", "ì•½ì 2"],
  "improvement_suggestions": ["ê°œì„ ì•ˆ1", "ê°œì„ ì•ˆ2"]
}}
"""

    print("í‰ê°€ ì¤‘...")
    eval_response = await client.chat.completions.create(
        model="gpt-5",
        messages=[
            {"role": "system", "content": "You are an expert evaluator. Always respond in valid JSON format."},
            {"role": "user", "content": evaluation_prompt}
        ],
        response_format={"type": "json_object"}
    )

    evaluation = json.loads(eval_response.choices[0].message.content)

    print("\nğŸ“Š í‰ê°€ ê²°ê³¼:")
    print(f"  íŠ¹ì •ì„± (Specificity): {evaluation['specificity_score']}/10")
    print(f"  ì›ë¬¸ ë³´ì¡´: {evaluation['original_text_preservation']}/10")
    print(f"  ë…¼ë¦¬ êµ¬ì¡°: {evaluation['logic_structure_clarity']}/10")
    print(f"  ì„¸ê³„ê´€ ì‹¬ë„: {evaluation['worldview_depth']}/10")
    print(f"  ì´ì : {evaluation['total_score']}/40")

    print("\nâœ… ê°•ì :")
    for s in evaluation['strengths']:
        print(f"  - {s}")

    print("\nâŒ ì•½ì :")
    for w in evaluation['weaknesses']:
        print(f"  - {w}")

    print("\nğŸ’¡ ê°œì„  ì œì•ˆ:")
    for i in evaluation['improvement_suggestions']:
        print(f"  - {i}")

    # Step 5: ë‹¤ë¥¸ 10ê°œ ê¸€ë¡œ ì¼ê´€ì„± í…ŒìŠ¤íŠ¸
    print("\n\n[Step 5] ì¼ê´€ì„± í…ŒìŠ¤íŠ¸: ë‹¤ë¥¸ ê¸€ë“¤ì—ì„œë„ 'íŠ¹ì •ì„±' ìœ ì§€ë˜ëŠ”ê°€?")
    print("-" * 80)

    # Get 10 random posts
    sample_contents = supabase.table('contents')\
        .select('id, title, body')\
        .neq('body', '')\
        .limit(10)\
        .execute().data

    print(f"10ê°œ ê¸€ ìƒ˜í”Œë§ ì™„ë£Œ")

    scores = []
    for i, content in enumerate(sample_contents, 1):
        print(f"\n[{i}/10] {content['title'][:50]}...")

        # Extract
        test_prompt = original_prompt.replace(test_content['title'], content['title'])\
            .replace(test_content['body'], content['body'][:2000])

        response = await client.chat.completions.create(
            model="gpt-5",
            messages=[
                {"role": "system", "content": "You are an expert in discourse analysis. Always respond in valid JSON format."},
                {"role": "user", "content": test_prompt}
            ],
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)

        # Quick evaluation
        eval_response = await client.chat.completions.create(
            model="gpt-5",
            messages=[
                {"role": "system", "content": "You are an expert evaluator. Respond with just a number 0-40."},
                {"role": "user", "content": f"""
ì´ ë¶„ì„ì´ "íŠ¹ì •í•œ ì„¸ê³„ê´€"ì„ í¬ì°©í–ˆëŠ”ì§€ 0-40ì  í‰ê°€:
{json.dumps(result, ensure_ascii=False)}

íŠ¹ì •ì„±(0-10) + ì›ë¬¸ë³´ì¡´(0-10) + ë…¼ë¦¬êµ¬ì¡°(0-10) + ì„¸ê³„ê´€ì‹¬ë„(0-10)

JSON: {{"score": ìˆ«ì}}
"""}
            ],
            response_format={"type": "json_object"}
        )

        score = json.loads(eval_response.choices[0].message.content)['score']
        scores.append(score)
        print(f"  ì ìˆ˜: {score}/40")

    avg_score = sum(scores) / len(scores)
    print(f"\ní‰ê·  ì ìˆ˜: {avg_score:.1f}/40")
    print(f"ì ìˆ˜ ë²”ìœ„: {min(scores)} ~ {max(scores)}")

    # Step 6: ìµœì¢… ì§„ë‹¨ ë° ì œì•ˆ
    print("\n\n[Step 6] ìµœì¢… ì§„ë‹¨ ë° ê°œì„  ë°©ì•ˆ")
    print("=" * 80)

    diagnosis_prompt = f"""
**í˜„ì¬ ì‹œìŠ¤í…œ ë¶„ì„ ê²°ê³¼:**

1. ë°ì´í„°ë² ì´ìŠ¤ í˜„í™©:
   - Contents: {contents.count}ê°œ
   - Perceptions: {perceptions.count}ê°œ
   - Worldviews: {worldviews.count}ê°œ
   - Layered Perceptions: {"ìˆìŒ" if has_layered_table else "ì—†ìŒ"}

2. 3-Layer Prompt ì„±ëŠ¥:
   - í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì ìˆ˜: {evaluation['total_score']}/40
   - 10ê°œ ìƒ˜í”Œ í‰ê· : {avg_score:.1f}/40
   - ì¼ê´€ì„±: {"ë†’ìŒ" if max(scores) - min(scores) < 15 else "ë‚®ìŒ"}

3. ì£¼ìš” ì•½ì :
{chr(10).join(f"   - {w}" for w in evaluation['weaknesses'])}

**ì§ˆë¬¸:**

ìœ ì €ì˜ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì€:
"ì €ë“¤ì˜ íŠ¹ì •í•œ ì„¸ê³„ê´€ì„ ì´í•´í•˜ê³  ì‹¶ë‹¤.
'ìœ ì‹¬êµì²´ë¥¼ ì–´ë–»ê²Œ ì•Œì•„'ë¼ëŠ” ì§ˆë¬¸ ìì²´ê°€ ê·¸ë“¤ë§Œì˜ ì‹œê°ì´ë‹¤."

í˜„ì¬ 3-layer ì‹œìŠ¤í…œì´ ì´ ëª©ì ì„ ë‹¬ì„±í•˜ê³  ìˆëŠ”ê°€?

ë§Œì•½ ë¶€ì¡±í•˜ë‹¤ë©´:
1. **êµ¬ì¡° ë¬¸ì œ**ì¸ê°€? (Layer êµ¬ì¡° ìì²´ê°€ ì˜ëª»ë¨)
2. **Prompt ë¬¸ì œ**ì¸ê°€? (ì§€ì‹œì‚¬í•­ì´ ë¶€ì¡±/ë¶ˆëª…í™•)
3. **ëª¨ë¸ í•œê³„**ì¸ê°€? (GPTê°€ íŠ¹ì •ì„±ì„ í¬ì°© ëª»í•¨)
4. **ë°ì´í„° ë¬¸ì œ**ì¸ê°€? (DC ê¸€ ìì²´ê°€ íŠ¹ì •ì„±ì´ ë¶€ì¡±)

ê·¸ë¦¬ê³  ìµœì„ ì˜ í•´ê²° ë°©ì•ˆì€?

JSON í˜•ì‹ìœ¼ë¡œ ì¢…í•© ì§„ë‹¨ ë° ì œì•ˆ:
{{
  "current_performance": "good/acceptable/poor",
  "root_cause": "structure/prompt/model/data",
  "detailed_diagnosis": "ìì„¸í•œ ì§„ë‹¨...",
  "recommended_approach": {{
    "keep": ["ìœ ì§€í•  ê²ƒë“¤"],
    "fix": ["ìˆ˜ì •í•  ê²ƒë“¤"],
    "add": ["ì¶”ê°€í•  ê²ƒë“¤"]
  }},
  "concrete_next_steps": [
    {{
      "step": "1ë‹¨ê³„ ì‘ì—…",
      "action": "êµ¬ì²´ì  ì•¡ì…˜",
      "expected_improvement": "ê¸°ëŒ€ íš¨ê³¼"
    }}
  ]
}}
"""

    print("ì¢…í•© ì§„ë‹¨ ì¤‘...")
    final_response = await client.chat.completions.create(
        model="gpt-5",
        messages=[
            {"role": "system", "content": "You are a senior system architect. Provide deep analysis."},
            {"role": "user", "content": diagnosis_prompt}
        ],
        response_format={"type": "json_object"}
    )

    diagnosis = json.loads(final_response.choices[0].message.content)

    print(f"\ní˜„ì¬ ì„±ëŠ¥: {diagnosis['current_performance'].upper()}")
    print(f"ê·¼ë³¸ ì›ì¸: {diagnosis['root_cause'].upper()}")

    print(f"\nğŸ“‹ ì§„ë‹¨:")
    print(diagnosis['detailed_diagnosis'])

    print(f"\nâœ… ìœ ì§€í•  ê²ƒ:")
    for k in diagnosis['recommended_approach']['keep']:
        print(f"  - {k}")

    print(f"\nğŸ”§ ìˆ˜ì •í•  ê²ƒ:")
    for f in diagnosis['recommended_approach']['fix']:
        print(f"  - {f}")

    print(f"\nâ• ì¶”ê°€í•  ê²ƒ:")
    for a in diagnosis['recommended_approach']['add']:
        print(f"  - {a}")

    print(f"\n\nğŸ“ êµ¬ì²´ì  Next Steps:")
    for step in diagnosis['concrete_next_steps']:
        print(f"\n{step['step']}")
        print(f"  ì•¡ì…˜: {step['action']}")
        print(f"  ê¸°ëŒ€íš¨ê³¼: {step['expected_improvement']}")

    # Save results
    output = {
        "database_status": {
            "contents": contents.count,
            "perceptions": perceptions.count,
            "worldviews": worldviews.count,
            "has_layered_table": has_layered_table
        },
        "test_results": {
            "single_case_score": evaluation['total_score'],
            "average_score": avg_score,
            "score_range": [min(scores), max(scores)],
            "evaluation_details": evaluation
        },
        "diagnosis": diagnosis
    }

    with open('/tmp/comprehensive_analysis_result.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print("\n\n" + "=" * 80)
    print("âœ… ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ ì €ì¥: /tmp/comprehensive_analysis_result.json")
    print("=" * 80)


if __name__ == '__main__':
    asyncio.run(main())
