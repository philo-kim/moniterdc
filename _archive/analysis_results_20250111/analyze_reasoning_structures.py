"""
ì¶”ë¡  êµ¬ì¡° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ëª©ì : ì‹¤ì œ GPT-5 APIë¡œ ëª¨ë“  perceptionì˜ ì¶”ë¡  êµ¬ì¡°ë¥¼ ìƒì„¸ ë¶„ì„
"""

import os
import json
import asyncio
from openai import AsyncOpenAI
from engines.utils.supabase_client import get_supabase

client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))
supabase = get_supabase()


async def analyze_reasoning_structure(perception):
    """
    ë‹¨ì¼ perceptionì˜ ì¶”ë¡  êµ¬ì¡° ìƒì„¸ ë¶„ì„

    ë°˜í™˜:
    - ì¶”ë¡  ë©”ì»¤ë‹ˆì¦˜ (ì¦‰ì‹œ_ë‹¨ì •, í•„ì—°ì _ì¸ê³¼, í‘œë©´_ë¶€ì • ë“±)
    - ìƒëµëœ ì¶”ë¡  ë‹¨ê³„
    - í–‰ìœ„ì ë° ëª©ì 
    - ì¼ê´€ì„± íŒ¨í„´
    """

    # ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„
    explicit = perception.get('explicit_claims', [])
    implicit = perception.get('implicit_assumptions', [])
    gaps = perception.get('reasoning_gaps', [])
    deep = perception.get('deep_beliefs', [])

    prompt = f"""
ë‹¤ìŒì€ DC Gallery ì •ì¹˜ ê¸€ì˜ 3ì¸µ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.

**í‘œë©´ ì£¼ì¥ (Explicit)**:
{json.dumps(explicit, ensure_ascii=False, indent=2)}

**ì•”ë¬µì  ì „ì œ (Implicit)**:
{json.dumps(implicit, ensure_ascii=False, indent=2)}

**ì¶”ë¡  ê³¼ì • (Reasoning Gaps)**:
{json.dumps(gaps, ensure_ascii=False, indent=2)}

**ì‹¬ì¸µ ë¯¿ìŒ (Deep Beliefs)**:
{json.dumps(deep, ensure_ascii=False, indent=2)}

---

ì´ ê¸€ì˜ **ì¶”ë¡  êµ¬ì¡°**ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì¶”ë¡  ë©”ì»¤ë‹ˆì¦˜** (í•´ë‹¹ë˜ëŠ” ê²ƒ ëª¨ë‘):
   - ì¦‰ì‹œ_ë‹¨ì •: ê´€ì°° â†’ (ì¤‘ê°„ ê³¼ì • ìƒëµ) â†’ ê²°ë¡ 
   - í•„ì—°ì _ì¸ê³¼: X â†’ ë°˜ë“œì‹œ/ê³§/í•„ì—°ì ìœ¼ë¡œ â†’ Y
   - í‘œë©´_ë¶€ì •: í‘œë©´ì€ X / ì‹¤ì œëŠ” Y
   - ì—­ì‚¬_íˆ¬ì‚¬: ê³¼ê±° íŒ¨í„´ â†’ í˜„ì¬ ë°˜ë³µ
   - ë„¤íŠ¸ì›Œí¬_ì¶”ë¡ : ì—°ê²° â†’ ì¡°ì§ì  ê³µëª¨

2. **ìƒëµëœ ì¶”ë¡  ë‹¨ê³„** (ë¬´ì—‡ì„ ê²€ì¦í•˜ì§€ ì•Šì•˜ë‚˜?):
   - ì˜ˆ: ì •ë³´ ì¶œì²˜ íƒìƒ‰, í•©ë²• ê°€ëŠ¥ì„±, ì§ì ‘ ì¦ê±° ë“±

3. **í–‰ìœ„ì ê·œì •**:
   - ì£¼ì²´: ëˆ„ê°€ í–‰ë™í•˜ëŠ”ê°€?
   - ëª©ì : ì™œ ê·¸ë ‡ê²Œ í•œë‹¤ê³  ë³´ëŠ”ê°€?
   - ë°©ë²•: ì–´ë–¤ ìˆ˜ë‹¨ì„ ì“´ë‹¤ê³  ë³´ëŠ”ê°€?

4. **ë…¼ë¦¬ ì²´ì¸** (ê´€ì°° â†’ ... â†’ ê²°ë¡ ):
   - Step 1: êµ¬ì²´ì  ê´€ì°°
   - Step 2, 3, ...: ì¤‘ê°„ ì¶”ë¡  (ìˆë‹¤ë©´)
   - Final: ìµœì¢… ê²°ë¡ 

JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
{{
  "mechanisms": ["ì¦‰ì‹œ_ë‹¨ì •", ...],
  "skipped_steps": ["ì¶œì²˜ íƒìƒ‰ ì•ˆ í•¨", ...],
  "actor": {{
    "subject": "ë¯¼ì£¼ë‹¹/ì¢ŒíŒŒ",
    "purpose": "ê¶Œë ¥ ìœ ì§€",
    "methods": ["ì‚¬ì°°", "í˜‘ë°•"]
  }},
  "logic_chain": [
    "ì •ë³´ íŒŒì•…",
    "ë¶ˆë²•ìœ¼ë¡œ ë‹¨ì •",
    "ë…ì¬ ì‹œë„"
  ],
  "consistency_pattern": "ì •ë³´_íŒŒì•…_ë¶ˆë²•_í•´ì„"
}}
"""

    try:
        response = await client.chat.completions.create(
            model="gpt-4o",  # gpt-5 ì‚¬ìš© ì‹œ ë³€ê²½
            messages=[
                {"role": "system", "content": "You are an expert in analyzing reasoning structures in political discourse. Always respond in valid JSON."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.3
        )

        result = json.loads(response.choices[0].message.content)
        return result

    except Exception as e:
        print(f"  âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None


async def analyze_all_perceptions(limit=None):
    """
    ëª¨ë“  perception ë¶„ì„
    """

    print("="*80)
    print("ì¶”ë¡  êµ¬ì¡° ë¶„ì„ ì‹œì‘")
    print("="*80)

    # 1. ëª¨ë“  perception ë¡œë“œ
    query = supabase.table('layered_perceptions').select('*')
    if limit:
        query = query.limit(limit)

    perceptions = query.execute().data
    print(f"\nì´ {len(perceptions)}ê°œ perception ë¶„ì„ ì‹œì‘\n")

    # 2. ë°°ì¹˜ ì²˜ë¦¬
    batch_size = 5  # API ì œí•œ ê³ ë ¤
    results = []

    for i in range(0, len(perceptions), batch_size):
        batch = perceptions[i:i+batch_size]

        print(f"ë°°ì¹˜ {i//batch_size + 1}/{(len(perceptions)-1)//batch_size + 1}")

        # ë³‘ë ¬ ì²˜ë¦¬
        tasks = []
        for lp in batch:
            tasks.append(analyze_reasoning_structure(lp))

        batch_results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ ì €ì¥
        for j, result in enumerate(batch_results):
            if isinstance(result, Exception):
                print(f"  âŒ {batch[j]['id']}: {result}")
            elif result:
                results.append({
                    'perception_id': batch[j]['id'],
                    'content_id': batch[j]['content_id'],
                    'reasoning_structure': result
                })
                print(f"  âœ“ {batch[j]['id'][:8]}... - {result.get('consistency_pattern', 'unknown')}")

        # Rate limit ê³ ë ¤
        await asyncio.sleep(1)

    print(f"\nâœ… {len(results)}ê°œ ë¶„ì„ ì™„ë£Œ")

    # 3. ê²°ê³¼ ì €ì¥
    output_file = '_reasoning_structures_analysis.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"âœ… ê²°ê³¼ ì €ì¥: {output_file}")

    return results


async def main():
    """ë©”ì¸ ì‹¤í–‰"""

    # ì „ì²´ ë°ì´í„° ë¶„ì„
    print("ğŸš€ ì „ì²´ ë°ì´í„° ë¶„ì„ ì‹¤í–‰")
    results = await analyze_all_perceptions()

    # íŒ¨í„´ ë¶„ì„
    print("\n" + "="*80)
    print("íŒ¨í„´ ë¶„ì„")
    print("="*80)

    from collections import Counter

    all_mechanisms = []
    all_patterns = []

    for r in results:
        structure = r['reasoning_structure']
        all_mechanisms.extend(structure.get('mechanisms', []))
        pattern = structure.get('consistency_pattern', 'unknown')
        all_patterns.append(pattern)

    print("\në©”ì»¤ë‹ˆì¦˜ ë¶„í¬:")
    for mech, count in Counter(all_mechanisms).most_common():
        print(f"  {mech}: {count}ê°œ")

    print("\nì¼ê´€ì„± íŒ¨í„´:")
    for pattern, count in Counter(all_patterns).most_common(10):
        print(f"  {pattern}: {count}ê°œ")

    print("\n" + "="*80)
    print("âœ… ì „ì²´ ë¶„ì„ ì™„ë£Œ")
    print("="*80)


if __name__ == "__main__":
    asyncio.run(main())
