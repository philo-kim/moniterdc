"""
GPT-5 Í∏∞Î∞ò ÏÑ∏Í≥ÑÍ¥Ä ÌÜµÌï© Ïä§ÌÅ¨Î¶ΩÌä∏

Î¨∏Ï†ú: 484Í∞úÏùò Í≥†Ïú†Ìïú consistency_pattern ‚Üí Ïã§ÏßàÏ†Å ÏÑ∏Í≥ÑÍ¥ÄÏù¥ ÏïÑÎãò
Ìï¥Í≤∞: GPT-5Î°ú Ï†ÑÏ≤¥ Î∂ÑÏÑù Í≤∞Í≥ºÎ•º ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅÌïòÏó¨ ÏßÑÏßú ÏÑ∏Í≥ÑÍ¥Ä Ï∂îÏ∂ú
"""

import os
import json
import asyncio
from openai import AsyncOpenAI
from collections import Counter

client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))

async def consolidate_worldviews():
    """
    GPT-5Î•º ÏÇ¨Ïö©Ìï¥ 484Í∞ú Ìå®ÌÑ¥ÏùÑ 5-10Í∞ú Ïã§ÏßàÏ†Å ÏÑ∏Í≥ÑÍ¥ÄÏúºÎ°ú ÌÜµÌï©
    """

    print("="*80)
    print("GPT-5 Í∏∞Î∞ò ÏÑ∏Í≥ÑÍ¥Ä ÌÜµÌï©")
    print("="*80)

    # 1. Î∂ÑÏÑù Í≤∞Í≥º Î°úÎìú
    with open('_reasoning_structures_analysis.json', 'r', encoding='utf-8') as f:
        all_data = json.load(f)

    print(f"\n‚úÖ {len(all_data)}Í∞ú Î∂ÑÏÑù Í≤∞Í≥º Î°úÎìú")

    # 2. ÏöîÏïΩ Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ (GPT-5 ÌÜ†ÌÅ∞ Ï†úÌïú Í≥†Î†§)
    summary_data = []
    for item in all_data[:200]:  # ÏÉòÌîå 200Í∞ú
        rs = item['reasoning_structure']
        summary_data.append({
            'mechanisms': rs.get('mechanisms', []),
            'actor': rs.get('actor', {}).get('subject', ''),
            'purpose': rs.get('actor', {}).get('purpose', ''),
            'pattern': rs.get('consistency_pattern', ''),
            'logic_chain': rs.get('logic_chain', [])[:3]  # Ï≤òÏùå 3Îã®Í≥ÑÎßå
        })

    # 3. GPT-5ÏóêÍ≤å ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅ ÏöîÏ≤≠
    prompt = f"""
Îã§ÏùåÏùÄ DC Gallery Ï†ïÏπò Í∏Ä 200Í∞úÏùò Ï∂îÎ°† Íµ¨Ï°∞ Î∂ÑÏÑù Í≤∞Í≥ºÏûÖÎãàÎã§.

{json.dumps(summary_data, ensure_ascii=False, indent=1)}

Ïù¥ Îç∞Ïù¥ÌÑ∞Î•º Î∂ÑÏÑùÌï¥ÏÑú **5-10Í∞úÏùò ÌïµÏã¨ ÏÑ∏Í≥ÑÍ¥Ä**ÏùÑ Ï∂îÏ∂úÌï¥Ï£ºÏÑ∏Ïöî.

**ÏöîÍµ¨ÏÇ¨Ìï≠:**

1. Í∞Å ÏÑ∏Í≥ÑÍ¥ÄÏùÄ **Ï∂îÎ°† Î©îÏª§ÎãàÏ¶ò Í∏∞Î∞ò**Ïù¥Ïñ¥Ïïº Ìï©ÎãàÎã§ (Ï£ºÏ†úÍ∞Ä ÏïÑÎãò)
   - Ï¢ãÏùÄ Ïòà: "ÎØºÏ£ºÎãπÏùò Ïñ¥Îñ§ ÌñâÎèôÎèÑ ÎèÖÏû¨ ÏãúÎèÑÎ°ú Ìï¥ÏÑùÌïòÎäî Íµ¨Ï°∞"
   - ÎÇòÏÅú Ïòà: "ÎØºÏ£ºÎãπÏóê ÎåÄÌïú Ïù∏Ïãù" (Ïù¥Í±¥ Ï£ºÏ†úÏûÑ)

2. Í∞Å ÏÑ∏Í≥ÑÍ¥ÄÏùÄ **Îã§ÏñëÌïú ÏÇ¨Í±¥Ïóê Ï†ÅÏö© Í∞ÄÎä•**Ìï¥Ïïº Ìï©ÎãàÎã§
   - Ïú†Ïã¨ÍµêÏ≤¥, ÏßëÌöåÏ†úÌïú, Î≤ïÏïàÎ∞úÏùò Îì± Ï†ÑÌòÄ Îã§Î•∏ ÏÇ¨Í±¥ÏóêÎèÑ Í∞ôÏùÄ ÎÖºÎ¶¨ Ï†ÅÏö©

3. ÌñâÏúÑÏûê Ï§ëÏã¨ÏúºÎ°ú Î∂ÑÎ•ò:
   - ÎØºÏ£ºÎãπ/Ï¢åÌååÏóê ÎåÄÌïú Ìï¥ÏÑù
   - Ï§ëÍµ≠Ïóê ÎåÄÌïú Ìï¥ÏÑù
   - Ïñ∏Î°†/ÏÇ¨Î≤ïÎ∂ÄÏóê ÎåÄÌïú Ìï¥ÏÑù
   - Î≥¥Ïàò ÏßÑÏòÅ ÏûêÏã†Îì§Ïóê ÎåÄÌïú Ìï¥ÏÑù

4. Í∞Å ÏÑ∏Í≥ÑÍ¥ÄÎßàÎã§:
   - ÌïµÏã¨ Î©îÏª§ÎãàÏ¶ò (Ï¶âÏãú_Îã®Ï†ï, ÌïÑÏó∞Ï†Å_Ïù∏Í≥º Îì±)
   - ÌñâÏúÑÏûê
   - Ï∂îÏ†ï Î™©Ï†Å
   - ÎÖºÎ¶¨ Íµ¨Ï°∞ (A ‚Üí B ‚Üí C)

JSON ÌòïÏãù:
{{
  "worldviews": [
    {{
      "title": "ÎØºÏ£ºÎãπ/Ï¢åÌååÏùò Ï†ïÎ≥¥ ÌååÏïÖ ‚Üí Ï¶âÏãú Î∂àÎ≤ï/ÏÇ¨Ï∞∞Î°ú Ìï¥ÏÑù",
      "actor": "ÎØºÏ£ºÎãπ/Ï¢åÌåå",
      "core_mechanisms": ["Ï¶âÏãú_Îã®Ï†ï", "Ïó≠ÏÇ¨_Ìà¨ÏÇ¨"],
      "logic_pattern": {{
        "trigger": "ÎØºÏ£ºÎãπÏù¥ Ïñ¥Îñ§ Ï†ïÎ≥¥Î•º ÏïåÍ≥† ÏûàÏùå",
        "skipped_verification": ["Ï†ïÎ≥¥ Ï∂úÏ≤ò ÌôïÏù∏", "Ìï©Î≤ï Í∞ÄÎä•ÏÑ±"],
        "conclusion": "Î∂àÎ≤ï ÏÇ¨Ï∞∞ Î∞è ÎèÖÏû¨ ÏãúÎèÑ"
      }},
      "examples": ["Ïú†Ïã¨ÍµêÏ≤¥ Ï†ïÎ≥¥", "ÏßëÌöå Ï†ïÎ≥¥"],
      "estimated_coverage_pct": 15
    }}
  ]
}}

**Ï§ëÏöî:** ÌÜµÌï© Ïãú ÌäπÏ†ïÏÑ±ÏùÑ ÏûÉÏßÄ ÎßàÏÑ∏Ïöî. Í∞Å ÏÑ∏Í≥ÑÍ¥ÄÏùÄ Íµ¨Ï≤¥Ï†ÅÏù∏ ÎÖºÎ¶¨ Ìå®ÌÑ¥ÏùÑ Í∞ÄÏ†∏Ïïº Ìï©ÎãàÎã§.
"""

    print("\nü§ñ GPT-5Î°ú ÏÑ∏Í≥ÑÍ¥Ä ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅ Ï§ë...")

    response = await client.chat.completions.create(
        model="gpt-5",
        messages=[
            {"role": "system", "content": "You are an expert in cognitive structure analysis. Always respond in valid JSON."},
            {"role": "user", "content": prompt}
        ],
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)
    worldviews = result.get('worldviews', [])

    print(f"\n‚úÖ {len(worldviews)}Í∞ú ÌïµÏã¨ ÏÑ∏Í≥ÑÍ¥Ä Ï∂îÏ∂ú")

    # 4. Í≤∞Í≥º Ï∂úÎ†•
    print("\n" + "="*80)
    print("Ï∂îÏ∂úÎêú ÏÑ∏Í≥ÑÍ¥Ä")
    print("="*80)

    for i, wv in enumerate(worldviews, 1):
        print(f"\nÏÑ∏Í≥ÑÍ¥Ä {i}: {wv['title']}")
        print(f"  ÌñâÏúÑÏûê: {wv['actor']}")
        print(f"  ÌïµÏã¨ Î©îÏª§ÎãàÏ¶ò: {', '.join(wv['core_mechanisms'])}")
        print(f"  ÎÖºÎ¶¨ Ìå®ÌÑ¥:")
        print(f"    - Trigger: {wv['logic_pattern']['trigger']}")
        print(f"    - ÏÉùÎûµ: {', '.join(wv['logic_pattern']['skipped_verification'])}")
        print(f"    - Í≤∞Î°†: {wv['logic_pattern']['conclusion']}")
        print(f"  ÏòàÏãú: {', '.join(wv.get('examples', []))}")
        print(f"  ÏòàÏÉÅ Ïª§Î≤ÑÎ¶¨ÏßÄ: {wv.get('estimated_coverage_pct', 0)}%")

    # 5. Ï†ÄÏû•
    output_file = '_consolidated_worldviews_gpt5.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(worldviews, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ Í≤∞Í≥º Ï†ÄÏû•: {output_file}")

    return worldviews


async def match_perceptions_to_worldviews(worldviews):
    """
    Í∞Å perceptionÏùÑ ÌÜµÌï©Îêú ÏÑ∏Í≥ÑÍ¥ÄÏóê Îß§Ïπ≠
    """

    print("\n" + "="*80)
    print("Perception ‚Üí Worldview Îß§Ïπ≠")
    print("="*80)

    # Î∂ÑÏÑù Í≤∞Í≥º Î°úÎìú
    with open('_reasoning_structures_analysis.json', 'r', encoding='utf-8') as f:
        all_data = json.load(f)

    # Í∞Å ÏÑ∏Í≥ÑÍ¥ÄÎ≥Ñ Îß§Ïπ≠
    matches = {wv['title']: [] for wv in worldviews}

    for item in all_data:
        rs = item['reasoning_structure']

        # Í∞Å ÏÑ∏Í≥ÑÍ¥ÄÍ≥º ÎπÑÍµê
        for wv in worldviews:
            # Îß§Ïπ≠ Ï°∞Í±¥:
            # 1. ÌñâÏúÑÏûê ÏùºÏπò
            # 2. Î©îÏª§ÎãàÏ¶ò Ï§ë ÌïòÎÇò Ïù¥ÏÉÅ ÏùºÏπò

            actor_match = wv['actor'] in rs.get('actor', {}).get('subject', '')
            mechanism_match = any(m in rs.get('mechanisms', []) for m in wv['core_mechanisms'])

            # ÎÖºÎ¶¨ Ìå®ÌÑ¥ ÌÇ§ÏõåÎìú Îß§Ïπ≠ (Í∞ÑÎã® Î≤ÑÏ†Ñ)
            logic_text = ' '.join(rs.get('logic_chain', []))
            pattern_keywords = [
                wv['logic_pattern']['trigger'],
                wv['logic_pattern']['conclusion']
            ]
            keyword_match = any(kw[:10] in logic_text for kw in pattern_keywords)

            # Îß§Ïπ≠ Ï†êÏàò
            score = (actor_match * 0.4 + mechanism_match * 0.4 + keyword_match * 0.2)

            if score > 0.5:  # threshold
                matches[wv['title']].append({
                    'perception_id': item['perception_id'],
                    'score': score
                })

    # Í≤∞Í≥º Ï∂úÎ†•
    print("\nÎß§Ïπ≠ Í≤∞Í≥º:")
    total_matched = 0
    for wv_title, perception_list in matches.items():
        count = len(perception_list)
        total_matched += count
        pct = count / len(all_data) * 100
        print(f"  {wv_title[:60]}: {count}Í∞ú ({pct:.1f}%)")

    print(f"\nÏ¥ù Îß§Ïπ≠: {total_matched}Í∞ú / {len(all_data)}Í∞ú ({total_matched/len(all_data)*100:.1f}%)")

    # Ï†ÄÏû•
    output_file = '_worldview_perception_matches.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(matches, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ Îß§Ïπ≠ Í≤∞Í≥º Ï†ÄÏû•: {output_file}")

    return matches


async def main():
    """Î©îÏù∏ Ïã§Ìñâ"""

    # Step 1: GPT-5Î°ú ÏÑ∏Í≥ÑÍ¥Ä ÌÜµÌï©
    worldviews = await consolidate_worldviews()

    # Step 2: Perception Îß§Ïπ≠
    matches = await match_perceptions_to_worldviews(worldviews)

    print("\n" + "="*80)
    print("‚úÖ Ï†ÑÏ≤¥ ÌîÑÎ°úÏÑ∏Ïä§ ÏôÑÎ£å")
    print("="*80)


if __name__ == "__main__":
    asyncio.run(main())
