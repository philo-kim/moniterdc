#!/usr/bin/env python3
"""
Claude Mechanism Matcher ìµœì í™” ì‹¤í—˜

MechanismMatcherì˜ í•µì‹¬ ê¸°ëŠ¥:
- Perceptionê³¼ Worldviewë¥¼ ë§¤ì¹­
- Actor ìœ ì‚¬ë„ (50%) + Mechanism ê²¹ì¹¨ (30%) + Logic ìœ ì‚¬ë„ (20%)
- ì„ê³„ê°’ ì´ìƒì¼ ë•Œ ë§í¬ ìƒì„±

ì‹¤í—˜ ì „ëµ:
1. Baseline - ê¸°ì¡´ GPT ë§¤ì¹­ ë°©ì‹
2. Semantic-Matching - ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ë„
3. Weighted-Scoring - ê°€ì¤‘ì¹˜ ì¡°ì •
4. Explanation-Based - ë§¤ì¹­ ê·¼ê±° ì„¤ëª…
"""

import os
import asyncio
import json
import time
from datetime import datetime
from typing import Dict, List
from anthropic import Anthropic
from dotenv import load_dotenv
import sys
sys.path.insert(0, '/Users/taehyeonkim/dev/minjoo/moniterdc')

from engines.utils.supabase_client import get_supabase

load_dotenv()

claude_client = Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))
supabase = get_supabase()


class MatcherExperiment:
    """Base class for mechanism matcher experiments"""

    def __init__(self, name: str):
        self.name = name

    def build_prompt(self, perception: Dict, worldviews: List[Dict]) -> str:
        raise NotImplementedError

    def match_perception(self, perception: Dict, worldviews: List[Dict]) -> Dict:
        """Match perception to worldviews"""

        prompt = self.build_prompt(perception, worldviews)

        start_time = time.time()

        message = claude_client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4096,
            temperature=0,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )

        elapsed = time.time() - start_time

        response_text = message.content[0].text

        # Parse JSON
        if "```json" in response_text:
            json_start = response_text.find("```json") + 7
            json_end = response_text.find("```", json_start)
            json_str = response_text[json_start:json_end].strip()
        elif "{" in response_text:
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            json_str = response_text[json_start:json_end]
        else:
            json_str = response_text

        result = json.loads(json_str)
        result['_elapsed_time'] = elapsed

        return result


class BaselineMatcherExperiment(MatcherExperiment):
    """í˜„ì¬ GPT ë§¤ì¹­ ë°©ì‹"""

    def __init__(self):
        super().__init__("Baseline-Matcher")

    def build_prompt(self, perception: Dict, worldviews: List[Dict]) -> str:
        # Simplify worldviews for prompt
        wv_summaries = []
        for wv in worldviews:
            frame = wv.get('frame', {})
            if isinstance(frame, dict):
                wv_summaries.append({
                    'id': wv['id'],
                    'title': wv['title'],
                    'actor': frame.get('actor', {}),
                    'mechanisms': frame.get('core_mechanisms', [])
                })

        return f"""
ë‹¤ìŒ Perceptionì„ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ” Worldviewë¥¼ ì°¾ìœ¼ì„¸ìš”.

## Perception

ID: {perception['id']}
Actor: {perception.get('actor', {})}
Mechanisms: {perception.get('mechanisms', [])}
Logic Chain: {perception.get('logic_chain', [])[:3]}

## í›„ë³´ Worldviews ({len(worldviews)}ê°œ)

{json.dumps(wv_summaries, ensure_ascii=False, indent=2)}

---

## ë§¤ì¹­ ê¸°ì¤€

1. **Actor ìœ ì‚¬ë„ (50%)**: ê°™ì€ subjectë¥¼ ë‹¤ë£¨ëŠ”ê°€?
2. **Mechanism ê²¹ì¹¨ (30%)**: ê³µí†µ ë©”ì»¤ë‹ˆì¦˜ì´ ìˆëŠ”ê°€?
3. **Logic ìœ ì‚¬ë„ (20%)**: ì¶”ë¡  íŒ¨í„´ì´ ë¹„ìŠ·í•œê°€?

## ì„ê³„ê°’

- 0.6 ì´ìƒ: ë§¤ì¹­
- 0.6 ë¯¸ë§Œ: ë§¤ì¹­ ì•ˆë¨

JSON í˜•ì‹:
{{
  "matched_worldviews": [
    {{
      "worldview_id": "uuid",
      "worldview_title": "ì œëª©",
      "match_score": 0.0-1.0,
      "reasons": {{
        "actor_similarity": 0.0-1.0,
        "mechanism_overlap": 0.0-1.0,
        "logic_similarity": 0.0-1.0
      }}
    }}
  ]
}}
"""


class SemanticMatcherExperiment(MatcherExperiment):
    """ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ë„ ë§¤ì¹­"""

    def __init__(self):
        super().__init__("Semantic-Matcher")

    def build_prompt(self, perception: Dict, worldviews: List[Dict]) -> str:
        # Simplify
        wv_summaries = []
        for wv in worldviews:
            frame = wv.get('frame', {})
            if isinstance(frame, dict):
                wv_summaries.append({
                    'id': wv['id'],
                    'title': wv['title'],
                    'description': wv.get('description', ''),
                    'actor': frame.get('actor', {}),
                    'mechanisms': frame.get('core_mechanisms', [])
                })

        return f"""
Perceptionê³¼ Worldviewì˜ **ì˜ë¯¸ì  ìœ ì‚¬ë„**ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

## Perception

Actor: {perception.get('actor', {})}
Mechanisms: {perception.get('mechanisms', [])}
Deep Beliefs: {perception.get('deep_beliefs', [])[:3]}

## Worldviews

{json.dumps(wv_summaries, ensure_ascii=False, indent=2)}

---

## ì˜ë¯¸ ê¸°ë°˜ ë§¤ì¹­

ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì•„ë‹Œ **ì˜ë¯¸ ìœ ì‚¬ë„**ë¥¼ í‰ê°€í•˜ì„¸ìš”.

### Actor ì˜ë¯¸ ë¹„êµ

ì˜ˆì‹œ:
- "ë¯¼ì£¼ë‹¹" vs "ì¢ŒíŒŒ" â†’ ë†’ì€ ìœ ì‚¬ë„ (ê°™ì€ ì§„ì˜)
- "ì´ì¬ëª…" vs "ë¯¼ì£¼ë‹¹" â†’ ì¤‘ê°„ ìœ ì‚¬ë„ (ê´€ë ¨ ìˆìŒ)
- "ì¤‘êµ­" vs "ë¯¼ì£¼ë‹¹" â†’ ë‚®ì€ ìœ ì‚¬ë„ (ë‹¤ë¥¸ ëŒ€ìƒ)

### Mechanism ì˜ë¯¸

- ê°™ì€ ë©”ì»¤ë‹ˆì¦˜ = 1.0
- ë³´ì™„ì  ë©”ì»¤ë‹ˆì¦˜ = 0.5 (ì˜ˆ: ì¦‰ì‹œ_ë‹¨ì • + í‘œë©´_ë¶€ì •)
- ë¬´ê´€ = 0.0

### Deep Belief vs Worldview Description

Perceptionì˜ Deep Beliefsê°€ Worldviewì˜ ì„¤ëª…ê³¼ ì–¼ë§ˆë‚˜ ê²¹ì¹˜ëŠ”ê°€?

JSON:
{{
  "matched_worldviews": [
    {{
      "worldview_id": "uuid",
      "worldview_title": "ì œëª©",
      "match_score": 0.0-1.0,
      "semantic_analysis": {{
        "actor_semantic_similarity": 0.0-1.0,
        "mechanism_overlap": 0.0-1.0,
        "belief_description_similarity": 0.0-1.0
      }},
      "explanation": "ì™œ ì´ worldviewê°€ ë§¤ì¹­ë˜ëŠ”ê°€ (1-2ë¬¸ì¥)"
    }}
  ]
}}
"""


class WeightedScoringMatcherExperiment(MatcherExperiment):
    """ê°€ì¤‘ì¹˜ ì¡°ì • ì‹¤í—˜"""

    def __init__(self):
        super().__init__("Weighted-Scoring-Matcher")

    def build_prompt(self, perception: Dict, worldviews: List[Dict]) -> str:
        wv_summaries = []
        for wv in worldviews:
            frame = wv.get('frame', {})
            if isinstance(frame, dict):
                wv_summaries.append({
                    'id': wv['id'],
                    'title': wv['title'],
                    'actor': frame.get('actor', {}),
                    'mechanisms': frame.get('core_mechanisms', []),
                    'logic_pattern': frame.get('logic_pattern', {})
                })

        return f"""
ë‹¤ìŒ **3ê°€ì§€ ê°€ì¤‘ì¹˜**ë¡œ ë§¤ì¹­ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì„¸ìš”.

## Perception

Actor: {perception.get('actor', {})}
Mechanisms: {perception.get('mechanisms', [])}
Logic Chain: {perception.get('logic_chain', [])[:3]}

## Worldviews

{json.dumps(wv_summaries, ensure_ascii=False, indent=2)}

---

## ê°€ì¤‘ì¹˜ ì‹¤í—˜

### ì˜µì…˜ 1: ê¸°ì¡´ (Actor 50%, Mechanism 30%, Logic 20%)
### ì˜µì…˜ 2: Mechanism ì¤‘ì‹¬ (Actor 30%, Mechanism 50%, Logic 20%)
### ì˜µì…˜ 3: ê· ë“± (Actor 33%, Mechanism 33%, Logic 33%)

**ê° ì˜µì…˜ë³„ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³ , ì–´ëŠ ê²ƒì´ ê°€ì¥ ì ì ˆí•œì§€ íŒë‹¨í•˜ì„¸ìš”.**

## ì ìˆ˜ ê³„ì‚° ë°©ë²•

### Actor Similarity (0.0-1.0)
- ì •í™•íˆ ê°™ìŒ: 1.0
- ê°™ì€ ì§„ì˜ (ì˜ˆ: ë¯¼ì£¼ë‹¹ vs ì¢ŒíŒŒ): 0.8
- ê´€ë ¨ ìˆìŒ (ì˜ˆ: ì´ì¬ëª… vs ë¯¼ì£¼ë‹¹): 0.6
- ë‹¤ë¦„: 0.0

### Mechanism Overlap (0.0-1.0)
- ê²¹ì¹˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ ìˆ˜ / ì „ì²´ ë©”ì»¤ë‹ˆì¦˜ ìˆ˜

### Logic Similarity (0.0-1.0)
- Perceptionì˜ Logic Chainì´ Worldviewì˜ Logic Patternê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜?
  - Trigger ìœ ì‚¬: +0.4
  - Skipped ìœ ì‚¬: +0.3
  - Conclusion ìœ ì‚¬: +0.3

JSON:
{{
  "matched_worldviews": [
    {{
      "worldview_id": "uuid",
      "worldview_title": "ì œëª©",
      "scoring_options": {{
        "option1_actor50": {{
          "actor_sim": 0.0-1.0,
          "mechanism_overlap": 0.0-1.0,
          "logic_sim": 0.0-1.0,
          "final_score": 0.0-1.0
        }},
        "option2_mechanism50": {{
          "actor_sim": 0.0-1.0,
          "mechanism_overlap": 0.0-1.0,
          "logic_sim": 0.0-1.0,
          "final_score": 0.0-1.0
        }},
        "option3_equal": {{
          "actor_sim": 0.0-1.0,
          "mechanism_overlap": 0.0-1.0,
          "logic_sim": 0.0-1.0,
          "final_score": 0.0-1.0
        }}
      }},
      "best_option": "option1|option2|option3",
      "reason": "ì™œ ì´ ê°€ì¤‘ì¹˜ê°€ ê°€ì¥ ì ì ˆí•œê°€"
    }}
  ]
}}
"""


class ExplanationBasedMatcherExperiment(MatcherExperiment):
    """ë§¤ì¹­ ê·¼ê±° ì„¤ëª… ì¤‘ì‹¬"""

    def __init__(self):
        super().__init__("Explanation-Based-Matcher")

    def build_prompt(self, perception: Dict, worldviews: List[Dict]) -> str:
        wv_summaries = []
        for wv in worldviews:
            frame = wv.get('frame', {})
            if isinstance(frame, dict):
                wv_summaries.append({
                    'id': wv['id'],
                    'title': wv['title'],
                    'description': wv.get('description', ''),
                    'actor': frame.get('actor', {}),
                    'mechanisms': frame.get('core_mechanisms', [])
                })

        return f"""
Perceptionì´ ì–´ë–¤ Worldviewì— ì†í•˜ëŠ”ì§€ **ê·¼ê±°ë¥¼ ë“¤ì–´** ì„¤ëª…í•˜ì„¸ìš”.

## Perception

Actor: {perception.get('actor', {})}
Mechanisms: {perception.get('mechanisms', [])}
Deep Beliefs: {perception.get('deep_beliefs', [])[:2]}
Implicit Assumptions: {perception.get('implicit_assumptions', [])[:2]}

## Worldviews

{json.dumps(wv_summaries, ensure_ascii=False, indent=2)}

---

## ë§¤ì¹­ ê·¼ê±° ì„¤ëª…

ê° Worldviewì— ëŒ€í•´:

1. **ì™œ ë§¤ì¹­ë˜ëŠ”ê°€?**
   - Actorê°€ ì¼ì¹˜í•˜ëŠ”ê°€? (êµ¬ì²´ì ìœ¼ë¡œ)
   - Mechanismì´ ê²¹ì¹˜ëŠ”ê°€? (ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜?)
   - Deep Beliefê°€ Worldview ì„¤ëª…ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?

2. **ì–¼ë§ˆë‚˜ ê°•í•˜ê²Œ ë§¤ì¹­ë˜ëŠ”ê°€?**
   - Strong (0.8-1.0): Actor + Mechanism + Belief ëª¨ë‘ ì¼ì¹˜
   - Medium (0.6-0.8): 2ê°œ ì´ìƒ ì¼ì¹˜
   - Weak (0.4-0.6): 1ê°œë§Œ ì¼ì¹˜
   - None (< 0.4): ë§¤ì¹­ ì•ˆë¨

3. **ëŒ€ì•ˆ WorldviewëŠ”?**
   - ë‹¤ë¥¸ Worldviewê°€ ë” ì í•©í•œê°€?

JSON:
{{
  "matched_worldviews": [
    {{
      "worldview_id": "uuid",
      "worldview_title": "ì œëª©",
      "match_score": 0.0-1.0,
      "match_strength": "strong|medium|weak",
      "explanation": {{
        "actor_match": "Actor ë§¤ì¹­ ê·¼ê±°",
        "mechanism_match": "Mechanism ë§¤ì¹­ ê·¼ê±°",
        "belief_match": "Deep Belief ë§¤ì¹­ ê·¼ê±°"
      }},
      "why_this_worldview": "ì¢…í•© ì„¤ëª… (2-3ë¬¸ì¥)"
    }}
  ],
  "no_match_reason": "ë§¤ì¹­ ì•ˆë˜ëŠ” ê²½ìš° ì´ìœ "
}}
"""


def run_experiments():
    """ëª¨ë“  ì‹¤í—˜ ì‹¤í–‰"""

    print("=" * 80)
    print("Claude Mechanism Matcher ìµœì í™” ì‹¤í—˜")
    print("=" * 80)

    # Get test perception
    print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”©...")

    perception_query = supabase.table('layered_perceptions')\
        .select('*')\
        .not_.is_('mechanisms', 'null')\
        .not_.is_('actor', 'null')\
        .limit(1)\
        .order('created_at', desc=True)

    perception_result = perception_query.execute()
    perception = perception_result.data[0]

    print(f"   âœ“ Perception: {perception['id'][:8]}...")
    print(f"     Actor: {perception.get('actor', {}).get('subject', 'N/A')}")
    print(f"     Mechanisms: {perception.get('mechanisms', [])}")

    # Get worldviews
    worldview_query = supabase.table('worldviews')\
        .select('*')\
        .eq('archived', False)\
        .limit(7)

    worldview_result = worldview_query.execute()
    worldviews = worldview_result.data

    print(f"   âœ“ {len(worldviews)}ê°œ Worldviews ë¡œë”©")

    # Run experiments
    experiments = [
        BaselineMatcherExperiment(),
        SemanticMatcherExperiment(),
        WeightedScoringMatcherExperiment(),
        ExplanationBasedMatcherExperiment()
    ]

    results = {}

    for exp in experiments:
        print(f"\n{'=' * 80}")
        print(f"ì‹¤í—˜: {exp.name}")
        print(f"{'=' * 80}")

        try:
            matches = exp.match_perception(perception, worldviews)
            elapsed = matches.pop('_elapsed_time', 0)

            results[exp.name] = {
                "matches": matches,
                "elapsed": elapsed,
                "success": True
            }

            print(f"\nâœ… ì™„ë£Œ ({elapsed:.2f}ì´ˆ)")
            print(f"\nğŸ“‹ ë§¤ì¹­ ê²°ê³¼:")

            matched_wvs = matches.get('matched_worldviews', [])
            if matched_wvs:
                for m in matched_wvs[:3]:
                    score = m.get('match_score', 0)
                    title = m.get('worldview_title', 'N/A')
                    print(f"   - {title}: {score:.2f}")
            else:
                print(f"   ë§¤ì¹­ ì•ˆë¨: {matches.get('no_match_reason', 'N/A')}")

        except Exception as e:
            import traceback
            print(f"\nâŒ ì‹¤íŒ¨: {e}")
            print(f"\nğŸ” Traceback:")
            traceback.print_exc()
            results[exp.name] = {
                "error": str(e),
                "success": False
            }

    # Save results
    output = {
        "timestamp": datetime.now().isoformat(),
        "perception": {
            "id": perception['id'],
            "actor": perception.get('actor'),
            "mechanisms": perception.get('mechanisms')
        },
        "worldviews_count": len(worldviews),
        "experiments": results
    }

    output_file = f"_test_results/matcher_experiments_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\n{'=' * 80}")
    print(f"âœ… ì‹¤í—˜ ì™„ë£Œ: {output_file}")
    print(f"{'=' * 80}")

    # Summary
    print(f"\nğŸ“Š ìš”ì•½:")
    for name, data in results.items():
        if data.get('success'):
            matches = data['matches'].get('matched_worldviews', [])
            match_count = len(matches)
            print(f"   {name}: {data['elapsed']:.2f}s, {match_count}ê°œ ë§¤ì¹­ âœ…")
        else:
            print(f"   {name}: âŒ {data.get('error', 'Unknown error')}")


if __name__ == "__main__":
    run_experiments()
