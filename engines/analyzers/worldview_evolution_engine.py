"""
WorldviewEvolutionEngine - ì‚´ì•„ìžˆëŠ” ì„¸ê³„ê´€ ì‹œìŠ¤í…œ

ì£¼ê¸°ì ìœ¼ë¡œ ì „ì²´ perceptionì„ ìž¬ë¶„ì„í•˜ì—¬:
1. ìƒˆë¡œìš´ ì„¸ê³„ê´€ ë°œê²¬
2. ê¸°ì¡´ ì„¸ê³„ê´€ ë³€í™” ê°ì§€
3. ì‚¬ë¼ì§„ ì„¸ê³„ê´€ ì•„ì¹´ì´ë¸Œ
4. ì„¸ê³„ê´€ ë¶„ë¦¬/ë³‘í•©

ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹´ë¡  ë³€í™”ë¥¼ ì¶”ì í•˜ëŠ” ì‚´ì•„ìžˆëŠ” ì‹œìŠ¤í…œ
"""

from anthropic import Anthropic
import os
import json
import asyncio
from typing import Dict, List, Tuple
from datetime import datetime
from engines.utils.supabase_client import get_supabase

client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))


class WorldviewEvolutionEngine:
    """Evolving worldview system that adapts to discourse changes"""

    def __init__(self):
        self.supabase = get_supabase()

    async def run_evolution_cycle(self, sample_size: int = 200) -> Dict:
        """
        Run a complete evolution cycle

        Args:
            sample_size: Number of recent perceptions to analyze

        Returns:
            Evolution report with changes detected
        """

        print("\n" + "="*80)
        print("ì„¸ê³„ê´€ ì§„í™” ì‚¬ì´í´ ì‹œìž‘")
        print("="*80)

        # 1. Load recent perceptions
        perceptions = await self._load_recent_perceptions(sample_size)
        print(f"\nâœ… ìµœê·¼ {len(perceptions)}ê°œ perception ë¡œë“œ")

        # 2. Extract new worldviews from current data
        new_worldviews = await self._consolidate_worldviews(perceptions)
        print(f"\nâœ… {len(new_worldviews)}ê°œ ì„¸ê³„ê´€ ì¶”ì¶œ")

        # 3. Load existing worldviews
        existing_worldviews = await self._load_existing_worldviews()
        print(f"\nâœ… ê¸°ì¡´ {len(existing_worldviews)}ê°œ ì„¸ê³„ê´€ ë¡œë“œ")

        # 4. Compare and detect changes
        changes = await self._detect_changes(existing_worldviews, new_worldviews)
        print(f"\nâœ… ë³€í™” ê°ì§€ ì™„ë£Œ")

        # 5. Apply changes (if significant)
        if changes['significant']:
            await self._apply_changes(changes)
            print(f"\nâœ… ë³€í™” ì ìš© ì™„ë£Œ")
        else:
            print(f"\nâš ï¸  ìœ ì˜ë¯¸í•œ ë³€í™” ì—†ìŒ (ë³€í™” ì ìš© ê±´ë„ˆëœ€)")

        # 6. Generate report
        report = self._generate_report(changes)

        print("\n" + "="*80)
        print("ì„¸ê³„ê´€ ì§„í™” ì‚¬ì´í´ ì™„ë£Œ")
        print("="*80)

        return report

    async def _load_recent_perceptions(self, limit: int) -> List[Dict]:
        """Load most recent perceptions with reasoning structures"""

        perceptions = self.supabase.table('layered_perceptions')\
            .select('id, content_id, mechanisms, actor, logic_chain, consistency_pattern, deep_beliefs, implicit_assumptions, created_at')\
            .not_.is_('mechanisms', 'null')\
            .order('created_at', desc=True)\
            .limit(limit)\
            .execute().data

        # Filter out perceptions without mechanisms
        perceptions = [p for p in perceptions if p.get('mechanisms') and len(p.get('mechanisms', [])) > 0]

        return perceptions

    async def _consolidate_worldviews(self, perceptions: List[Dict]) -> List[Dict]:
        """
        Use GPT-5 to consolidate perceptions into 5-10 core worldviews

        Args:
            perceptions: List of perception dicts with reasoning structures

        Returns:
            List of worldview dicts
        """

        # Prepare statistics
        mechanism_counts = {}
        actor_counts = {}
        logic_chain_samples = []

        for p in perceptions[:200]:
            # Mechanisms
            for mech in p.get('mechanisms', []):
                mechanism_counts[mech] = mechanism_counts.get(mech, 0) + 1

            # Actors
            actor = p.get('actor', {})
            if isinstance(actor, dict):
                subj = actor.get('subject', 'Unknown')
                if isinstance(subj, list):
                    subj = ', '.join(str(s) for s in subj)
                elif not isinstance(subj, str):
                    subj = str(subj)
                actor_counts[subj] = actor_counts.get(subj, 0) + 1

            # Logic chain samples
            logic = p.get('logic_chain', [])
            if logic and len(logic) > 0:
                logic_chain_samples.append(logic[0])

        # Top stats
        top_mechs = sorted(mechanism_counts.items(), key=lambda x: x[1], reverse=True)
        top_actors = sorted(actor_counts.items(), key=lambda x: x[1], reverse=True)

        # Sample data (simplified)
        sample_data = []
        for p in perceptions[:5]:
            sample_data.append({
                'mechanisms': p.get('mechanisms', []),
                'actor': p.get('actor', {}),
                'logic_chain': p.get('logic_chain', [])[:3] if p.get('logic_chain') else []
            })

        prompt = f"""
{len(perceptions)}ê°œ ë‹´ë¡  í†µê³„ ë¶„ì„:

## ë©”ì»¤ë‹ˆì¦˜ ë¹ˆë„
{json.dumps(top_mechs, ensure_ascii=False, indent=2)}

## Actor ë¹ˆë„
{json.dumps(top_actors, ensure_ascii=False, indent=2)}

## Logic Chain ì‹œìž‘ì  ìƒ˜í”Œ (10ê°œ)
{json.dumps(logic_chain_samples[:10], ensure_ascii=False, indent=2)}

ì „ì²´ ë°ì´í„° ìƒ˜í”Œ:
{json.dumps(sample_data, ensure_ascii=False, indent=2)}

---

## ë°ì´í„° ê¸°ë°˜ ì„¸ê³„ê´€ ë°œê²¬

### ë¶„ì„ ê¸°ì¤€

1. **ìœ ì˜ë¯¸í•œ ê³µì¶œí˜„**: ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ë“¤ì´ ìžì£¼ í•¨ê»˜ ë‚˜íƒ€ë‚˜ëŠ”ê°€?
2. **ì§€ë°°ì  Actor**: ê°€ìž¥ ìžì£¼ ì–¸ê¸‰ë˜ëŠ” ActorëŠ”?
3. **ê³µí†µ Logic íŒ¨í„´**: Logic Chain ì‹œìž‘ì ì˜ ê³µí†µì ì€?

### ì„¸ê³„ê´€ ì •ì˜

ìœ„ í†µê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ **5-10ê°œì˜ í•µì‹¬ ì„¸ê³„ê´€**ì„ ì •ì˜í•˜ì„¸ìš”.

âš ï¸ ì£¼ì˜: ë‹¨ìˆœ ë¹ˆë„ê°€ ì•„ë‹Œ **ì˜ë¯¸ìžˆëŠ” ì¡°í•©**ì„ ì°¾ìœ¼ì„¸ìš”.

## ðŸŽ¯ ì„¸ê³„ê´€ ì œëª© ìž‘ì„± ì›ì¹™ (ë§¤ìš° ì¤‘ìš”!)

**DC Gallery ì‚¬ìš©ìžë“¤ì˜ ì‹¤ì œ ì–¸ì–´ì™€ ì‹œê°**ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.

âŒ ë‚˜ìœ ì˜ˆ (í•™ìˆ ì /ê°ê´€ì  í‘œí˜„):
- "ì¦‰ì‹œ ë‹¨ì •í˜• ìŒëª¨ë¡  ì„¸ê³„ê´€"
- "ì—­ì‚¬ ë°˜ë³µ í•„ì—°ë¡  ì„¸ê³„ê´€"
- "ì™¸ë¶€ ì„¸ë ¥ ì¹¨íˆ¬ë¡  ì„¸ê³„ê´€"

âœ… ì¢‹ì€ ì˜ˆ (ê·¸ë“¤ì˜ ì–¸ì–´ë¡œ):
- "ì¤‘êµ­/ì¢ŒíŒŒê°€ ëŒ“ê¸€ë¶€ëŒ€ë¡œ ì—¬ë¡ ì„ ì¡°ìž‘í•œë‹¤"
- "ë¯¼ì£¼ë‹¹ì€ ê³¼ê±° ë…ìž¬ì²˜ëŸ¼ ì‚¬ì°°ë¡œ êµ­ë¯¼ì„ ê°ì‹œí•œë‹¤"
- "ì´ìž¬ëª…ì€ ë„¤íŠ¸ì›Œí¬ë¡œ ê¶Œë ¥ì„ ìœ ì§€í•œë‹¤"
- "ì •ë¶€ëŠ” ê¶Œë ¥ì„ ì•…ìš©í•´ êµ­ë¯¼ì„ íƒ„ì••í•œë‹¤"
- "ì–¸ë¡ ì€ ì§„ì‹¤ì„ ì™œê³¡í•˜ì—¬ ì¡°ìž‘í•œë‹¤"

**í˜•ì‹**: "[í–‰ìœ„ìž]ëŠ”/ê°€ [í–‰ë™]í•œë‹¤" (30-50ìž)
**í†¤**: DC Gallery ì‚¬ìš©ìžê°€ ì§ì ‘ ë§í•˜ëŠ” ê²ƒì²˜ëŸ¼

JSON í˜•ì‹:
{{
  "worldviews": [
    {{
      "title": "ì„¸ê³„ê´€ ì œëª© - DC ì‚¬ìš©ìž ì–¸ì–´ë¡œ (30-50ìž)",
      "description": "í•µì‹¬ íŠ¹ì§• (2-3ë¬¸ìž¥)",
      "actor": {{
        "subject": "ì£¼ì²´",
        "purpose": "ëª©ì ",
        "methods": ["ìˆ˜ë‹¨1", "ìˆ˜ë‹¨2", "ìˆ˜ë‹¨3"]
      }},
      "core_mechanisms": ["ë©”ì»¤ë‹ˆì¦˜1", "ë©”ì»¤ë‹ˆì¦˜2", "ë©”ì»¤ë‹ˆì¦˜3"],
      "logic_pattern": {{
        "trigger": "ì‹œìž‘",
        "skipped_verification": "ìƒëžµ",
        "conclusion": "ê²°ë¡ "
      }},
      "statistical_basis": {{
        "top_mechanisms": ["ë©”ì»¤ë‹ˆì¦˜ë“¤"],
        "top_actor": "Actor",
        "occurrence_count": ìˆ«ìž
      }}
    }}
  ]
}}
"""

        print("\nðŸ¤– Claudeë¡œ ì„¸ê³„ê´€ ë°œê²¬ ì¤‘ (Data-Driven)...")

        # Claude Sonnet 4.5 (Data-Driven í”„ë¡¬í”„íŠ¸)
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=8192,
                temperature=0.3,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
        )

        response_text = response.content[0].text

        # Parse JSON
        if "```json" in response_text:
            json_start = response_text.find("```json") + 7
            json_end = response_text.find("```", json_start)
            json_str = response_text[json_start:json_end].strip()
        elif "{" in response_text:
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            json_str = response_text[json_start:json_end]
        else:
            json_str = response_text

        result = json.loads(json_str)
        worldviews = result.get('worldviews', [])

        # Print summary
        for i, wv in enumerate(worldviews, 1):
            print(f"  {i}. {wv['title']}")
            print(f"     í–‰ìœ„ìž: {wv['actor']}, ë©”ì»¤ë‹ˆì¦˜: {', '.join(wv['core_mechanisms'][:2])}")

        return worldviews

    async def _load_existing_worldviews(self) -> List[Dict]:
        """Load existing worldviews from database"""

        worldviews = self.supabase.table('worldviews')\
            .select('*')\
            .execute().data

        return worldviews

    async def _detect_changes(self, existing: List[Dict], new: List[Dict]) -> Dict:
        """
        Detect changes between existing and new worldviews

        Returns:
            Dict with change details
        """

        print("\n" + "="*80)
        print("ë³€í™” ê°ì§€")
        print("="*80)

        # Parse existing worldview structures
        existing_parsed = []
        for wv in existing:
            try:
                frame = json.loads(wv.get('frame', '{}'))
                existing_parsed.append({
                    'id': wv['id'],
                    'title': wv['title'],
                    'frame': frame
                })
            except:
                # Old format worldview - treat as legacy
                existing_parsed.append({
                    'id': wv['id'],
                    'title': wv['title'],
                    'frame': {}
                })

        # Compare using GPT-5
        comparison_prompt = f"""
ê¸°ì¡´ ì„¸ê³„ê´€ ({len(existing_parsed)}ê°œ):
{json.dumps([{'title': e['title']} for e in existing_parsed], ensure_ascii=False, indent=2)}

ìƒˆ ì„¸ê³„ê´€ ({len(new)}ê°œ):
{json.dumps([{'title': w['title'], 'actor': w['actor']} for w in new], ensure_ascii=False, indent=2)}

ì´ ë‘ ì„¸ê³„ê´€ ëª©ë¡ì„ ë¹„êµí•˜ê³  ë³€í™”ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ìƒˆë¡œ ë“±ìž¥í•œ ì„¸ê³„ê´€** (ê¸°ì¡´ì— ì—†ë˜ ê²ƒ)
2. **ì‚¬ë¼ì§„ ì„¸ê³„ê´€** (ìƒˆ ëª©ë¡ì— ì—†ëŠ” ê²ƒ)
3. **ë³€í™”í•œ ì„¸ê³„ê´€** (ë¹„ìŠ·í•˜ì§€ë§Œ ë‚´ìš©ì´ ë‹¬ë¼ì§„ ê²ƒ)
4. **ìœ ì§€ëœ ì„¸ê³„ê´€** (ê±°ì˜ ê°™ì€ ê²ƒ)

JSON í˜•ì‹:
{{
  "new_worldviews": ["ìƒˆ ì„¸ê³„ê´€ title 1", ...],
  "disappeared_worldviews": ["ì‚¬ë¼ì§„ ì„¸ê³„ê´€ title 1", ...],
  "evolved_worldviews": [
    {{
      "old_title": "ê¸°ì¡´ title",
      "new_title": "ìƒˆ title",
      "change_description": "ë³€í™” ì„¤ëª…"
    }}
  ],
  "stable_worldviews": ["ìœ ì§€ëœ ì„¸ê³„ê´€ title 1", ...],
  "significant": true,  // ìœ ì˜ë¯¸í•œ ë³€í™”ê°€ ìžˆëŠ”ê°€?
  "summary": "ë³€í™” ìš”ì•½ (1-2ë¬¸ìž¥)"
}}
"""

        # Claude Sonnet 4.5
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=4096,
                temperature=0,
                messages=[
                    {"role": "user", "content": comparison_prompt}
                ]
            )
        )

        response_text = response.content[0].text

        # Parse JSON
        if "```json" in response_text:
            json_start = response_text.find("```json") + 7
            json_end = response_text.find("```", json_start)
            json_str = response_text[json_start:json_end].strip()
        elif "{" in response_text:
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            json_str = response_text[json_start:json_end]
        else:
            json_str = response_text

        changes = json.loads(json_str)

        # Add actual worldview objects
        changes['new_worldview_objects'] = [
            wv for wv in new if wv['title'] in changes.get('new_worldviews', [])
        ]
        changes['disappeared_worldview_ids'] = [
            wv['id'] for wv in existing_parsed if wv['title'] in changes.get('disappeared_worldviews', [])
        ]

        # Print summary
        print(f"\nì‹ ê·œ: {len(changes.get('new_worldviews', []))}ê°œ")
        print(f"ì†Œë©¸: {len(changes.get('disappeared_worldviews', []))}ê°œ")
        print(f"ì§„í™”: {len(changes.get('evolved_worldviews', []))}ê°œ")
        print(f"ìœ ì§€: {len(changes.get('stable_worldviews', []))}ê°œ")
        print(f"\nìš”ì•½: {changes.get('summary', '')}")

        return changes

    async def _apply_changes(self, changes: Dict):
        """
        Apply detected changes to database

        1. Archive disappeared worldviews
        2. Insert new worldviews
        3. Update evolved worldviews
        """

        print("\n" + "="*80)
        print("ë³€í™” ì ìš©")
        print("="*80)

        # 1. Archive disappeared worldviews
        for wv_id in changes.get('disappeared_worldview_ids', []):
            self.supabase.table('worldviews')\
                .update({
                    'archived': True,
                    'archived_at': datetime.now().isoformat()
                })\
                .eq('id', wv_id)\
                .execute()
            print(f"  ðŸ“¦ ì•„ì¹´ì´ë¸Œ: {wv_id}")

        # 2. Insert new worldviews
        for wv_data in changes.get('new_worldview_objects', []):
            await self._insert_worldview(wv_data)
            print(f"  âœ¨ ì‹ ê·œ ìƒì„±: {wv_data['title']}")

        # 3. Update evolved worldviews
        # (For now, just create new versions - can be enhanced later)

        print(f"\nâœ… {len(changes.get('new_worldview_objects', []))}ê°œ ì‹ ê·œ, {len(changes.get('disappeared_worldview_ids', []))}ê°œ ì•„ì¹´ì´ë¸Œ")

    async def _insert_worldview(self, wv_data: Dict):
        """Insert a new worldview into database"""

        worldview = {
            'title': wv_data['title'],
            'frame': json.dumps({
                'actor': wv_data['actor'],
                'core_mechanisms': wv_data['core_mechanisms'],
                'logic_pattern': wv_data['logic_pattern'],
                'examples': wv_data.get('examples', []),
                'estimated_coverage_pct': wv_data.get('estimated_coverage_pct', 0)
            }, ensure_ascii=False),
            'description': wv_data['logic_pattern']['trigger'] + ' â†’ ' + wv_data['logic_pattern']['conclusion'],
            'core_subject': wv_data['actor'],
            'core_attributes': wv_data['core_mechanisms'],
            'overall_valence': 'negative',
            'version': 1,
            'last_updated': datetime.now().isoformat(),
            'total_perceptions': 0,
            'perception_ids': []
        }

        self.supabase.table('worldviews').insert(worldview).execute()

    def _generate_report(self, changes: Dict) -> Dict:
        """Generate evolution report"""

        return {
            'timestamp': datetime.now().isoformat(),
            'changes_detected': changes.get('significant', False),
            'summary': changes.get('summary', ''),
            'new_count': len(changes.get('new_worldviews', [])),
            'disappeared_count': len(changes.get('disappeared_worldviews', [])),
            'evolved_count': len(changes.get('evolved_worldviews', [])),
            'stable_count': len(changes.get('stable_worldviews', [])),
            'details': changes
        }
