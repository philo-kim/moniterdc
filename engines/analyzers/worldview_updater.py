"""
WorldviewUpdater - ì„¸ê³„ê´€ ì§€ì†ì  ì—…ë°ì´íŠ¸ ì—”ì§„

ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ê¸°ë°˜ ìµœì  ì „ëµ:
- í•˜ì´ë¸Œë¦¬ë“œ: ì ì§„ì  ë³‘í•© (C) + ì„ê³„ê°’ ê¸°ë°˜ (D)

ìš´ì˜ ë°©ì‹:
1. ì¼ìƒ (ë§¤ì¼): ìƒˆ ê¸€ ìˆ˜ì§‘ â†’ ë¶„ì„ â†’ ë§¤ì¹­
2. ì£¼ê°„ (ì£¼ 1íšŒ): ê¸°ì¡´ ì„¸ê³„ê´€ì— ì˜ˆì‹œ ì¶”ê°€
3. ì›”ê°„ (ì¡°ê±´ ì¶©ì¡± ì‹œ): ì „ì²´ ì¬êµ¬ì„±
4. ìˆ˜ì‹œ: ìƒˆ ì„¸ê³„ê´€ ë°œê²¬ ë° ìƒì„±
"""

from openai import AsyncOpenAI
import os
import json
import numpy as np
from typing import Dict, List, Tuple
from uuid import UUID
from datetime import datetime
from engines.utils.supabase_client import get_supabase

client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))

class WorldviewUpdater:
    """Continuously update worldviews with new data"""

    # ì„ê³„ê°’ ì„¤ì •
    REBUILD_THRESHOLD_COUNT = 100  # 100ê°œ ìƒˆ perception ëˆ„ì  ì‹œ ì¬êµ¬ì„±
    REBUILD_THRESHOLD_MISMATCH = 0.3  # 30% ë¯¸ë§¤ì¹­ ì‹œ ì¬êµ¬ì„±
    NEW_WORLDVIEW_THRESHOLD = 10  # ê°™ì€ ì£¼ì œ 10ê°œ ëˆ„ì  ì‹œ ìƒˆ ì„¸ê³„ê´€ ìƒì„±

    def __init__(self):
        self.supabase = get_supabase()

    async def daily_update(self) -> Dict:
        """
        ì¼ìƒ ì—…ë°ì´íŠ¸ (ë§¤ì¼)

        1. ìƒˆ ê¸€ ìˆ˜ì§‘
        2. 3-layer ë¶„ì„
        3. ê¸°ì¡´ ì„¸ê³„ê´€ì— ë§¤ì¹­

        Returns:
            ì—…ë°ì´íŠ¸ í†µê³„
        """
        print("\n" + "="*70)
        print("ì¼ìƒ ì—…ë°ì´íŠ¸ (Daily)")
        print("="*70)

        # 1. ë¶„ì„ë˜ì§€ ì•Šì€ contents ì°¾ê¸°
        all_contents = self.supabase.table('contents').select('id').execute().data
        analyzed_contents = self.supabase.table('layered_perceptions').select('content_id').execute().data

        analyzed_ids = set(lp['content_id'] for lp in analyzed_contents)
        unanalyzed = [c for c in all_contents if c['id'] not in analyzed_ids]

        print(f"\në¯¸ë¶„ì„ contents: {len(unanalyzed)}ê°œ")

        if len(unanalyzed) == 0:
            print("âœ… ëª¨ë“  ê¸€ì´ ë¶„ì„ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
            return {'new_analyzed': 0, 'new_matched': 0}

        # 2. 3-layer ë¶„ì„
        from engines.analyzers.layered_perception_extractor import LayeredPerceptionExtractor

        extractor = LayeredPerceptionExtractor()

        new_lps = []
        for i, content in enumerate(unanalyzed[:10], 1):  # ì¼ë‹¨ 10ê°œë§Œ
            print(f"\r  ë¶„ì„ ì¤‘: {i}/{min(len(unanalyzed), 10)}", end='', flush=True)

            content_data = self.supabase.table('contents')\
                .select('*')\
                .eq('id', content['id'])\
                .execute().data[0]

            try:
                lp_id = await extractor.extract(content_data)
                lp = self.supabase.table('layered_perceptions')\
                    .select('*')\
                    .eq('id', str(lp_id))\
                    .execute().data[0]
                new_lps.append(lp)
            except Exception as e:
                print(f"\n  âš ï¸  ë¶„ì„ ì‹¤íŒ¨: {e}")

        print(f"\n\nâœ… {len(new_lps)}ê°œ ìƒˆ ë¶„ì„ ì™„ë£Œ")

        # 3. ê¸°ì¡´ ì„¸ê³„ê´€ì— ë§¤ì¹­
        matched_count = await self._match_to_existing_worldviews(new_lps)

        print(f"âœ… {matched_count}ê°œ ë§¤ì¹­ ì™„ë£Œ")

        return {
            'new_analyzed': len(new_lps),
            'new_matched': matched_count
        }

    async def weekly_update(self) -> Dict:
        """
        ì£¼ê°„ ì—…ë°ì´íŠ¸ (ì£¼ 1íšŒ)

        1. ìµœê·¼ ë§¤ì¹­ëœ perception ì¤‘ ëŒ€í‘œ ì‚¬ë¡€ ì„ ì •
        2. ê¸°ì¡´ ì„¸ê³„ê´€ narrativeì— ì˜ˆì‹œ ì¶”ê°€

        Returns:
            ì—…ë°ì´íŠ¸ëœ ì„¸ê³„ê´€ ê°œìˆ˜
        """
        print("\n" + "="*70)
        print("ì£¼ê°„ ì—…ë°ì´íŠ¸ (Weekly)")
        print("="*70)

        # ê¸°ì¡´ ì„¸ê³„ê´€ ë¡œë“œ
        worldviews = self.supabase.table('worldviews')\
            .select('*')\
            .execute().data

        new_wvs = [wv for wv in worldviews if '>' in wv['title']]

        print(f"\nê¸°ì¡´ ì„¸ê³„ê´€: {len(new_wvs)}ê°œ")

        updated_count = 0

        for wv in new_wvs:
            # ì´ ì„¸ê³„ê´€ì— ìµœê·¼ ì—°ê²°ëœ perception ì°¾ê¸°
            try:
                recent_links = self.supabase.table('perception_worldview_links')\
                    .select('perception_id')\
                    .eq('worldview_id', wv['id'])\
                    .order('created_at', desc=True)\
                    .limit(5)\
                    .execute().data

                if not recent_links:
                    continue

                # ëŒ€í‘œ perception ì„ ì • (relevance_score ë†’ì€ ê²ƒ)
                perception_id = recent_links[0]['perception_id']

                perception = self.supabase.table('layered_perceptions')\
                    .select('*')\
                    .eq('id', perception_id)\
                    .execute().data[0]

                # ìƒˆ ì˜ˆì‹œ ìƒì„±
                new_example = await self._generate_example_from_perception(perception)

                # ì„¸ê³„ê´€ ì—…ë°ì´íŠ¸
                frame = json.loads(wv['frame'])

                if 'examples' not in frame['narrative']:
                    frame['narrative']['examples'] = []

                frame['narrative']['examples'].append(new_example)

                # DB ì—…ë°ì´íŠ¸
                self.supabase.table('worldviews')\
                    .update({'frame': json.dumps(frame, ensure_ascii=False)})\
                    .eq('id', wv['id'])\
                    .execute()

                print(f"  âœ… '{wv['title']}' ì˜ˆì‹œ ì¶”ê°€")
                updated_count += 1

            except Exception as e:
                print(f"  âš ï¸  '{wv['title']}' ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

        print(f"\nâœ… {updated_count}ê°œ ì„¸ê³„ê´€ ì—…ë°ì´íŠ¸ ì™„ë£Œ")

        return {'updated_worldviews': updated_count}

    async def check_and_rebuild_if_needed(self) -> Dict:
        """
        ì„ê³„ê°’ í™•ì¸ ë° ì¬êµ¬ì„± (ì›”ê°„ ë˜ëŠ” ì¡°ê±´ ì¶©ì¡± ì‹œ)

        ì¡°ê±´:
        1. ìƒˆ perception 100ê°œ+ ëˆ„ì 
        2. ë¯¸ë§¤ì¹­ë¥  30%+

        Returns:
            ì¬êµ¬ì„± ì—¬ë¶€ ë° í†µê³„
        """
        print("\n" + "="*70)
        print("ì„ê³„ê°’ í™•ì¸ (Monthly Check)")
        print("="*70)

        # í˜„ì¬ ìƒíƒœ
        total_perceptions = self.supabase.table('layered_perceptions')\
            .select('id', count='exact')\
            .execute().count

        total_links = self.supabase.table('perception_worldview_links')\
            .select('id', count='exact')\
            .execute().count

        # ìµœê·¼ ì—…ë°ì´íŠ¸ ì‹œì  í™•ì¸ (worldviewsì˜ updated_at)
        worldviews = self.supabase.table('worldviews')\
            .select('updated_at')\
            .order('updated_at', desc=True)\
            .limit(1)\
            .execute().data

        last_rebuild = worldviews[0]['updated_at'] if worldviews else None

        # ìµœê·¼ ì—…ë°ì´íŠ¸ ì´í›„ ìƒˆ perception ê°œìˆ˜
        if last_rebuild:
            new_perceptions = self.supabase.table('layered_perceptions')\
                .select('id', count='exact')\
                .gt('created_at', last_rebuild)\
                .execute().count
        else:
            new_perceptions = total_perceptions

        print(f"\ní˜„ì¬ ìƒíƒœ:")
        print(f"  ì „ì²´ perception: {total_perceptions}ê°œ")
        print(f"  ì „ì²´ ë§í¬: {total_links}ê°œ")
        print(f"  ìµœê·¼ ì¬êµ¬ì„± ì´í›„ ìƒˆ perception: {new_perceptions}ê°œ")

        # ì¡°ê±´ 1: ê°œìˆ˜ ì„ê³„ê°’
        needs_rebuild_count = new_perceptions >= self.REBUILD_THRESHOLD_COUNT

        print(f"\nì¡°ê±´ 1: ëˆ„ì  ê°œìˆ˜")
        print(f"  {new_perceptions} / {self.REBUILD_THRESHOLD_COUNT}")
        print(f"  â†’ {'âœ… ì¬êµ¬ì„± í•„ìš”' if needs_rebuild_count else 'âŒ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ'}")

        # ì¡°ê±´ 2: ë¯¸ë§¤ì¹­ë¥ 
        matched_perceptions = len(set(
            link['perception_id']
            for link in self.supabase.table('perception_worldview_links')
                .select('perception_id')
                .execute().data
        ))

        mismatch_rate = 1 - (matched_perceptions / max(total_perceptions, 1))
        needs_rebuild_mismatch = mismatch_rate > self.REBUILD_THRESHOLD_MISMATCH

        print(f"\nì¡°ê±´ 2: ë¯¸ë§¤ì¹­ë¥ ")
        print(f"  {mismatch_rate*100:.1f}% (ì„ê³„ê°’: {self.REBUILD_THRESHOLD_MISMATCH*100}%)")
        print(f"  â†’ {'âœ… ì¬êµ¬ì„± í•„ìš”' if needs_rebuild_mismatch else 'âŒ ì¶©ë¶„íˆ ë§¤ì¹­ë¨'}")

        # ìµœì¢… ê²°ì •
        should_rebuild = needs_rebuild_count or needs_rebuild_mismatch

        print(f"\nğŸ¯ ìµœì¢… ê²°ì •: {'ì¬êµ¬ì„± ì‹¤í–‰' if should_rebuild else 'ìœ ì§€'}")

        if should_rebuild:
            print("\nì„¸ê³„ê´€ ì¬êµ¬ì„± ì‹œì‘...")

            from engines.analyzers.optimal_worldview_constructor import OptimalWorldviewConstructor

            constructor = OptimalWorldviewConstructor()
            stats = await constructor.construct_all()

            print(f"âœ… ì¬êµ¬ì„± ì™„ë£Œ: {stats['total_worldviews']}ê°œ ì„¸ê³„ê´€")

            return {
                'rebuilt': True,
                'new_worldviews': stats['total_worldviews']
            }
        else:
            return {
                'rebuilt': False,
                'new_perceptions': new_perceptions,
                'mismatch_rate': mismatch_rate
            }

    async def detect_and_create_new_worldviews(self) -> Dict:
        """
        ìƒˆ ì„¸ê³„ê´€ ë°œê²¬ (ìˆ˜ì‹œ)

        ë¯¸ë§¤ì¹­ perception ì¤‘ ê°™ì€ ì£¼ì œê°€ 10ê°œ+ ëˆ„ì ë˜ë©´
        ìƒˆ ì„¸ê³„ê´€ ìƒì„±

        Returns:
            ìƒˆë¡œ ìƒì„±ëœ ì„¸ê³„ê´€ ê°œìˆ˜
        """
        print("\n" + "="*70)
        print("ìƒˆ ì„¸ê³„ê´€ ë°œê²¬ (Ad-hoc)")
        print("="*70)

        # ë¯¸ë§¤ì¹­ perception ì°¾ê¸°
        all_perceptions = self.supabase.table('layered_perceptions')\
            .select('*')\
            .execute().data

        matched_ids = set(
            link['perception_id']
            for link in self.supabase.table('perception_worldview_links')
                .select('perception_id')
                .execute().data
        )

        unmatched = [lp for lp in all_perceptions if lp['id'] not in matched_ids]

        print(f"\në¯¸ë§¤ì¹­ perception: {len(unmatched)}ê°œ")

        if len(unmatched) < self.NEW_WORLDVIEW_THRESHOLD:
            print(f"âŒ ì„ê³„ê°’ ë¯¸ë‹¬ ({len(unmatched)} < {self.NEW_WORLDVIEW_THRESHOLD})")
            return {'new_worldviews': 0}

        # ì£¼ì œë³„ ê·¸ë£¹í™”
        themes = {}
        for lp in unmatched:
            hint = lp.get('worldview_hints', '')
            beliefs = lp.get('deep_beliefs', [])

            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì£¼ì œ ì¶”ì¶œ
            theme = self._extract_theme(hint, beliefs)

            if theme not in themes:
                themes[theme] = []
            themes[theme].append(lp)

        print(f"\nì£¼ì œë³„ ê·¸ë£¹:")
        for theme, lps in themes.items():
            print(f"  - {theme}: {len(lps)}ê°œ")

        # ì„ê³„ê°’ ì´ìƒì¸ ì£¼ì œë¡œ ìƒˆ ì„¸ê³„ê´€ ìƒì„±
        created_count = 0

        for theme, lps in themes.items():
            if len(lps) >= self.NEW_WORLDVIEW_THRESHOLD:
                print(f"\nâ­ '{theme}' ìƒˆ ì„¸ê³„ê´€ ìƒì„± ({len(lps)}ê°œ ë°ì´í„°)")

                # GPTë¡œ ìƒˆ ì„¸ê³„ê´€ ìƒì„±
                new_wv = await self._create_new_worldview(theme, lps)

                print(f"  âœ… ìƒì„± ì™„ë£Œ: {new_wv['title']}")
                created_count += 1

        print(f"\nâœ… {created_count}ê°œ ìƒˆ ì„¸ê³„ê´€ ìƒì„±")

        return {'new_worldviews': created_count}

    async def _match_to_existing_worldviews(self, perceptions: List[Dict]) -> int:
        """ìƒˆ perceptionì„ ê¸°ì¡´ ì„¸ê³„ê´€ì— ë§¤ì¹­"""

        worldviews = self.supabase.table('worldviews')\
            .select('*')\
            .execute().data

        new_wvs = [wv for wv in worldviews if '>' in wv['title']]

        matched_count = 0

        for lp in perceptions:
            lp_text = ' '.join(lp.get('deep_beliefs', []))

            best_match = None
            best_score = 0

            for wv in new_wvs:
                frame = json.loads(wv['frame'])
                keywords = frame['metadata'].get('key_concepts', [])

                score = sum(1 for kw in keywords if kw in lp_text)

                if score > best_score:
                    best_score = score
                    best_match = wv['id']

            if best_score > 0:
                # Link ìƒì„±
                try:
                    self.supabase.table('perception_worldview_links').insert({
                        'perception_id': lp['id'],
                        'worldview_id': best_match,
                        'relevance_score': best_score / 5.0  # Normalize
                    }).execute()
                    matched_count += 1
                except:
                    pass  # ì´ë¯¸ ì¡´ì¬í•  ìˆ˜ ìˆìŒ

        return matched_count

    async def _generate_example_from_perception(self, perception: Dict) -> Dict:
        """Perceptionì—ì„œ ì˜ˆì‹œ ìƒì„±"""

        prompt = f"""
ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ì„¸ê³„ê´€ ì˜ˆì‹œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

ì‹¬ì¸µ ë¯¿ìŒ: {perception.get('deep_beliefs', [])[:2]}
ì•”ë¬µì  ì „ì œ: {perception.get('implicit_assumptions', [])[:2]}

í˜•ì‹:
{{
  "case": "êµ¬ì²´ì  ì‚¬ë¡€",
  "dc_interpretation": "DC Gallery í•´ì„",
  "normal_interpretation": "ì¼ë°˜ì  í•´ì„",
  "gap": "í•µì‹¬ ì°¨ì´"
}}

JSONìœ¼ë¡œ ì‘ë‹µ:
"""

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are an expert. Always respond in valid JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            response_format={"type": "json_object"}
        )

        return json.loads(response.choices[0].message.content)

    def _extract_theme(self, hint: str, beliefs: List[str]) -> str:
        """ê°„ë‹¨í•œ ì£¼ì œ ì¶”ì¶œ"""

        text = hint + ' ' + ' '.join(beliefs)

        if 'ë¯¼ì£¼ë‹¹' in text or 'ì¢ŒíŒŒ' in text:
            return 'ë¯¼ì£¼ë‹¹/ì¢ŒíŒŒ'
        elif 'ì¤‘êµ­' in text:
            return 'ì¤‘êµ­'
        elif 'ë¶í•œ' in text:
            return 'ë¶í•œ'
        elif 'í†µì¼êµ' in text or 'ì¢…êµ' in text:
            return 'ì¢…êµ/í†µì¼êµ'
        else:
            return 'ê¸°íƒ€'

    async def _create_new_worldview(self, theme: str, perceptions: List[Dict]) -> Dict:
        """ìƒˆ ì„¸ê³„ê´€ ìƒì„±"""

        # ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„
        sample_data = []
        for lp in perceptions[:10]:
            sample_data.append({
                'deep_beliefs': lp.get('deep_beliefs', [])[:2],
                'implicit_assumptions': lp.get('implicit_assumptions', [])[:2]
            })

        prompt = f"""
ì£¼ì œ '{theme}'ì— ëŒ€í•œ ìƒˆë¡œìš´ ì„¸ê³„ê´€ì„ ìƒì„±í•˜ì„¸ìš”.

ë°ì´í„° {len(sample_data)}ê°œ:
{json.dumps(sample_data, ensure_ascii=False, indent=1)}

ì„¸ê³„ê´€ êµ¬ì¡°:
{{
  "title": "ì„¸ê³„ê´€ ì œëª©",
  "category": "ëŒ€ë¶„ë¥˜ (ê¸°ì¡´: ë¯¼ì£¼ë‹¹/ì¢ŒíŒŒì— ëŒ€í•œ ì¸ì‹, ì™¸ë¶€ ì„¸ë ¥ì˜ ìœ„í˜‘, êµ­ë‚´ ì •ì¹˜ì  ë¶ˆì•ˆì •)",
  "narrative": {{
    "summary": "í•œ ì¤„ ìš”ì•½",
    "examples": [...],
    "logic_chain": "ë…¼ë¦¬",
    "historical_context": "ì—­ì‚¬"
  }},
  "metadata": {{
    "core": {{"primary_subject": "...", "primary_attribute": "..."}},
    "interpretation_frame": {{...}},
    "emotional_drivers": {{...}},
    "key_concepts": [...]
  }}
}}

JSONìœ¼ë¡œ ì‘ë‹µ:
"""

        response = await client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are an expert. Always respond in valid JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        wv_data = json.loads(response.choices[0].message.content)

        # DB ì €ì¥
        worldview = {
            'title': f"{wv_data['category']} > {wv_data['title']}",
            'frame': json.dumps({
                'category': wv_data['category'],
                'subcategory': wv_data['title'],
                'narrative': wv_data['narrative'],
                'metadata': wv_data['metadata']
            }, ensure_ascii=False),
            'description': wv_data['narrative']['summary'],
            'core_subject': wv_data['metadata']['core']['primary_subject'],
            'core_attributes': wv_data['metadata'].get('key_concepts', []),
            'overall_valence': 'negative'
        }

        result = self.supabase.table('worldviews').insert(worldview).execute()

        return result.data[0]
