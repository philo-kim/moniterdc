"""
OptimalWorldviewConstructor - ÏµúÏ†ÅÌôîÎêú ÏÑ∏Í≥ÑÍ¥Ä Íµ¨ÏÑ± ÏóîÏßÑ

ÏãúÎÆ¨Î†àÏù¥ÏÖò Í≤∞Í≥º Í∏∞Î∞ò ÏµúÏ†Å ÏÑ§Í≥Ñ:
1. Í≥ÑÏ∏µÌòï Íµ¨Ï°∞ (ÎåÄÎ∂ÑÎ•ò ‚Üí ÏÑ∏Î∂Ä)
2. ÏòàÏãú Ï§ëÏã¨ Narrative
3. Í≥ÑÏ∏µÌòï Metadata
4. Hybrid Îß§Ïπ≠ (Vector 70% + Keyword 30%)
"""

from openai import AsyncOpenAI
import os
import json
import numpy as np
from typing import Dict, List, Tuple
from uuid import UUID
from engines.utils.supabase_client import get_supabase

client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))

class OptimalWorldviewConstructor:
    """Construct hierarchical worldviews from layered perceptions"""

    def __init__(self):
        self.supabase = get_supabase()

    async def construct_all(self) -> Dict:
        """
        Ï†ÑÏ≤¥ ÏÑ∏Í≥ÑÍ¥Ä Íµ¨ÏÑ± ÌîÑÎ°úÏÑ∏Ïä§

        Returns:
            Íµ¨ÏÑ± Í≤∞Í≥º ÌÜµÍ≥Ñ
        """

        print("\n" + "="*70)
        print("ÏÑ∏Í≥ÑÍ¥Ä Íµ¨ÏÑ± ÏãúÏûë")
        print("="*70)

        # 1. Î™®Îì† layered_perceptions Î°úÎìú
        perceptions = await self._load_all_perceptions()
        print(f"\n‚úÖ {len(perceptions)}Í∞ú perception Î°úÎìú ÏôÑÎ£å")

        # 2. Í≥ÑÏ∏µÌòï ÏÑ∏Í≥ÑÍ¥Ä Ï∂îÏ∂ú
        worldview_hierarchy = await self._extract_hierarchical_worldviews(perceptions)
        print(f"\n‚úÖ {len(worldview_hierarchy)}Í∞ú ÎåÄÎ∂ÑÎ•ò ÏÑ∏Í≥ÑÍ¥Ä Ï∂îÏ∂ú")

        # 3. ÏÑ∏Í≥ÑÍ¥Ä Ï†ÄÏû•
        saved_worldviews = await self._save_worldviews(worldview_hierarchy)
        print(f"\n‚úÖ {len(saved_worldviews)}Í∞ú ÏÑ∏Í≥ÑÍ¥Ä Ï†ÄÏû• ÏôÑÎ£å")

        # 4. Perception ‚Üî Worldview Îß§Ïπ≠ (Hybrid)
        links_created = await self._match_perceptions_to_worldviews(
            perceptions,
            saved_worldviews
        )
        print(f"\n‚úÖ {links_created}Í∞ú Ïó∞Í≤∞ ÏÉùÏÑ±")

        # 5. ÌÜµÍ≥Ñ Í≥ÑÏÇ∞
        stats = await self._calculate_statistics(saved_worldviews)

        return stats

    async def _load_all_perceptions(self) -> List[Dict]:
        """Î™®Îì† layered_perceptions Î°úÎìú"""

        lps = self.supabase.table('layered_perceptions')\
            .select('id, content_id, deep_beliefs, implicit_assumptions, worldview_hints, explicit_claims')\
            .execute().data

        # Content titles Ï∂îÍ∞Ä
        for lp in lps:
            content = self.supabase.table('contents')\
                .select('title')\
                .eq('id', lp['content_id'])\
                .execute().data

            if content:
                lp['title'] = content[0]['title']

        return lps

    async def _extract_hierarchical_worldviews(self, perceptions: List[Dict]) -> List[Dict]:
        """
        Í≥ÑÏ∏µÌòï ÏÑ∏Í≥ÑÍ¥Ä Ï∂îÏ∂ú

        ÎåÄÎ∂ÑÎ•ò 3-4Í∞ú ‚Üí Í∞Å ÎåÄÎ∂ÑÎ•òÎßàÎã§ ÏÑ∏Î∂Ä 2-3Í∞ú
        """

        # ÏÉòÌîåÎßÅ (GPT ÌÜ†ÌÅ∞ Ï†úÌïú Í≥†Î†§)
        sample_size = min(100, len(perceptions))
        sample_perceptions = perceptions[:sample_size]

        # Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
        analysis_data = []
        for lp in sample_perceptions:
            analysis_data.append({
                'title': lp.get('title', '')[:100],
                'deep_beliefs': lp.get('deep_beliefs', [])[:3],
                'implicit_assumptions': lp.get('implicit_assumptions', [])[:2],
                'worldview_hints': lp.get('worldview_hints', '')
            })

        prompt = f"""
Îã§ÏùåÏùÄ DC Gallery Ï†ïÏπò Í∏Ä {len(analysis_data)}Í∞úÏùò Î∂ÑÏÑù Í≤∞Í≥ºÏûÖÎãàÎã§.

{json.dumps(analysis_data[:30], ensure_ascii=False, indent=1)}

Ïù¥ Îç∞Ïù¥ÌÑ∞Î•º Î∂ÑÏÑùÌï¥ÏÑú **Í≥ÑÏ∏µÌòï ÏÑ∏Í≥ÑÍ¥Ä Íµ¨Ï°∞**Î•º ÎßåÎì§Ïñ¥Ï£ºÏÑ∏Ïöî.

ÏöîÍµ¨ÏÇ¨Ìï≠:
1. **3-4Í∞ú ÎåÄÎ∂ÑÎ•ò** (Ï£ºÏöî Ï£ºÏ†ú Ï∂ï)
2. Í∞Å ÎåÄÎ∂ÑÎ•òÎßàÎã§ **2-3Í∞ú ÏÑ∏Î∂Ä ÏÑ∏Í≥ÑÍ¥Ä**
3. Í∞Å ÏÑ∏Î∂Ä ÏÑ∏Í≥ÑÍ¥ÄÏùÄ:
   - ÏòàÏãú Ï§ëÏã¨ Narrative (DC Ìï¥ÏÑù vs ÏùºÎ∞ò Ìï¥ÏÑù ÎåÄÎπÑ)
   - Í≥ÑÏ∏µÌòï Metadata (core, interpretation_frame, emotional_drivers)

JSON ÌòïÏãù:
{{
  "hierarchy": [
    {{
      "category": "ÎåÄÎ∂ÑÎ•òÎ™Ö (Ïòà: ÎØºÏ£ºÎãπ/Ï¢åÌååÏóê ÎåÄÌïú Ïù∏Ïãù)",
      "description": "ÎåÄÎ∂ÑÎ•ò ÏÑ§Î™Ö",
      "subcategories": [
        {{
          "title": "ÏÑ∏Î∂Ä ÏÑ∏Í≥ÑÍ¥ÄÎ™Ö (Ïòà: ÎèÖÏû¨ Ïû¨ÌòÑ)",
          "narrative": {{
            "summary": "Ìïú Ï§Ñ ÏöîÏïΩ",
            "examples": [
              {{
                "case": "Íµ¨Ï≤¥Ï†Å ÏÇ¨Î°Ä (Ïòà: Ïú†Ïã¨ÍµêÏ≤¥ Ï†ïÎ≥¥)",
                "dc_interpretation": "DC GalleryÏùò Ìï¥ÏÑù",
                "normal_interpretation": "ÏùºÎ∞òÏ†Å Ìï¥ÏÑù",
                "gap": "Ìï¥ÏÑù Ï∞®Ïù¥Ïùò ÌïµÏã¨"
              }}
            ],
            "logic_chain": "ÎÖºÎ¶¨ ÌùêÎ¶Ñ (A ‚Üí B ‚Üí C)",
            "historical_context": "Ïó≠ÏÇ¨Ï†Å Ï∞∏Ï°∞"
          }},
          "metadata": {{
            "core": {{
              "primary_subject": "Ï£ºÏöî ÎåÄÏÉÅ",
              "primary_attribute": "ÌïµÏã¨ ÏÜçÏÑ±",
              "primary_action": "ÌïµÏã¨ ÌñâÎèô"
            }},
            "interpretation_frame": {{
              "historical_lens": {{
                "reference_period": "Ï∞∏Ï°∞ ÏãúÍ∏∞",
                "reference_events": ["ÏÇ¨Í±¥1", "ÏÇ¨Í±¥2"],
                "projection_logic": "Ìà¨ÏòÅ ÎÖºÎ¶¨"
              }},
              "causal_chain": ["Îã®Í≥Ñ1", "Îã®Í≥Ñ2", "Îã®Í≥Ñ3"],
              "slippery_slope": {{
                "trigger": "ÏãúÏûëÏ†ê",
                "escalation": "ÌôïÎåÄ Í≤ΩÎ°ú",
                "endpoint": "ÏµúÏ¢Ö Í≤∞Í≥º"
              }}
            }},
            "emotional_drivers": {{
              "primary": "Ï£º Í∞êÏ†ï",
              "secondary": ["Î∂Ä Í∞êÏ†ïÎì§"],
              "urgency_level": "Í∏¥Í∏âÎèÑ"
            }},
            "key_concepts": ["Í∞úÎÖê1", "Í∞úÎÖê2", "Í∞úÎÖê3"]
          }}
        }}
      ]
    }}
  ]
}}
"""

        print("\nÍ≥ÑÏ∏µÌòï ÏÑ∏Í≥ÑÍ¥Ä Ï∂îÏ∂ú Ï§ë (GPT-5)...")

        response = await client.chat.completions.create(
            model="gpt-5",
            messages=[
                {"role": "system", "content": "You are an expert in political discourse analysis. Always respond in valid JSON format."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}
        )

        result = json.loads(response.choices[0].message.content)
        hierarchy = result.get('hierarchy', [])

        # Í≤∞Í≥º Ï∂úÎ†•
        for cat in hierarchy:
            print(f"\nüìÇ {cat['category']}")
            for subcat in cat.get('subcategories', []):
                print(f"  ‚îî‚îÄ {subcat['title']}")

        return hierarchy

    async def _save_worldviews(self, hierarchy: List[Dict]) -> List[Dict]:
        """
        ÏÑ∏Í≥ÑÍ¥ÄÏùÑ worldviews ÌÖåÏù¥Î∏îÏóê Ï†ÄÏû•

        Í≥ÑÏ∏µ Íµ¨Ï°∞Î•º ÌèâÌÉÑÌôîÌïòÎêò, category Ï†ïÎ≥¥ Ïú†ÏßÄ
        """

        saved_worldviews = []

        for category in hierarchy:
            category_name = category['category']
            category_desc = category.get('description', '')

            for subcat in category.get('subcategories', []):

                worldview_data = {
                    'title': f"{category_name} > {subcat['title']}",

                    # FrameÏùÑ JSONÏúºÎ°ú Ï†ÄÏû•
                    'frame': json.dumps({
                        'category': category_name,
                        'subcategory': subcat['title'],
                        'narrative': subcat.get('narrative', {}),
                        'metadata': subcat.get('metadata', {})
                    }, ensure_ascii=False),

                    'description': subcat['narrative'].get('summary', ''),

                    # Core fields
                    'core_subject': subcat['metadata']['core'].get('primary_subject', ''),
                    'core_attributes': subcat['metadata'].get('key_concepts', []),
                    'overall_valence': 'negative',  # DC GalleryÎäî ÎåÄÎ∂ÄÎ∂Ñ Î∂ÄÏ†ïÏ†Å

                    # Empty arrays for now (will be filled during matching)
                    'perception_ids': [],
                    'total_perceptions': 0,
                }

                # Save
                result = self.supabase.table('worldviews').insert(worldview_data).execute()

                if result.data:
                    saved = result.data[0]
                    saved['subcategory_data'] = subcat  # Îß§Ïπ≠Ïö© Îç∞Ïù¥ÌÑ∞ Î≥¥Ï°¥
                    saved_worldviews.append(saved)

        return saved_worldviews

    async def _match_perceptions_to_worldviews(
        self,
        perceptions: List[Dict],
        worldviews: List[Dict]
    ) -> int:
        """
        Hybrid Îß§Ïπ≠ (Vector 70% + Keyword 30%)

        Í∞Å perceptionÏùÑ Í∞ÄÏû• Ï†ÅÌï©Ìïú worldview(s)Ïóê Ïó∞Í≤∞
        """

        print("\n" + "="*70)
        print("Perception ‚Üî Worldview Îß§Ïπ≠ (Hybrid)")
        print("="*70)

        # 1. Worldview embeddings Í≥ÑÏÇ∞
        print("\n1. Worldview embeddings Í≥ÑÏÇ∞ Ï§ë...")
        worldview_embeddings = []

        for wv in worldviews:
            # Narrative ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú
            frame_data = json.loads(wv['frame'])
            narrative = frame_data.get('narrative', {})

            narrative_text = f"{narrative.get('summary', '')} "
            narrative_text += ' '.join([
                ex.get('dc_interpretation', '')
                for ex in narrative.get('examples', [])
            ])

            # Embedding Í≥ÑÏÇ∞
            emb_response = await client.embeddings.create(
                model="text-embedding-3-small",
                input=narrative_text
            )

            worldview_embeddings.append({
                'id': wv['id'],
                'title': wv['title'],
                'embedding': emb_response.data[0].embedding,
                'metadata': frame_data.get('metadata', {})
            })

        # 2. Perception Îß§Ïπ≠
        print(f"\n2. {len(perceptions)}Í∞ú perception Îß§Ïπ≠ Ï§ë...")

        links_created = 0
        batch_size = 10

        for i in range(0, len(perceptions), batch_size):
            batch = perceptions[i:i+batch_size]

            for lp in batch:
                # Perception ÌÖçÏä§Ìä∏
                lp_text = ' '.join(lp.get('deep_beliefs', []))

                if not lp_text.strip():
                    continue

                # Vector similarity
                lp_emb_response = await client.embeddings.create(
                    model="text-embedding-3-small",
                    input=lp_text
                )
                lp_embedding = lp_emb_response.data[0].embedding

                # Calculate scores
                best_matches = []

                for wv_emb in worldview_embeddings:
                    # Vector similarity
                    vector_sim = self._cosine_similarity(lp_embedding, wv_emb['embedding'])

                    # Keyword matching
                    keyword_score = self._keyword_match_score(lp, wv_emb['metadata'])

                    # Hybrid score (70% vector + 30% keyword)
                    hybrid_score = 0.7 * vector_sim + 0.3 * keyword_score

                    if hybrid_score > 0.5:  # Threshold
                        best_matches.append({
                            'worldview_id': wv_emb['id'],
                            'score': hybrid_score
                        })

                # Create links (top 2 matches)
                best_matches.sort(key=lambda x: x['score'], reverse=True)

                for match in best_matches[:2]:
                    await self._create_link(
                        lp['id'],
                        match['worldview_id'],
                        match['score']
                    )
                    links_created += 1

            print(f"\r  ÏßÑÌñâ: {min(i+batch_size, len(perceptions))}/{len(perceptions)}", end='', flush=True)

        print(f"\n\n‚úÖ {links_created}Í∞ú ÎßÅÌÅ¨ ÏÉùÏÑ± ÏôÑÎ£å")

        return links_created

    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """Cosine similarity"""
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

    def _keyword_match_score(self, perception: Dict, metadata: Dict) -> float:
        """
        ÌÇ§ÏõåÎìú Îß§Ïπ≠ Ï†êÏàò (0-1)

        MetadataÏùò key_conceptsÏôÄ perceptionÏùò deep_beliefs ÎπÑÍµê
        """

        lp_text = ' '.join(perception.get('deep_beliefs', []) +
                          perception.get('implicit_assumptions', []))

        if not lp_text:
            return 0.0

        key_concepts = metadata.get('key_concepts', [])
        core = metadata.get('core', {})

        # Í≤ÄÏÉâ ÌÇ§ÏõåÎìú
        keywords = key_concepts + [
            core.get('primary_subject', ''),
            core.get('primary_attribute', '')
        ]

        matches = 0
        for keyword in keywords:
            if keyword and keyword in lp_text:
                matches += 1

        # Normalize (0-1)
        return min(matches / max(len(keywords), 1), 1.0)

    async def _create_link(self, perception_id: str, worldview_id: str, score: float):
        """Create perception_worldview_link"""

        # Check if table exists
        try:
            link_data = {
                'perception_id': perception_id,
                'worldview_id': worldview_id,
                'relevance_score': score
            }

            self.supabase.table('perception_worldview_links').insert(link_data).execute()
        except Exception as e:
            # Table might not exist, create manually
            if 'does not exist' in str(e):
                # Create table first
                await self._ensure_links_table_exists()
                # Retry
                self.supabase.table('perception_worldview_links').insert(link_data).execute()

    async def _ensure_links_table_exists(self):
        """Ensure perception_worldview_links table exists"""

        # Read migration SQL
        migration_path = '/Users/taehyeonkim/dev/minjoo/moniterdc/supabase/migrations/203_create_perception_worldview_links.sql'

        with open(migration_path, 'r') as f:
            sql = f.read()

        # Execute (this is a simplified version, actual execution needs admin privileges)
        print("\n‚ö†Ô∏è  perception_worldview_links ÌÖåÏù¥Î∏îÏù¥ ÏóÜÏäµÎãàÎã§.")
        print(f"   Îã§Ïùå SQLÏùÑ ÏàòÎèôÏúºÎ°ú Ïã§ÌñâÌïòÏÑ∏Ïöî:\n")
        print(sql)

    async def _calculate_statistics(self, worldviews: List[Dict]) -> Dict:
        """ÌÜµÍ≥Ñ Í≥ÑÏÇ∞"""

        print("\n" + "="*70)
        print("ÌÜµÍ≥Ñ Í≥ÑÏÇ∞")
        print("="*70)

        # Í∞Å worldviewÏùò perception Í∞úÏàò Í≥ÑÏÇ∞
        for wv in worldviews:
            try:
                links = self.supabase.table('perception_worldview_links')\
                    .select('perception_id', count='exact')\
                    .eq('worldview_id', wv['id'])\
                    .execute()

                count = links.count if links.count else 0

                # Update worldview
                self.supabase.table('worldviews')\
                    .update({'total_perceptions': count})\
                    .eq('id', wv['id'])\
                    .execute()

                print(f"  {wv['title'][:60]}: {count}Í∞ú")

            except Exception as e:
                print(f"  ‚ö†Ô∏è  ÌÜµÍ≥Ñ Í≥ÑÏÇ∞ Ïã§Ìå®: {e}")

        return {
            'total_worldviews': len(worldviews),
            'status': 'completed'
        }
